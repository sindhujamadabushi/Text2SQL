{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: fineGrained).\n",
      "The token `text2sql_deepseek` has been saved to /home/swsingh/.cache/huggingface/stored_tokens\n",
      "Your token has been saved to /home/swsingh/.cache/huggingface/token\n",
      "Login successful.\n",
      "The current active token is: `text2sql_deepseek`\n"
     ]
    }
   ],
   "source": [
    "get_ipython().system('token')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langchain'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoModelForCausalLM, AutoTokenizer, pipeline\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllms\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HuggingFacePipeline\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PromptTemplate, LLMChain\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'langchain'"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain import PromptTemplate, LLMChain\n",
    "import torch\n",
    "import pandas as pd\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: For better debugging info if CUDA errors occur\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 7/7 [00:28<00:00,  4.06s/it]\n"
     ]
    }
   ],
   "source": [
    "model_name = \"deepseek-ai/deepseek-coder-33b-instruct\"\n",
    "custom_cache_dir = \"/isilon/datalake/dma_research/scratch/damalab/Data/Swapnil/Personal/Model\"  # Change this to your desired directory\n",
    "\n",
    "# Load tokenizer with custom cache path\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, cache_dir=custom_cache_dir)\n",
    "\n",
    "# Load model with custom cache path\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name, \n",
    "    cache_dir=custom_cache_dir, \n",
    "    device_map={\"\":0}, \n",
    "    torch_dtype=torch.float16,\n",
    "    low_cpu_mem_usage=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "text_gen_pipeline = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_new_tokens=1024,  # or higher, like 1024 if needed\n",
    "    temperature=0.3,\n",
    "    top_p=0.9,\n",
    "    do_sample=False, # Changed to deterministic decoding\n",
    "    pad_token_id=tokenizer.eos_token_id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/swsingh/ipykernel_792359/2474907508.py:2: LangChainDeprecationWarning: The class `HuggingFacePipeline` was deprecated in LangChain 0.0.37 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFacePipeline``.\n",
      "  llm = HuggingFacePipeline(pipeline=text_gen_pipeline)\n"
     ]
    }
   ],
   "source": [
    "# Initialize HuggingFacePipeline with the text generation pipeline\n",
    "llm = HuggingFacePipeline(pipeline=text_gen_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define a prompt template for SQL generation\n",
    "# prompt = PromptTemplate(\n",
    "#     input_variables=[\"text\", \"ini_query\", \"query\"],\n",
    "#     template=\"\"\"\n",
    "#     A SQL query was generated to answer the following natural language request:\n",
    "\n",
    "#     Question: {text}\n",
    "#     Initail SQL Querry:\n",
    "#     ```sql\n",
    "#     {ini_query}\n",
    "#     ```\n",
    "#     SQL Query:\n",
    "#     ```sql\n",
    "#     {query}\n",
    "#     ```\n",
    "\n",
    "#     Please do the following:\n",
    "#     1. Verify if the SQL query correctly answers the question.\n",
    "#     2. If it does, explain why it's correct.\n",
    "#     3. If it's incorrect or suboptimal, explain the issue and provide a corrected or optimized version of the SQL query.\n",
    "#     4. Make sure the syntax is valid and executable in standard SQL (PostgreSQL/MySQL-compatible).\n",
    "\n",
    "#     Provide your answer in the following format:\n",
    "#     - Verdict: Correct / Incorrect\n",
    "#     - Explanation: <Your reasoning>\n",
    "#     - Improved SQL (if applicable)/input SQL:\n",
    "#     ```sql\n",
    "#     <Improved query>\n",
    "#     ```\n",
    "#     \"\"\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create an LLMChain with the prompt template and language model\n",
    "# llm_chain = LLMChain(prompt=prompt, llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Example natural language query\n",
    "# text = \"How many pseudo users were active in the last 7 days but inactive in the last 2 days as of January 7, 2021?\"\n",
    "# db = \"ga4\"\n",
    "# query = \"\"\"\n",
    "# SELECT COUNT(*) \n",
    "# FROM users \n",
    "# WHERE user_type = 'pseudo' \n",
    "# AND last_activity_date >= DATE_SUB('2021-01-07', INTERVAL 7 DAY) \n",
    "# AND last_activity_date < DATE_SUB('2021-01-07', INTERVAL 2 DAY)\n",
    "# \"\"\"\n",
    "# # Generate the SQL statement\n",
    "# sql_query = llm_chain.run(text=text, query=query)\n",
    "\n",
    "# # Extract SQL block using regex\n",
    "# sql_blocks = re.findall(r\"```sql(.*?)```\", sql_query, re.DOTALL)\n",
    "# if sql_blocks:\n",
    "#     cleaned_sql = sql_blocks[-1].strip()\n",
    "#     print(cleaned_sql)\n",
    "# else:\n",
    "#     print(\"No SQL block found in response.\")\n",
    "# #print(sql_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instance_id</th>\n",
       "      <th>generated_sql</th>\n",
       "      <th>nl_query</th>\n",
       "      <th>db</th>\n",
       "      <th>external_knowledge</th>\n",
       "      <th>refined_sql</th>\n",
       "      <th>refined_sql_cleaned</th>\n",
       "      <th>final_query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bq001</td>\n",
       "      <td>SELECT \\n    T1.visitor_id,\\n    T1.date_of_vi...</td>\n",
       "      <td>For each visitor who made at least one transac...</td>\n",
       "      <td>ga360</td>\n",
       "      <td>google_analytics_sample.ga_sessions.md</td>\n",
       "      <td>SELECT \\n    T1.visitor_id,\\n    T1.date_of_vi...</td>\n",
       "      <td>SELECT T1.visitor_id, T1.date_of_visit, COUNT(...</td>\n",
       "      <td>SELECT \\n    v.visitor_id, \\n    MIN(v.date_of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bq002</td>\n",
       "      <td>SELECT \\r\\n    t1.source_name,\\r\\n    MAX(t1.r...</td>\n",
       "      <td>During the first half of 2017,  focusing on hi...</td>\n",
       "      <td>ga360</td>\n",
       "      <td>google_analytics_sample.ga_sessions.md</td>\n",
       "      <td>SELECT \\r\\n    t1.source_name,\\r\\n    MAX(t1.r...</td>\n",
       "      <td>SELECT t1.source_name, MAX(t1.revenue) AS max_...</td>\n",
       "      <td>SELECT t1.source_name, MAX(t1.revenue) AS max_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bq003</td>\n",
       "      <td>SELECT \\n    DATE_FORMAT(visits.visit_date, '%...</td>\n",
       "      <td>Between April 1 and July 31 of 2017, using the...</td>\n",
       "      <td>ga360</td>\n",
       "      <td>google_analytics_sample.ga_sessions.md</td>\n",
       "      <td>SELECT \\n    DATE_FORMAT(visits.visit_date, '%...</td>\n",
       "      <td>SELECT DATE_FORMAT(visits.visit_date, '%Y-%m')...</td>\n",
       "      <td>SELECT \\n        DATE_FORMAT(visits.visit_date...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bq268</td>\n",
       "      <td>SELECT \\n    MAX(DATEDIFF(day, MAX(last_visit)...</td>\n",
       "      <td>Identify the longest number of days between th...</td>\n",
       "      <td>ga360</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SELECT \\n    MAX(DATEDIFF(day, MAX(last_visit)...</td>\n",
       "      <td>SELECT MAX(DATEDIFF(day, MAX(last_visit), MIN(...</td>\n",
       "      <td>SELECT MAX(DATEDIFF(day, first_visit, last_eve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bq270</td>\n",
       "      <td>SELECT \\n    p.category,\\n    COUNT(DISTINCT p...</td>\n",
       "      <td>What were the monthly add-to-cart and purchase...</td>\n",
       "      <td>ga360</td>\n",
       "      <td>ga360_hits.eCommerceAction.action_type.md</td>\n",
       "      <td>SELECT \\n    p.category,\\n    COUNT(DISTINCT p...</td>\n",
       "      <td>SELECT p.category, COUNT(DISTINCT p.product_id...</td>\n",
       "      <td>SELECT p.category, COUNT(DISTINCT p.product_id...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>sf037</td>\n",
       "      <td>SELECT \\n    StoreName,\\n    MIN(DISTANCE) AS ...</td>\n",
       "      <td>How can we find the shortest straight-line dis...</td>\n",
       "      <td>US_REAL_ESTATE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SELECT \\n    StoreName,\\n    MIN(DISTANCE) AS ...</td>\n",
       "      <td>SELECT StoreName, MIN(DISTANCE) AS ShortestDis...</td>\n",
       "      <td>SELECT \\n        hd.StoreID AS TheHomeDepotSto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>sf029</td>\n",
       "      <td>SELECT \\r\\n    s.date AS date,\\r\\n    s.asin A...</td>\n",
       "      <td>Generate a daily detailed sales report for eac...</td>\n",
       "      <td>AMAZON_VENDOR_ANALYTICS__SAMPLE_DATASET</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SELECT \\r\\n    s.date AS date,\\r\\n    s.asin A...</td>\n",
       "      <td>SELECT s.date AS date, s.asin AS asin, s.progr...</td>\n",
       "      <td>SELECT \\n        s.date, \\n        s.asin, \\n ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>sf013</td>\n",
       "      <td>SELECT \\n    c.class_name AS Class,\\n    s.sub...</td>\n",
       "      <td>Compare the total road lengths in Amsterdam an...</td>\n",
       "      <td>NETHERLANDS_OPEN_MAP_DATA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SELECT \\n    c.class_name AS Class,\\n    s.sub...</td>\n",
       "      <td>SELECT c.class_name AS Class, s.sub_class_name...</td>\n",
       "      <td>SELECT c.class_name AS Class, s.sub_class_name...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>sf041</td>\n",
       "      <td>SELECT \\r\\n    T1.date AS date,\\r\\n    T1.hour...</td>\n",
       "      <td>Produce a report for ERCOT on October 1, 2022,...</td>\n",
       "      <td>YES_ENERGY__SAMPLE_DATA</td>\n",
       "      <td>ERCOT_Daily_Market_Dynamics_Report.md</td>\n",
       "      <td># Refine the following SQL query using externa...</td>\n",
       "      <td># Refine the following SQL query using externa...</td>\n",
       "      <td>&lt;Improved query&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>sf011</td>\n",
       "      <td>SELECT \\n    census_value,\\n    CASE \\n       ...</td>\n",
       "      <td>Determine the population distribution within e...</td>\n",
       "      <td>CENSUS_GALAXY__ZIP_CODE_TO_BLOCK_GROUP_SAMPLE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SELECT \\n    census_value,\\n    CASE \\n       ...</td>\n",
       "      <td>SELECT census_value, CASE WHEN state_county_tr...</td>\n",
       "      <td>SELECT \\n        block_group_id, \\n        cen...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>281 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    instance_id                                      generated_sql  \\\n",
       "0         bq001  SELECT \\n    T1.visitor_id,\\n    T1.date_of_vi...   \n",
       "1         bq002  SELECT \\r\\n    t1.source_name,\\r\\n    MAX(t1.r...   \n",
       "2         bq003  SELECT \\n    DATE_FORMAT(visits.visit_date, '%...   \n",
       "3         bq268  SELECT \\n    MAX(DATEDIFF(day, MAX(last_visit)...   \n",
       "4         bq270  SELECT \\n    p.category,\\n    COUNT(DISTINCT p...   \n",
       "..          ...                                                ...   \n",
       "276       sf037  SELECT \\n    StoreName,\\n    MIN(DISTANCE) AS ...   \n",
       "277       sf029  SELECT \\r\\n    s.date AS date,\\r\\n    s.asin A...   \n",
       "278       sf013  SELECT \\n    c.class_name AS Class,\\n    s.sub...   \n",
       "279       sf041  SELECT \\r\\n    T1.date AS date,\\r\\n    T1.hour...   \n",
       "280       sf011  SELECT \\n    census_value,\\n    CASE \\n       ...   \n",
       "\n",
       "                                              nl_query  \\\n",
       "0    For each visitor who made at least one transac...   \n",
       "1    During the first half of 2017,  focusing on hi...   \n",
       "2    Between April 1 and July 31 of 2017, using the...   \n",
       "3    Identify the longest number of days between th...   \n",
       "4    What were the monthly add-to-cart and purchase...   \n",
       "..                                                 ...   \n",
       "276  How can we find the shortest straight-line dis...   \n",
       "277  Generate a daily detailed sales report for eac...   \n",
       "278  Compare the total road lengths in Amsterdam an...   \n",
       "279  Produce a report for ERCOT on October 1, 2022,...   \n",
       "280  Determine the population distribution within e...   \n",
       "\n",
       "                                                db  \\\n",
       "0                                            ga360   \n",
       "1                                            ga360   \n",
       "2                                            ga360   \n",
       "3                                            ga360   \n",
       "4                                            ga360   \n",
       "..                                             ...   \n",
       "276                                 US_REAL_ESTATE   \n",
       "277        AMAZON_VENDOR_ANALYTICS__SAMPLE_DATASET   \n",
       "278                      NETHERLANDS_OPEN_MAP_DATA   \n",
       "279                        YES_ENERGY__SAMPLE_DATA   \n",
       "280  CENSUS_GALAXY__ZIP_CODE_TO_BLOCK_GROUP_SAMPLE   \n",
       "\n",
       "                            external_knowledge  \\\n",
       "0       google_analytics_sample.ga_sessions.md   \n",
       "1       google_analytics_sample.ga_sessions.md   \n",
       "2       google_analytics_sample.ga_sessions.md   \n",
       "3                                          NaN   \n",
       "4    ga360_hits.eCommerceAction.action_type.md   \n",
       "..                                         ...   \n",
       "276                                        NaN   \n",
       "277                                        NaN   \n",
       "278                                        NaN   \n",
       "279      ERCOT_Daily_Market_Dynamics_Report.md   \n",
       "280                                        NaN   \n",
       "\n",
       "                                           refined_sql  \\\n",
       "0    SELECT \\n    T1.visitor_id,\\n    T1.date_of_vi...   \n",
       "1    SELECT \\r\\n    t1.source_name,\\r\\n    MAX(t1.r...   \n",
       "2    SELECT \\n    DATE_FORMAT(visits.visit_date, '%...   \n",
       "3    SELECT \\n    MAX(DATEDIFF(day, MAX(last_visit)...   \n",
       "4    SELECT \\n    p.category,\\n    COUNT(DISTINCT p...   \n",
       "..                                                 ...   \n",
       "276  SELECT \\n    StoreName,\\n    MIN(DISTANCE) AS ...   \n",
       "277  SELECT \\r\\n    s.date AS date,\\r\\n    s.asin A...   \n",
       "278  SELECT \\n    c.class_name AS Class,\\n    s.sub...   \n",
       "279  # Refine the following SQL query using externa...   \n",
       "280  SELECT \\n    census_value,\\n    CASE \\n       ...   \n",
       "\n",
       "                                   refined_sql_cleaned  \\\n",
       "0    SELECT T1.visitor_id, T1.date_of_visit, COUNT(...   \n",
       "1    SELECT t1.source_name, MAX(t1.revenue) AS max_...   \n",
       "2    SELECT DATE_FORMAT(visits.visit_date, '%Y-%m')...   \n",
       "3    SELECT MAX(DATEDIFF(day, MAX(last_visit), MIN(...   \n",
       "4    SELECT p.category, COUNT(DISTINCT p.product_id...   \n",
       "..                                                 ...   \n",
       "276  SELECT StoreName, MIN(DISTANCE) AS ShortestDis...   \n",
       "277  SELECT s.date AS date, s.asin AS asin, s.progr...   \n",
       "278  SELECT c.class_name AS Class, s.sub_class_name...   \n",
       "279  # Refine the following SQL query using externa...   \n",
       "280  SELECT census_value, CASE WHEN state_county_tr...   \n",
       "\n",
       "                                           final_query  \n",
       "0    SELECT \\n    v.visitor_id, \\n    MIN(v.date_of...  \n",
       "1    SELECT t1.source_name, MAX(t1.revenue) AS max_...  \n",
       "2    SELECT \\n        DATE_FORMAT(visits.visit_date...  \n",
       "3    SELECT MAX(DATEDIFF(day, first_visit, last_eve...  \n",
       "4    SELECT p.category, COUNT(DISTINCT p.product_id...  \n",
       "..                                                 ...  \n",
       "276  SELECT \\n        hd.StoreID AS TheHomeDepotSto...  \n",
       "277  SELECT \\n        s.date, \\n        s.asin, \\n ...  \n",
       "278  SELECT c.class_name AS Class, s.sub_class_name...  \n",
       "279                                   <Improved query>  \n",
       "280  SELECT \\n        block_group_id, \\n        cen...  \n",
       "\n",
       "[281 rows x 8 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"refined_spider2_queries_cleaned_basic_final1.csv\")\n",
    "#df.head()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39, 8)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = df[df['final_query']=='<Improved query>']\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import glob\n",
    "\n",
    "# external_knowledge = {}\n",
    "# external_knowledge_dir = '/isilon/datalake/dma_research/scratch/damalab/Data/Swapnil/Personal/Text2SQL/Spider2/spider2-lite/resource/documents/'\n",
    "\n",
    "# # Load each Markdown (.md) file into the dictionary\n",
    "# for file_path in glob.glob(os.path.join(external_knowledge_dir, '*.md')):\n",
    "#     query_id = os.path.basename(file_path)\n",
    "#     with open(file_path, 'r', encoding='utf-8') as file:\n",
    "#         external_knowledge[query_id] = file.read().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = []\n",
    "for i in range(df1.shape[0]):\n",
    "    text = df1['nl_query'].iloc[i]\n",
    "    query = df1['refined_sql_cleaned'].iloc[i]\n",
    "    db = df1['db'].iloc[i]\n",
    "    # external_knowledge_name = df['external_knowledge'].iloc[i]\n",
    "\n",
    "    # # Check for NaN or missing knowledge\n",
    "    # if pd.isna(external_knowledge_name) or external_knowledge_name not in external_knowledge:\n",
    "    #     ek = \"N/A\"\n",
    "    # else:\n",
    "    #     ek = external_knowledge[external_knowledge_name]\n",
    "    # db = df['db'].iloc[i]\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    A SQL query was generated to answer the following natural language request:\n",
    "\n",
    "    Question: {text}\n",
    "    Database: {db}\n",
    "    SQL Query:\n",
    "    ```sql\n",
    "    {query}\n",
    "    ```\n",
    "\n",
    "    Please do the following:\n",
    "    1. Verify if the SQL query correctly answers the question.\n",
    "    2. If it does, explain why it's correct.\n",
    "    3. If it's incorrect or suboptimal, explain the issue and provide a corrected or optimized version of the SQL query.\n",
    "    4. Make sure the syntax is valid and executable in standard SQL (PostgreSQL/MySQL-compatible).\n",
    "\n",
    "    Provide your answer in the following format:\n",
    "    - Improved SQL (if applicable)/input SQL:\n",
    "    ```sql\n",
    "    <Improved query>\n",
    "    ```\n",
    "    \"\"\"\n",
    "    prompts.append(prompt.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import ceil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/39 [00:00<?, ?it/s]/isilon/datalake/dma_research/scratch/damalab/Data/Swapnil/miniconda3/envs/monai_conda/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.3` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/isilon/datalake/dma_research/scratch/damalab/Data/Swapnil/miniconda3/envs/monai_conda/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "100%|██████████| 39/39 [46:27<00:00, 71.49s/it]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1  # Choose based on your GPU memory\n",
    "final_query = []\n",
    "outputs = []\n",
    "\n",
    "for i in tqdm(range(0, len(prompts), batch_size)):\n",
    "    batch_prompts = prompts[i:i + batch_size]\n",
    "    \n",
    "    # Run batch through the Hugging Face pipeline\n",
    "    responses = text_gen_pipeline(batch_prompts)\n",
    "    \n",
    "    for r in responses:\n",
    "        output = r[0]['generated_text']\n",
    "        sql_blocks = re.findall(r\"```sql(.*?)```\", output, re.DOTALL)\n",
    "        cleaned_sql = sql_blocks[-1].strip() if sql_blocks else \"\"\n",
    "        final_query.append(cleaned_sql)\n",
    "        outputs.append(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"A SQL query was generated to answer the following natural language request:\\n\\n    Question: Produce a report for ERCOT on October 1, 2022, that combines hourly data on day-ahead and real-time prices from node ID 10000697078, load forecasts (datatypeid 19060) and actual loads, plus wind (forecast datatypeid 9285, actual datatypeid 16) and solar (forecast datatypeid 662, actual datatypeid 650) generation forecasts and actuals from object ID 10000712973. This report should include time zone alignments, peak classifications, and net load calculations, providing insights into daily operational dynamics and efficiency.\\n    Database: YES_ENERGY__SAMPLE_DATA\\n    SQL Query:\\n    ```sql\\n    # Refine the following SQL query using external knowledge and schema context # Fix syntax errors and optimize for clarity and correctness Database: YES_ENERGY__SAMPLE_DATA External knowledge: ERCOT_Daily_Market_Dynamics_Report.md Natural language query: Produce a report for ERCOT on October 1, 2022, that combines hourly data on day-ahead and real-time prices from node ID 10000697078, load forecasts (datatypeid 19060) and actual loads, plus wind (forecast datatypeid 9285, actual datatypeid 16) and solar (forecast datatypeid 662, actual datatypeid 650) generation forecasts and actuals from object ID 10000712973. This report should include time zone alignments, peak classifications, and net load calculations, providing insights into daily operational dynamics and efficiency. Original query:\\n    ```\\n\\n    Please do the following:\\n    1. Verify if the SQL query correctly answers the question.\\n    2. If it does, explain why it's correct.\\n    3. If it's incorrect or suboptimal, explain the issue and provide a corrected or optimized version of the SQL query.\\n    4. Make sure the syntax is valid and executable in standard SQL (PostgreSQL/MySQL-compatible).\\n\\n    Provide your answer in the following format:\\n    - Improved SQL (if applicable)/input SQL:\\n    ```sql\\n    <Improved query>\\n    ```\\n    - Explanation:\\n    ```\\n    <Explanation>\\n    ```\\n\\n    The provided SQL query is incorrect because it does not include any JOINs or WHERE clauses to filter the data. It also does not include any aggregation functions or GROUP BY clause to calculate the net load.\\n\\n    Here is a corrected version of the SQL query:\\n    ```sql\\n    SELECT \\n        t.datetime,\\n        t.value AS 'Day-ahead Price',\\n        r.value AS 'Real-time Price',\\n        lf.value AS 'Load Forecast',\\n        la.value AS 'Actual Load',\\n        wf.value AS 'Wind Forecast',\\n        wa.value AS 'Actual Wind',\\n        sf.value AS 'Solar Forecast',\\n        sa.value AS 'Actual Solar',\\n        t.timezone AS 'Timezone',\\n        CASE\\n            WHEN t.value > r.value THEN 'Day-ahead Price is higher'\\n            WHEN t.value < r.value THEN 'Real-time Price is higher'\\n            ELSE 'Prices are equal'\\n        END AS 'Peak Classification',\\n        (lf.value + la.value + wf.value + wa.value + sf.value + sa.value) AS 'Net Load'\\n    FROM \\n        table_name t\\n    JOIN \\n        table_name r ON t.datetime = r.datetime\\n    JOIN \\n        table_name lf ON t.datetime = lf.datetime\\n    JOIN \\n        table_name la ON t.datetime = la.datetime\\n    JOIN \\n        table_name wf ON t.datetime = wf.datetime\\n    JOIN \\n        table_name wa ON t.datetime = wa.datetime\\n    JOIN \\n        table_name sf ON t.datetime = sf.datetime\\n    JOIN \\n        table_name sa ON t.datetime = sa.datetime\\n    WHERE \\n        t.nodeid = 10000697078\\n        AND lf.datatypeid = 19060\\n        AND la.datatypeid = 19060\\n        AND wf.datatypeid = 9285\\n        AND wa.datatypeid = 16\\n        AND sf.datatypeid = 662\\n        AND sa.datatypeid = 650\\n        AND wf.objectid = 10000712973\\n        AND wa.objectid = 10000712973\\n        AND sf.objectid = 10000712973\\n        AND sa.objectid = 10000712973\\n        AND t.datetime >= '2022-10-01 00:00:00'\\n        AND t.datetime < '2022-10-02 00:00:00'\\n    ORDER BY \\n        t.datetime;\\n    ```\\n    Explanation:\\n    This query joins the tables on the datetime field and filters the data based on the nodeid, datatypeid, and objectid. It also calculates the net load by summing up the forecast and actual values. The peak classification is determined based on the day-ahead and real-time prices. The query also includes a timezone field to align with ERCOT's timezone.\\n\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/swsingh/ipykernel_792359/2912785296.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['final_query'] = final_query\n"
     ]
    }
   ],
   "source": [
    "df1['final_query'] = final_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instance_id</th>\n",
       "      <th>generated_sql</th>\n",
       "      <th>nl_query</th>\n",
       "      <th>db</th>\n",
       "      <th>external_knowledge</th>\n",
       "      <th>refined_sql</th>\n",
       "      <th>refined_sql_cleaned</th>\n",
       "      <th>final_query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>sf_bq052</td>\n",
       "      <td>SELECT \\n    p.id AS patent_id,\\n    p.title A...</td>\n",
       "      <td>Retrieve the following information for U.S. pa...</td>\n",
       "      <td>PATENTSVIEW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SELECT \\n    p.id AS patent_id,\\n    p.title A...</td>\n",
       "      <td>SELECT p.id AS patent_id, p.title AS patent_ti...</td>\n",
       "      <td>SELECT p.id AS patent_id, p.title AS patent_ti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>sf_bq101</td>\n",
       "      <td>SELECT \\n    package_name,\\n    COUNT(*) AS oc...</td>\n",
       "      <td>From GitHub Repos contents, how can we identif...</td>\n",
       "      <td>GITHUB_REPOS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SELECT \\n    package_name,\\n    COUNT(*) AS oc...</td>\n",
       "      <td>SELECT package_name, COUNT(*) AS occurrence_co...</td>\n",
       "      <td>&lt;Improved query&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>bq031</td>\n",
       "      <td>SELECT \\n    DATE_TRUNC('day', timestamp) AS d...</td>\n",
       "      <td>Provide the daily weather data for Rochester f...</td>\n",
       "      <td>noaa_data</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SELECT \\n    date,\\n    temperature,\\n    prec...</td>\n",
       "      <td>SELECT date, temperature, precipitation, wind_...</td>\n",
       "      <td>SELECT date, temperature, precipitation, wind_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>bq293</td>\n",
       "      <td>SELECT \\r\\n    zip_code, \\r\\n    COUNT(*) AS t...</td>\n",
       "      <td>I want to analyze New York City yellow taxi tr...</td>\n",
       "      <td>new_york_geo</td>\n",
       "      <td>functions_st_contains.md</td>\n",
       "      <td># Refine the following SQL query using externa...</td>\n",
       "      <td># Refine the following SQL query using externa...</td>\n",
       "      <td>&lt;Improved query&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>sf_bq131</td>\n",
       "      <td>SELECT statement with the COUNT function to co...</td>\n",
       "      <td>What is the number of bus stops for the bus ne...</td>\n",
       "      <td>GEO_OPENSTREETMAP</td>\n",
       "      <td>functions_st_dwithin.md</td>\n",
       "      <td>SELECT COUNT(*) \\nFROM (\\n  SELECT \\n    STOP_...</td>\n",
       "      <td>SELECT COUNT(*) FROM ( SELECT STOP_ID, NAME, S...</td>\n",
       "      <td>&lt;Improved query&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>sf_bq410</td>\n",
       "      <td>SELECT`, `FROM`, `WHERE`, `GROUP BY`, `ORDER B...</td>\n",
       "      <td>Find the top 3 states with the smallest adjust...</td>\n",
       "      <td>CENSUS_BUREAU_ACS_2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SELECT\\n    STATE_NAME,\\n    AGGREGATE_VALUE,\\...</td>\n",
       "      <td>SELECT STATE_NAME, AGGREGATE_VALUE, TRACT_CODE...</td>\n",
       "      <td>SELECT \\n        STATE_NAME, \\n        SUM(CAS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>sf_bq253</td>\n",
       "      <td>SELECT \\n    r.name AS relation_name,\\n    f.f...</td>\n",
       "      <td>Find the name of the OpenStreetMap relation th...</td>\n",
       "      <td>GEO_OPENSTREETMAP</td>\n",
       "      <td>functions_st_dwithin.md</td>\n",
       "      <td># Refine the following SQL query using externa...</td>\n",
       "      <td># Refine the following SQL query using externa...</td>\n",
       "      <td>SELECT relation_name\\n    FROM planet_features...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>sf_bq250</td>\n",
       "      <td>SELECT \\r\\n    g.id AS grid_id,\\r\\n    g.name ...</td>\n",
       "      <td>Based on the most recent 1km population grid d...</td>\n",
       "      <td>GEO_OPENSTREETMAP_WORLDPOP</td>\n",
       "      <td>OpenStreetMap_data_in_layered_GIS_format.md</td>\n",
       "      <td>SELECT \\r\\n    g.id AS grid_id,\\r\\n    g.name ...</td>\n",
       "      <td>SELECT g.id AS grid_id, g.name AS grid_name, s...</td>\n",
       "      <td>SELECT g.id AS grid_id, g.name AS grid_name, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>sf_bq342</td>\n",
       "      <td>SELECT AVG(transaction_value) AS avg_change\\r\\...</td>\n",
       "      <td>What is the difference between the average hou...</td>\n",
       "      <td>CRYPTO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SELECT AVG(transaction_value) AS avg_change\\r\\...</td>\n",
       "      <td>SELECT AVG(transaction_value) AS avg_change FR...</td>\n",
       "      <td>&lt;Improved query&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>sf_bq444</td>\n",
       "      <td>SELECT \\n    t.block_timestamp,\\n    t.transac...</td>\n",
       "      <td>Can you pull the blockchain timestamp, block n...</td>\n",
       "      <td>CRYPTO</td>\n",
       "      <td>ethereum_logs_and_events_overview.md</td>\n",
       "      <td>SELECT \\n    t.block_timestamp,\\n    t.transac...</td>\n",
       "      <td>SELECT t.block_timestamp, t.transaction_hash, ...</td>\n",
       "      <td>SELECT t.block_timestamp, t.transaction_hash, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>sf_bq057</td>\n",
       "      <td>SELECT \\n    MONTH(CURRENT_DATE) AS Month,\\n  ...</td>\n",
       "      <td>Which month (e.g., 3 for March) in 2021 witnes...</td>\n",
       "      <td>CRYPTO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SELECT \\n    MONTH(CURRENT_DATE) AS Month,\\n  ...</td>\n",
       "      <td>SELECT MONTH(CURRENT_DATE) AS Month, MAX(TIME_...</td>\n",
       "      <td>SELECT MONTH(date) AS Month,\\n           ROUND...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>sf_bq136</td>\n",
       "      <td>SELECT \\n    t1.tx_from,\\n    t1.tx_intermedia...</td>\n",
       "      <td>Find all exactly 2-hop transaction paths on Zi...</td>\n",
       "      <td>CRYPTO</td>\n",
       "      <td>NaN</td>\n",
       "      <td># Refine the following SQL query using externa...</td>\n",
       "      <td># Refine the following SQL query using externa...</td>\n",
       "      <td>&lt;Improved query&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>sf_bq259</td>\n",
       "      <td>SELECT \\r\\n    MONTH(purchase_date) AS month,\\...</td>\n",
       "      <td>Using data up to the end of 2022 and organized...</td>\n",
       "      <td>THELOOK_ECOMMERCE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SELECT \\r\\n    month,\\r\\n    num_users,\\r\\n   ...</td>\n",
       "      <td>SELECT month, num_users, first_month_purchases...</td>\n",
       "      <td>SELECT \\n        month, \\n        num_users, \\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>bq088</td>\n",
       "      <td>SELECT \\n    DATE_FORMAT(date, '%Y-%m') AS Dat...</td>\n",
       "      <td>Please calculate the average levels of anxiety...</td>\n",
       "      <td>covid19_symptom_search</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SELECT \\n    DATE_FORMAT(date, '%Y-%m') AS Dat...</td>\n",
       "      <td>SELECT DATE_FORMAT(date, '%Y-%m') AS Date, cou...</td>\n",
       "      <td>SELECT DATE_FORMAT(date, '%Y-%m') AS Date, cou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>sf_bq058</td>\n",
       "      <td>create a script in Python that connects to the...</td>\n",
       "      <td>Retrieve all finalized deposits into Optimism ...</td>\n",
       "      <td>GOOG_BLOCKCHAIN</td>\n",
       "      <td>optimism_standard_bridge_contract.md</td>\n",
       "      <td>create a script in Python that connects to the...</td>\n",
       "      <td>create a script in Python that connects to the...</td>\n",
       "      <td>&lt;Improved query&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>bq067</td>\n",
       "      <td>create a labeled dataset from the National Hig...</td>\n",
       "      <td>I want to create a labeled dataset from the Na...</td>\n",
       "      <td>nhtsa_traffic_fatalities</td>\n",
       "      <td>nhtsa_traffic_fatalities.md</td>\n",
       "      <td>create a labeled dataset from the National Hig...</td>\n",
       "      <td>create a labeled dataset from the National Hig...</td>\n",
       "      <td>SELECT \\n        state_number,\\n        body_t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>bq041</td>\n",
       "      <td>SELECT \\n    DATE_FORMAT(creation_date, '%Y-%m...</td>\n",
       "      <td>Compute the monthly statistics for new StackOv...</td>\n",
       "      <td>stackoverflow</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SELECT \\n    DATE_FORMAT(creation_date, '%Y-%m...</td>\n",
       "      <td>SELECT DATE_FORMAT(creation_date, '%Y-%m') AS ...</td>\n",
       "      <td>SELECT DATE_FORMAT(creation_date, '%Y-%m') AS ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>bq304</td>\n",
       "      <td>select the top 50 questions ranked by view cou...</td>\n",
       "      <td>Retrieve the top 50 most viewed questions for ...</td>\n",
       "      <td>stackoverflow</td>\n",
       "      <td>NaN</td>\n",
       "      <td>select the top 50 questions ranked by view cou...</td>\n",
       "      <td>select the top 50 questions ranked by view cou...</td>\n",
       "      <td>SELECT t1.title, t1.body, t1.views\\n    FROM (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>sf_bq460</td>\n",
       "      <td>SELECT id, date, title, cosine_similarity_scor...</td>\n",
       "      <td>Please process the articles from the 'nature' ...</td>\n",
       "      <td>WORD_VECTORS_US</td>\n",
       "      <td>tokenize_func.md</td>\n",
       "      <td>SELECT id, date, title, cosine_similarity_scor...</td>\n",
       "      <td>SELECT id, date, title, cosine_similarity_scor...</td>\n",
       "      <td>&lt;Improved query&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>sf_bq141</td>\n",
       "      <td>select patients from the 'TCGA_bioclin_v0.Clin...</td>\n",
       "      <td>Using the TCGA-KIRP dataset, select patients f...</td>\n",
       "      <td>TCGA_HG38_DATA_V0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SELECT \\n    tcga_bioclin_v0.clinical_stage,\\n...</td>\n",
       "      <td>SELECT tcga_bioclin_v0.clinical_stage, tcga_hg...</td>\n",
       "      <td>SELECT tcga_bioclin_v0.clinical_stage, tcga_hg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>sf_bq163</td>\n",
       "      <td>SELECT \\r\\n    g1.gene_name AS gene1,\\r\\n    g...</td>\n",
       "      <td>Which 20 genes in the HTAN scRNAseq MSK-SCLC c...</td>\n",
       "      <td>HTAN_2</td>\n",
       "      <td>NaN</td>\n",
       "      <td># Refine the following SQL query using externa...</td>\n",
       "      <td># Refine the following SQL query using externa...</td>\n",
       "      <td>SELECT \\n        gene,\\n        AVG(CASE WHEN ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>bq165</td>\n",
       "      <td>SELECT \\n    chromosome,\\n    start_position,\\...</td>\n",
       "      <td>Can you use CytoConverter genomic coordinates ...</td>\n",
       "      <td>mitelman</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SELECT \\n    chromosome,\\n    start_position,\\...</td>\n",
       "      <td>SELECT chromosome, start_position, end_positio...</td>\n",
       "      <td>SELECT \\n        chromosome, \\n        start_p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>bq451</td>\n",
       "      <td>SELECT \\r\\n    s.sample_id,\\r\\n    COUNT(DISTI...</td>\n",
       "      <td>Extract genotype data for single nucleotide po...</td>\n",
       "      <td>_1000_genomes</td>\n",
       "      <td>1000_genomes_alleles_type.md</td>\n",
       "      <td># Refine the following SQL query using externa...</td>\n",
       "      <td># Refine the following SQL query using externa...</td>\n",
       "      <td>SELECT\\n        sample_id,\\n        COUNT(*) A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>bq452</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Identify variants on chromosome 12 and, for ea...</td>\n",
       "      <td>_1000_genomes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SELECT\\n        start_position,\\n        end_p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>bq430</td>\n",
       "      <td>update them.\\r\\n\\r\\nHere's the SQL query:\\r\\n\\...</td>\n",
       "      <td>Find pairs of different molecules tested in th...</td>\n",
       "      <td>ebi_chembl</td>\n",
       "      <td>chembl.md</td>\n",
       "      <td># Refine the following SQL query using externa...</td>\n",
       "      <td># Refine the following SQL query using externa...</td>\n",
       "      <td>SELECT\\n        MAX(mol1.heavy_atom_count) AS ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>sf_bq456</td>\n",
       "      <td>SELECT \\n    P.PatientID,\\n    P.StudyInstance...</td>\n",
       "      <td>Please retrieve from the dicom_all table each ...</td>\n",
       "      <td>IDC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SELECT \\n    P.PatientID,\\n    P.StudyInstance...</td>\n",
       "      <td>SELECT P.PatientID, P.StudyInstanceUID, P.Stud...</td>\n",
       "      <td>SELECT P.PatientID, P.StudyInstanceUID, P.Stud...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>bq330</td>\n",
       "      <td>SELECT b.zip_code, COUNT(b.block_group) AS ban...</td>\n",
       "      <td>Which Colorado zip code has the highest concen...</td>\n",
       "      <td>fda</td>\n",
       "      <td>overlap_ratio.md</td>\n",
       "      <td>SELECT b.zip_code, COUNT(b.block_group) AS ban...</td>\n",
       "      <td>SELECT b.zip_code, COUNT(b.block_group) AS ban...</td>\n",
       "      <td>SELECT b.zip_code, COUNT(b.block_group) AS ban...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>ga017</td>\n",
       "      <td>SELECT \\n    COUNT(DISTINCT u.user_id) AS user...</td>\n",
       "      <td>How many distinct users viewed the most freque...</td>\n",
       "      <td>ga4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SELECT \\n    COUNT(DISTINCT u.user_id) AS user...</td>\n",
       "      <td>SELECT COUNT(DISTINCT u.user_id) AS user_count...</td>\n",
       "      <td>SELECT COUNT(DISTINCT u.user_id) AS user_count...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>ga011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>What is the page with the second highest total...</td>\n",
       "      <td>ga4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>ga005</td>\n",
       "      <td>SELECT \\n    DATE_FORMAT(first_session_start_e...</td>\n",
       "      <td>Conduct a weekly cohort analysis for user rete...</td>\n",
       "      <td>firebase</td>\n",
       "      <td>retention_rate.md</td>\n",
       "      <td>SELECT \\n    DATE_FORMAT(first_session_start_e...</td>\n",
       "      <td>SELECT DATE_FORMAT(first_session_start_event, ...</td>\n",
       "      <td>WITH user_sessions AS (\\n        SELECT user_i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>local060</td>\n",
       "      <td>select only those cities where total sales (wi...</td>\n",
       "      <td>In the United States, for Q4 2019 and Q4 2020,...</td>\n",
       "      <td>complex_oracle</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SELECT \\n    s.product_id,\\n    s.total_sales,...</td>\n",
       "      <td>SELECT s.product_id, s.total_sales, s.date, SU...</td>\n",
       "      <td>SELECT \\n        s.product_id, \\n        s.tot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>local061</td>\n",
       "      <td>SELECT \\n    product_name,\\n    AVG(monthly_sa...</td>\n",
       "      <td>What is the average projected monthly sales in...</td>\n",
       "      <td>complex_oracle</td>\n",
       "      <td>projection_calculation.md</td>\n",
       "      <td>SELECT \\n    product_name,\\n    AVG(monthly_sa...</td>\n",
       "      <td>SELECT product_name, AVG(monthly_sales) AS avg...</td>\n",
       "      <td>SELECT \\n        product_name, \\n        AVG(m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>local297</td>\n",
       "      <td>SELECT \\r\\n    customer_id,\\r\\n    month_of_mo...</td>\n",
       "      <td>For each customer, group all deposits and with...</td>\n",
       "      <td>bank_sales_trading</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SELECT \\r\\n    customer_id,\\r\\n    month_of_mo...</td>\n",
       "      <td>SELECT customer_id, month_of_month, SUM(deposi...</td>\n",
       "      <td>SELECT customer_id, month_of_month, \\n        ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>local157</td>\n",
       "      <td>SELECT \\n    t.ticker,\\n    t.date,\\n    SUM(t...</td>\n",
       "      <td>Using the \"bitcoin_prices\" table, please calcu...</td>\n",
       "      <td>bank_sales_trading</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SELECT \\n    t.ticker,\\n    t.date,\\n    SUM(t...</td>\n",
       "      <td>SELECT t.ticker, t.date, SUM(t.amount) AS tota...</td>\n",
       "      <td>SELECT \\n        t.ticker, \\n        t.date, \\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>local171</td>\n",
       "      <td>SELECT \\n    l.name AS legislator_name,\\n    C...</td>\n",
       "      <td>For male legislators from Louisiana, how many ...</td>\n",
       "      <td>city_legislation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SELECT \\n    l.name AS legislator_name,\\n    C...</td>\n",
       "      <td>SELECT l.name AS legislator_name, COUNT(DISTIN...</td>\n",
       "      <td>SELECT \\n        l.name AS legislator_name, \\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>local170</td>\n",
       "      <td>SELECT legislators.state_id, retention_rate, \\...</td>\n",
       "      <td>Identify the state abbreviations where, for bo...</td>\n",
       "      <td>city_legislation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SELECT legislators.state_id, retention_rate, \\...</td>\n",
       "      <td>SELECT legislators.state_id, retention_rate, C...</td>\n",
       "      <td>SELECT \\n        l.state_id, \\n        r.reten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>local228</td>\n",
       "      <td>SELECT \\n    ipl_seasons.player_id,\\n    batsm...</td>\n",
       "      <td>For each IPL season, identify the top three ba...</td>\n",
       "      <td>IPL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SELECT \\n    ipl_seasons.player_id,\\n    batsm...</td>\n",
       "      <td>SELECT ipl_seasons.player_id, batsman_1.battin...</td>\n",
       "      <td>SELECT ipl_seasons.season_id, batsman_1.player...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>local259</td>\n",
       "      <td>SELECT \\n    m.player_id AS player_id,\\n    m....</td>\n",
       "      <td>For each player, list their ID, name, their mo...</td>\n",
       "      <td>IPL</td>\n",
       "      <td>baseball_game_special_words_definition.md</td>\n",
       "      <td># Refine the following SQL query using externa...</td>\n",
       "      <td># Refine the following SQL query using externa...</td>\n",
       "      <td>SELECT \\n        player_id,\\n        player_na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>sf041</td>\n",
       "      <td>SELECT \\r\\n    T1.date AS date,\\r\\n    T1.hour...</td>\n",
       "      <td>Produce a report for ERCOT on October 1, 2022,...</td>\n",
       "      <td>YES_ENERGY__SAMPLE_DATA</td>\n",
       "      <td>ERCOT_Daily_Market_Dynamics_Report.md</td>\n",
       "      <td># Refine the following SQL query using externa...</td>\n",
       "      <td># Refine the following SQL query using externa...</td>\n",
       "      <td>SELECT \\n        t.datetime,\\n        t.value ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    instance_id                                      generated_sql  \\\n",
       "15     sf_bq052  SELECT \\n    p.id AS patent_id,\\n    p.title A...   \n",
       "17     sf_bq101  SELECT \\n    package_name,\\n    COUNT(*) AS oc...   \n",
       "33        bq031  SELECT \\n    DATE_TRUNC('day', timestamp) AS d...   \n",
       "39        bq293  SELECT \\r\\n    zip_code, \\r\\n    COUNT(*) AS t...   \n",
       "40     sf_bq131  SELECT statement with the COUNT function to co...   \n",
       "43     sf_bq410  SELECT`, `FROM`, `WHERE`, `GROUP BY`, `ORDER B...   \n",
       "44     sf_bq253  SELECT \\n    r.name AS relation_name,\\n    f.f...   \n",
       "48     sf_bq250  SELECT \\r\\n    g.id AS grid_id,\\r\\n    g.name ...   \n",
       "50     sf_bq342  SELECT AVG(transaction_value) AS avg_change\\r\\...   \n",
       "51     sf_bq444  SELECT \\n    t.block_timestamp,\\n    t.transac...   \n",
       "54     sf_bq057  SELECT \\n    MONTH(CURRENT_DATE) AS Month,\\n  ...   \n",
       "58     sf_bq136  SELECT \\n    t1.tx_from,\\n    t1.tx_intermedia...   \n",
       "81     sf_bq259  SELECT \\r\\n    MONTH(purchase_date) AS month,\\...   \n",
       "93        bq088  SELECT \\n    DATE_FORMAT(date, '%Y-%m') AS Dat...   \n",
       "106    sf_bq058  create a script in Python that connects to the...   \n",
       "119       bq067  create a labeled dataset from the National Hig...   \n",
       "123       bq041  SELECT \\n    DATE_FORMAT(creation_date, '%Y-%m...   \n",
       "127       bq304  select the top 50 questions ranked by view cou...   \n",
       "135    sf_bq460  SELECT id, date, title, cosine_similarity_scor...   \n",
       "155    sf_bq141  select patients from the 'TCGA_bioclin_v0.Clin...   \n",
       "163    sf_bq163  SELECT \\r\\n    g1.gene_name AS gene1,\\r\\n    g...   \n",
       "165       bq165  SELECT \\n    chromosome,\\n    start_position,\\...   \n",
       "168       bq451  SELECT \\r\\n    s.sample_id,\\r\\n    COUNT(DISTI...   \n",
       "169       bq452                                                NaN   \n",
       "175       bq430  update them.\\r\\n\\r\\nHere's the SQL query:\\r\\n\\...   \n",
       "183    sf_bq456  SELECT \\n    P.PatientID,\\n    P.StudyInstance...   \n",
       "185       bq330  SELECT b.zip_code, COUNT(b.block_group) AS ban...   \n",
       "195       ga017  SELECT \\n    COUNT(DISTINCT u.user_id) AS user...   \n",
       "201       ga011                                                NaN   \n",
       "203       ga005  SELECT \\n    DATE_FORMAT(first_session_start_e...   \n",
       "220    local060  select only those cities where total sales (wi...   \n",
       "222    local061  SELECT \\n    product_name,\\n    AVG(monthly_sa...   \n",
       "232    local297  SELECT \\r\\n    customer_id,\\r\\n    month_of_mo...   \n",
       "246    local157  SELECT \\n    t.ticker,\\n    t.date,\\n    SUM(t...   \n",
       "248    local171  SELECT \\n    l.name AS legislator_name,\\n    C...   \n",
       "249    local170  SELECT legislators.state_id, retention_rate, \\...   \n",
       "255    local228  SELECT \\n    ipl_seasons.player_id,\\n    batsm...   \n",
       "259    local259  SELECT \\n    m.player_id AS player_id,\\n    m....   \n",
       "279       sf041  SELECT \\r\\n    T1.date AS date,\\r\\n    T1.hour...   \n",
       "\n",
       "                                              nl_query  \\\n",
       "15   Retrieve the following information for U.S. pa...   \n",
       "17   From GitHub Repos contents, how can we identif...   \n",
       "33   Provide the daily weather data for Rochester f...   \n",
       "39   I want to analyze New York City yellow taxi tr...   \n",
       "40   What is the number of bus stops for the bus ne...   \n",
       "43   Find the top 3 states with the smallest adjust...   \n",
       "44   Find the name of the OpenStreetMap relation th...   \n",
       "48   Based on the most recent 1km population grid d...   \n",
       "50   What is the difference between the average hou...   \n",
       "51   Can you pull the blockchain timestamp, block n...   \n",
       "54   Which month (e.g., 3 for March) in 2021 witnes...   \n",
       "58   Find all exactly 2-hop transaction paths on Zi...   \n",
       "81   Using data up to the end of 2022 and organized...   \n",
       "93   Please calculate the average levels of anxiety...   \n",
       "106  Retrieve all finalized deposits into Optimism ...   \n",
       "119  I want to create a labeled dataset from the Na...   \n",
       "123  Compute the monthly statistics for new StackOv...   \n",
       "127  Retrieve the top 50 most viewed questions for ...   \n",
       "135  Please process the articles from the 'nature' ...   \n",
       "155  Using the TCGA-KIRP dataset, select patients f...   \n",
       "163  Which 20 genes in the HTAN scRNAseq MSK-SCLC c...   \n",
       "165  Can you use CytoConverter genomic coordinates ...   \n",
       "168  Extract genotype data for single nucleotide po...   \n",
       "169  Identify variants on chromosome 12 and, for ea...   \n",
       "175  Find pairs of different molecules tested in th...   \n",
       "183  Please retrieve from the dicom_all table each ...   \n",
       "185  Which Colorado zip code has the highest concen...   \n",
       "195  How many distinct users viewed the most freque...   \n",
       "201  What is the page with the second highest total...   \n",
       "203  Conduct a weekly cohort analysis for user rete...   \n",
       "220  In the United States, for Q4 2019 and Q4 2020,...   \n",
       "222  What is the average projected monthly sales in...   \n",
       "232  For each customer, group all deposits and with...   \n",
       "246  Using the \"bitcoin_prices\" table, please calcu...   \n",
       "248  For male legislators from Louisiana, how many ...   \n",
       "249  Identify the state abbreviations where, for bo...   \n",
       "255  For each IPL season, identify the top three ba...   \n",
       "259  For each player, list their ID, name, their mo...   \n",
       "279  Produce a report for ERCOT on October 1, 2022,...   \n",
       "\n",
       "                             db                           external_knowledge  \\\n",
       "15                  PATENTSVIEW                                          NaN   \n",
       "17                 GITHUB_REPOS                                          NaN   \n",
       "33                    noaa_data                                          NaN   \n",
       "39                 new_york_geo                     functions_st_contains.md   \n",
       "40            GEO_OPENSTREETMAP                      functions_st_dwithin.md   \n",
       "43          CENSUS_BUREAU_ACS_2                                          NaN   \n",
       "44            GEO_OPENSTREETMAP                      functions_st_dwithin.md   \n",
       "48   GEO_OPENSTREETMAP_WORLDPOP  OpenStreetMap_data_in_layered_GIS_format.md   \n",
       "50                       CRYPTO                                          NaN   \n",
       "51                       CRYPTO         ethereum_logs_and_events_overview.md   \n",
       "54                       CRYPTO                                          NaN   \n",
       "58                       CRYPTO                                          NaN   \n",
       "81            THELOOK_ECOMMERCE                                          NaN   \n",
       "93       covid19_symptom_search                                          NaN   \n",
       "106             GOOG_BLOCKCHAIN         optimism_standard_bridge_contract.md   \n",
       "119    nhtsa_traffic_fatalities                  nhtsa_traffic_fatalities.md   \n",
       "123               stackoverflow                                          NaN   \n",
       "127               stackoverflow                                          NaN   \n",
       "135             WORD_VECTORS_US                             tokenize_func.md   \n",
       "155           TCGA_HG38_DATA_V0                                          NaN   \n",
       "163                      HTAN_2                                          NaN   \n",
       "165                    mitelman                                          NaN   \n",
       "168               _1000_genomes                 1000_genomes_alleles_type.md   \n",
       "169               _1000_genomes                                          NaN   \n",
       "175                  ebi_chembl                                    chembl.md   \n",
       "183                         IDC                                          NaN   \n",
       "185                         fda                             overlap_ratio.md   \n",
       "195                         ga4                                          NaN   \n",
       "201                         ga4                                          NaN   \n",
       "203                    firebase                            retention_rate.md   \n",
       "220              complex_oracle                                          NaN   \n",
       "222              complex_oracle                    projection_calculation.md   \n",
       "232          bank_sales_trading                                          NaN   \n",
       "246          bank_sales_trading                                          NaN   \n",
       "248            city_legislation                                          NaN   \n",
       "249            city_legislation                                          NaN   \n",
       "255                         IPL                                          NaN   \n",
       "259                         IPL    baseball_game_special_words_definition.md   \n",
       "279     YES_ENERGY__SAMPLE_DATA        ERCOT_Daily_Market_Dynamics_Report.md   \n",
       "\n",
       "                                           refined_sql  \\\n",
       "15   SELECT \\n    p.id AS patent_id,\\n    p.title A...   \n",
       "17   SELECT \\n    package_name,\\n    COUNT(*) AS oc...   \n",
       "33   SELECT \\n    date,\\n    temperature,\\n    prec...   \n",
       "39   # Refine the following SQL query using externa...   \n",
       "40   SELECT COUNT(*) \\nFROM (\\n  SELECT \\n    STOP_...   \n",
       "43   SELECT\\n    STATE_NAME,\\n    AGGREGATE_VALUE,\\...   \n",
       "44   # Refine the following SQL query using externa...   \n",
       "48   SELECT \\r\\n    g.id AS grid_id,\\r\\n    g.name ...   \n",
       "50   SELECT AVG(transaction_value) AS avg_change\\r\\...   \n",
       "51   SELECT \\n    t.block_timestamp,\\n    t.transac...   \n",
       "54   SELECT \\n    MONTH(CURRENT_DATE) AS Month,\\n  ...   \n",
       "58   # Refine the following SQL query using externa...   \n",
       "81   SELECT \\r\\n    month,\\r\\n    num_users,\\r\\n   ...   \n",
       "93   SELECT \\n    DATE_FORMAT(date, '%Y-%m') AS Dat...   \n",
       "106  create a script in Python that connects to the...   \n",
       "119  create a labeled dataset from the National Hig...   \n",
       "123  SELECT \\n    DATE_FORMAT(creation_date, '%Y-%m...   \n",
       "127  select the top 50 questions ranked by view cou...   \n",
       "135  SELECT id, date, title, cosine_similarity_scor...   \n",
       "155  SELECT \\n    tcga_bioclin_v0.clinical_stage,\\n...   \n",
       "163  # Refine the following SQL query using externa...   \n",
       "165  SELECT \\n    chromosome,\\n    start_position,\\...   \n",
       "168  # Refine the following SQL query using externa...   \n",
       "169                                                NaN   \n",
       "175  # Refine the following SQL query using externa...   \n",
       "183  SELECT \\n    P.PatientID,\\n    P.StudyInstance...   \n",
       "185  SELECT b.zip_code, COUNT(b.block_group) AS ban...   \n",
       "195  SELECT \\n    COUNT(DISTINCT u.user_id) AS user...   \n",
       "201                                                NaN   \n",
       "203  SELECT \\n    DATE_FORMAT(first_session_start_e...   \n",
       "220  SELECT \\n    s.product_id,\\n    s.total_sales,...   \n",
       "222  SELECT \\n    product_name,\\n    AVG(monthly_sa...   \n",
       "232  SELECT \\r\\n    customer_id,\\r\\n    month_of_mo...   \n",
       "246  SELECT \\n    t.ticker,\\n    t.date,\\n    SUM(t...   \n",
       "248  SELECT \\n    l.name AS legislator_name,\\n    C...   \n",
       "249  SELECT legislators.state_id, retention_rate, \\...   \n",
       "255  SELECT \\n    ipl_seasons.player_id,\\n    batsm...   \n",
       "259  # Refine the following SQL query using externa...   \n",
       "279  # Refine the following SQL query using externa...   \n",
       "\n",
       "                                   refined_sql_cleaned  \\\n",
       "15   SELECT p.id AS patent_id, p.title AS patent_ti...   \n",
       "17   SELECT package_name, COUNT(*) AS occurrence_co...   \n",
       "33   SELECT date, temperature, precipitation, wind_...   \n",
       "39   # Refine the following SQL query using externa...   \n",
       "40   SELECT COUNT(*) FROM ( SELECT STOP_ID, NAME, S...   \n",
       "43   SELECT STATE_NAME, AGGREGATE_VALUE, TRACT_CODE...   \n",
       "44   # Refine the following SQL query using externa...   \n",
       "48   SELECT g.id AS grid_id, g.name AS grid_name, s...   \n",
       "50   SELECT AVG(transaction_value) AS avg_change FR...   \n",
       "51   SELECT t.block_timestamp, t.transaction_hash, ...   \n",
       "54   SELECT MONTH(CURRENT_DATE) AS Month, MAX(TIME_...   \n",
       "58   # Refine the following SQL query using externa...   \n",
       "81   SELECT month, num_users, first_month_purchases...   \n",
       "93   SELECT DATE_FORMAT(date, '%Y-%m') AS Date, cou...   \n",
       "106  create a script in Python that connects to the...   \n",
       "119  create a labeled dataset from the National Hig...   \n",
       "123  SELECT DATE_FORMAT(creation_date, '%Y-%m') AS ...   \n",
       "127  select the top 50 questions ranked by view cou...   \n",
       "135  SELECT id, date, title, cosine_similarity_scor...   \n",
       "155  SELECT tcga_bioclin_v0.clinical_stage, tcga_hg...   \n",
       "163  # Refine the following SQL query using externa...   \n",
       "165  SELECT chromosome, start_position, end_positio...   \n",
       "168  # Refine the following SQL query using externa...   \n",
       "169                                                NaN   \n",
       "175  # Refine the following SQL query using externa...   \n",
       "183  SELECT P.PatientID, P.StudyInstanceUID, P.Stud...   \n",
       "185  SELECT b.zip_code, COUNT(b.block_group) AS ban...   \n",
       "195  SELECT COUNT(DISTINCT u.user_id) AS user_count...   \n",
       "201                                                NaN   \n",
       "203  SELECT DATE_FORMAT(first_session_start_event, ...   \n",
       "220  SELECT s.product_id, s.total_sales, s.date, SU...   \n",
       "222  SELECT product_name, AVG(monthly_sales) AS avg...   \n",
       "232  SELECT customer_id, month_of_month, SUM(deposi...   \n",
       "246  SELECT t.ticker, t.date, SUM(t.amount) AS tota...   \n",
       "248  SELECT l.name AS legislator_name, COUNT(DISTIN...   \n",
       "249  SELECT legislators.state_id, retention_rate, C...   \n",
       "255  SELECT ipl_seasons.player_id, batsman_1.battin...   \n",
       "259  # Refine the following SQL query using externa...   \n",
       "279  # Refine the following SQL query using externa...   \n",
       "\n",
       "                                           final_query  \n",
       "15   SELECT p.id AS patent_id, p.title AS patent_ti...  \n",
       "17                                    <Improved query>  \n",
       "33   SELECT date, temperature, precipitation, wind_...  \n",
       "39                                    <Improved query>  \n",
       "40                                    <Improved query>  \n",
       "43   SELECT \\n        STATE_NAME, \\n        SUM(CAS...  \n",
       "44   SELECT relation_name\\n    FROM planet_features...  \n",
       "48   SELECT g.id AS grid_id, g.name AS grid_name, s...  \n",
       "50                                    <Improved query>  \n",
       "51   SELECT t.block_timestamp, t.transaction_hash, ...  \n",
       "54   SELECT MONTH(date) AS Month,\\n           ROUND...  \n",
       "58                                    <Improved query>  \n",
       "81   SELECT \\n        month, \\n        num_users, \\...  \n",
       "93   SELECT DATE_FORMAT(date, '%Y-%m') AS Date, cou...  \n",
       "106                                   <Improved query>  \n",
       "119  SELECT \\n        state_number,\\n        body_t...  \n",
       "123  SELECT DATE_FORMAT(creation_date, '%Y-%m') AS ...  \n",
       "127  SELECT t1.title, t1.body, t1.views\\n    FROM (...  \n",
       "135                                   <Improved query>  \n",
       "155  SELECT tcga_bioclin_v0.clinical_stage, tcga_hg...  \n",
       "163  SELECT \\n        gene,\\n        AVG(CASE WHEN ...  \n",
       "165  SELECT \\n        chromosome, \\n        start_p...  \n",
       "168  SELECT\\n        sample_id,\\n        COUNT(*) A...  \n",
       "169  SELECT\\n        start_position,\\n        end_p...  \n",
       "175  SELECT\\n        MAX(mol1.heavy_atom_count) AS ...  \n",
       "183  SELECT P.PatientID, P.StudyInstanceUID, P.Stud...  \n",
       "185  SELECT b.zip_code, COUNT(b.block_group) AS ban...  \n",
       "195  SELECT COUNT(DISTINCT u.user_id) AS user_count...  \n",
       "201                                                nan  \n",
       "203  WITH user_sessions AS (\\n        SELECT user_i...  \n",
       "220  SELECT \\n        s.product_id, \\n        s.tot...  \n",
       "222  SELECT \\n        product_name, \\n        AVG(m...  \n",
       "232  SELECT customer_id, month_of_month, \\n        ...  \n",
       "246  SELECT \\n        t.ticker, \\n        t.date, \\...  \n",
       "248  SELECT \\n        l.name AS legislator_name, \\n...  \n",
       "249  SELECT \\n        l.state_id, \\n        r.reten...  \n",
       "255  SELECT ipl_seasons.season_id, batsman_1.player...  \n",
       "259  SELECT \\n        player_id,\\n        player_na...  \n",
       "279  SELECT \\n        t.datetime,\\n        t.value ...  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv('refined_spider2_queries_cleaned_basic_final2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_query = []\n",
    "# for i in tqdm(range(df.shape[0])):\n",
    "#     text = df['nl_query'].iloc[i]\n",
    "#     query = df['refined_sql_cleaned'].iloc[i]\n",
    "#     sql_query = llm_chain.run({\"text\": text, \"query\": query})\n",
    "#     sql_blocks = re.findall(r\"```sql(.*?)```\", sql_query, re.DOTALL)\n",
    "#     cleaned_sql = sql_blocks[-1].strip()\n",
    "\n",
    "#     # try:\n",
    "#     #     sql_query = llm_chain.run({\"text\": text, \"query\": query})\n",
    "#     #     sql_blocks = re.findall(r\"```sql(.*?)```\", sql_query, re.DOTALL)\n",
    "#     #     cleaned_sql = sql_blocks[-1].strip() if sql_blocks else \"\"\n",
    "#     # except Exception as e:\n",
    "#     #     print(f\"Error at index {i}: {e}\")\n",
    "#     #     cleaned_sql = \"\"\n",
    "    \n",
    "#     final_query.append(cleaned_sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "547"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['final_query'] = final_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instance_id</th>\n",
       "      <th>generated_sql</th>\n",
       "      <th>nl_query</th>\n",
       "      <th>db</th>\n",
       "      <th>external_knowledge</th>\n",
       "      <th>refined_sql</th>\n",
       "      <th>refined_sql_cleaned</th>\n",
       "      <th>final_query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bq011</td>\n",
       "      <td>create the appropriate SQL query.\\n\\nHowever, ...</td>\n",
       "      <td>How many distinct pseudo users had positive en...</td>\n",
       "      <td>ga4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SELECT \\n    DATE_TRUNC('month', date) AS mont...</td>\n",
       "      <td>SELECT DATE_TRUNC('month', date) AS month, COU...</td>\n",
       "      <td>&lt;Improved query&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bq010</td>\n",
       "      <td>SELECT \\n    Product,\\n    SUM(Quantity * Reve...</td>\n",
       "      <td>Find the top-selling product among customers w...</td>\n",
       "      <td>ga360</td>\n",
       "      <td>google_analytics_sample.ga_sessions.md</td>\n",
       "      <td>SELECT \\n    Product,\\n    SUM(Quantity * Reve...</td>\n",
       "      <td>SELECT Product, SUM(Quantity * Revenue) AS Tot...</td>\n",
       "      <td>SELECT Product, SUM(Quantity * Revenue) AS Tot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bq009</td>\n",
       "      <td>SELECT t1.total_transaction_revenue, t1.monthl...</td>\n",
       "      <td>Which traffic source has the highest total tra...</td>\n",
       "      <td>ga360</td>\n",
       "      <td>google_analytics_sample.ga_sessions.md</td>\n",
       "      <td>SELECT t1.traffic_source, t1.total_transaction...</td>\n",
       "      <td>SELECT t1.traffic_source, t1.total_transaction...</td>\n",
       "      <td>SELECT traffic_source, MAX(total_transaction_r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bq001</td>\n",
       "      <td>SELECT \\n    T1.visitor_id,\\n    T1.date_of_vi...</td>\n",
       "      <td>For each visitor who made at least one transac...</td>\n",
       "      <td>ga360</td>\n",
       "      <td>google_analytics_sample.ga_sessions.md</td>\n",
       "      <td>SELECT \\n    T1.visitor_id,\\n    T1.date_of_vi...</td>\n",
       "      <td>SELECT T1.visitor_id, T1.date_of_visit, COUNT(...</td>\n",
       "      <td>&lt;Improved query&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bq002</td>\n",
       "      <td>SELECT \\r\\n    t1.source_name,\\r\\n    MAX(t1.r...</td>\n",
       "      <td>During the first half of 2017,  focusing on hi...</td>\n",
       "      <td>ga360</td>\n",
       "      <td>google_analytics_sample.ga_sessions.md</td>\n",
       "      <td>SELECT \\r\\n    t1.source_name,\\r\\n    MAX(t1.r...</td>\n",
       "      <td>SELECT t1.source_name, MAX(t1.revenue) AS max_...</td>\n",
       "      <td>SELECT trafficSource.source AS source_name, MA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>542</th>\n",
       "      <td>sf009</td>\n",
       "      <td>SELECT \\n    b.building_class AS 'Building Typ...</td>\n",
       "      <td>A real estate company needs a detailed side-by...</td>\n",
       "      <td>NETHERLANDS_OPEN_MAP_DATA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SELECT \\n    b.building_class AS 'Building Typ...</td>\n",
       "      <td>SELECT b.building_class AS 'Building Type', b....</td>\n",
       "      <td>&lt;Improved query&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>sf013</td>\n",
       "      <td>SELECT \\n    c.class_name AS Class,\\n    s.sub...</td>\n",
       "      <td>Compare the total road lengths in Amsterdam an...</td>\n",
       "      <td>NETHERLANDS_OPEN_MAP_DATA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SELECT \\n    c.class_name AS Class,\\n    s.sub...</td>\n",
       "      <td>SELECT c.class_name AS Class, s.sub_class_name...</td>\n",
       "      <td>&lt;Improved query&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>sf041</td>\n",
       "      <td>SELECT \\r\\n    T1.date AS date,\\r\\n    T1.hour...</td>\n",
       "      <td>Produce a report for ERCOT on October 1, 2022,...</td>\n",
       "      <td>YES_ENERGY__SAMPLE_DATA</td>\n",
       "      <td>ERCOT_Daily_Market_Dynamics_Report.md</td>\n",
       "      <td># Refine the following SQL query using externa...</td>\n",
       "      <td># Refine the following SQL query using externa...</td>\n",
       "      <td>&lt;Improved query&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>sf011</td>\n",
       "      <td>SELECT \\n    census_value,\\n    CASE \\n       ...</td>\n",
       "      <td>Determine the population distribution within e...</td>\n",
       "      <td>CENSUS_GALAXY__ZIP_CODE_TO_BLOCK_GROUP_SAMPLE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SELECT \\n    census_value,\\n    CASE \\n       ...</td>\n",
       "      <td>SELECT census_value, CASE WHEN state_county_tr...</td>\n",
       "      <td>&lt;Improved query&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>sf014</td>\n",
       "      <td>SELECT \\n    zip_code,\\n    SUM(commuters) AS ...</td>\n",
       "      <td>What is the New York State ZIP code with the h...</td>\n",
       "      <td>CENSUS_GALAXY__AIML_MODEL_DATA_ENRICHMENT_SAMPLE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SELECT \\n    zip_code,\\n    SUM(commuters) AS ...</td>\n",
       "      <td>SELECT zip_code, SUM(commuters) AS total_commu...</td>\n",
       "      <td>SELECT zip_code, SUM(commuters) AS total_commu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>547 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    instance_id                                      generated_sql  \\\n",
       "0         bq011  create the appropriate SQL query.\\n\\nHowever, ...   \n",
       "1         bq010  SELECT \\n    Product,\\n    SUM(Quantity * Reve...   \n",
       "2         bq009  SELECT t1.total_transaction_revenue, t1.monthl...   \n",
       "3         bq001  SELECT \\n    T1.visitor_id,\\n    T1.date_of_vi...   \n",
       "4         bq002  SELECT \\r\\n    t1.source_name,\\r\\n    MAX(t1.r...   \n",
       "..          ...                                                ...   \n",
       "542       sf009  SELECT \\n    b.building_class AS 'Building Typ...   \n",
       "543       sf013  SELECT \\n    c.class_name AS Class,\\n    s.sub...   \n",
       "544       sf041  SELECT \\r\\n    T1.date AS date,\\r\\n    T1.hour...   \n",
       "545       sf011  SELECT \\n    census_value,\\n    CASE \\n       ...   \n",
       "546       sf014  SELECT \\n    zip_code,\\n    SUM(commuters) AS ...   \n",
       "\n",
       "                                              nl_query  \\\n",
       "0    How many distinct pseudo users had positive en...   \n",
       "1    Find the top-selling product among customers w...   \n",
       "2    Which traffic source has the highest total tra...   \n",
       "3    For each visitor who made at least one transac...   \n",
       "4    During the first half of 2017,  focusing on hi...   \n",
       "..                                                 ...   \n",
       "542  A real estate company needs a detailed side-by...   \n",
       "543  Compare the total road lengths in Amsterdam an...   \n",
       "544  Produce a report for ERCOT on October 1, 2022,...   \n",
       "545  Determine the population distribution within e...   \n",
       "546  What is the New York State ZIP code with the h...   \n",
       "\n",
       "                                                   db  \\\n",
       "0                                                 ga4   \n",
       "1                                               ga360   \n",
       "2                                               ga360   \n",
       "3                                               ga360   \n",
       "4                                               ga360   \n",
       "..                                                ...   \n",
       "542                         NETHERLANDS_OPEN_MAP_DATA   \n",
       "543                         NETHERLANDS_OPEN_MAP_DATA   \n",
       "544                           YES_ENERGY__SAMPLE_DATA   \n",
       "545     CENSUS_GALAXY__ZIP_CODE_TO_BLOCK_GROUP_SAMPLE   \n",
       "546  CENSUS_GALAXY__AIML_MODEL_DATA_ENRICHMENT_SAMPLE   \n",
       "\n",
       "                         external_knowledge  \\\n",
       "0                                       NaN   \n",
       "1    google_analytics_sample.ga_sessions.md   \n",
       "2    google_analytics_sample.ga_sessions.md   \n",
       "3    google_analytics_sample.ga_sessions.md   \n",
       "4    google_analytics_sample.ga_sessions.md   \n",
       "..                                      ...   \n",
       "542                                     NaN   \n",
       "543                                     NaN   \n",
       "544   ERCOT_Daily_Market_Dynamics_Report.md   \n",
       "545                                     NaN   \n",
       "546                                     NaN   \n",
       "\n",
       "                                           refined_sql  \\\n",
       "0    SELECT \\n    DATE_TRUNC('month', date) AS mont...   \n",
       "1    SELECT \\n    Product,\\n    SUM(Quantity * Reve...   \n",
       "2    SELECT t1.traffic_source, t1.total_transaction...   \n",
       "3    SELECT \\n    T1.visitor_id,\\n    T1.date_of_vi...   \n",
       "4    SELECT \\r\\n    t1.source_name,\\r\\n    MAX(t1.r...   \n",
       "..                                                 ...   \n",
       "542  SELECT \\n    b.building_class AS 'Building Typ...   \n",
       "543  SELECT \\n    c.class_name AS Class,\\n    s.sub...   \n",
       "544  # Refine the following SQL query using externa...   \n",
       "545  SELECT \\n    census_value,\\n    CASE \\n       ...   \n",
       "546  SELECT \\n    zip_code,\\n    SUM(commuters) AS ...   \n",
       "\n",
       "                                   refined_sql_cleaned  \\\n",
       "0    SELECT DATE_TRUNC('month', date) AS month, COU...   \n",
       "1    SELECT Product, SUM(Quantity * Revenue) AS Tot...   \n",
       "2    SELECT t1.traffic_source, t1.total_transaction...   \n",
       "3    SELECT T1.visitor_id, T1.date_of_visit, COUNT(...   \n",
       "4    SELECT t1.source_name, MAX(t1.revenue) AS max_...   \n",
       "..                                                 ...   \n",
       "542  SELECT b.building_class AS 'Building Type', b....   \n",
       "543  SELECT c.class_name AS Class, s.sub_class_name...   \n",
       "544  # Refine the following SQL query using externa...   \n",
       "545  SELECT census_value, CASE WHEN state_county_tr...   \n",
       "546  SELECT zip_code, SUM(commuters) AS total_commu...   \n",
       "\n",
       "                                           final_query  \n",
       "0                                     <Improved query>  \n",
       "1    SELECT Product, SUM(Quantity * Revenue) AS Tot...  \n",
       "2    SELECT traffic_source, MAX(total_transaction_r...  \n",
       "3                                     <Improved query>  \n",
       "4    SELECT trafficSource.source AS source_name, MA...  \n",
       "..                                                 ...  \n",
       "542                                   <Improved query>  \n",
       "543                                   <Improved query>  \n",
       "544                                   <Improved query>  \n",
       "545                                   <Improved query>  \n",
       "546  SELECT zip_code, SUM(commuters) AS total_commu...  \n",
       "\n",
       "[547 rows x 8 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instance_id</th>\n",
       "      <th>generated_sql</th>\n",
       "      <th>nl_query</th>\n",
       "      <th>db</th>\n",
       "      <th>external_knowledge</th>\n",
       "      <th>refined_sql</th>\n",
       "      <th>refined_sql_cleaned</th>\n",
       "      <th>final_query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bq011</td>\n",
       "      <td>create the appropriate SQL query.\\n\\nHowever, ...</td>\n",
       "      <td>How many distinct pseudo users had positive en...</td>\n",
       "      <td>ga4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SELECT \\n    DATE_TRUNC('month', date) AS mont...</td>\n",
       "      <td>SELECT DATE_TRUNC('month', date) AS month, COU...</td>\n",
       "      <td>&lt;Improved query&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bq001</td>\n",
       "      <td>SELECT \\n    T1.visitor_id,\\n    T1.date_of_vi...</td>\n",
       "      <td>For each visitor who made at least one transac...</td>\n",
       "      <td>ga360</td>\n",
       "      <td>google_analytics_sample.ga_sessions.md</td>\n",
       "      <td>SELECT \\n    T1.visitor_id,\\n    T1.date_of_vi...</td>\n",
       "      <td>SELECT T1.visitor_id, T1.date_of_visit, COUNT(...</td>\n",
       "      <td>&lt;Improved query&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bq003</td>\n",
       "      <td>SELECT \\n    DATE_FORMAT(visits.visit_date, '%...</td>\n",
       "      <td>Between April 1 and July 31 of 2017, using the...</td>\n",
       "      <td>ga360</td>\n",
       "      <td>google_analytics_sample.ga_sessions.md</td>\n",
       "      <td>SELECT \\n    DATE_FORMAT(visits.visit_date, '%...</td>\n",
       "      <td>SELECT DATE_FORMAT(visits.visit_date, '%Y-%m')...</td>\n",
       "      <td>&lt;Improved query&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>bq008</td>\n",
       "      <td>SELECT \\n    MAX(`visit_time`) AS `most_visite...</td>\n",
       "      <td>In January 2017, among visitors whose campaign...</td>\n",
       "      <td>ga360</td>\n",
       "      <td>google_analytics_sample.ga_sessions.md</td>\n",
       "      <td>SELECT \\n    MAX(`visit_time`) AS `most_visite...</td>\n",
       "      <td>SELECT MAX(`visit_time`) AS `most_visited_page...</td>\n",
       "      <td>&lt;Improved query&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>bq268</td>\n",
       "      <td>SELECT \\n    MAX(DATEDIFF(day, MAX(last_visit)...</td>\n",
       "      <td>Identify the longest number of days between th...</td>\n",
       "      <td>ga360</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SELECT \\n    MAX(DATEDIFF(day, MAX(last_visit)...</td>\n",
       "      <td>SELECT MAX(DATEDIFF(day, MAX(last_visit), MIN(...</td>\n",
       "      <td>&lt;Improved query&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540</th>\n",
       "      <td>sf029</td>\n",
       "      <td>SELECT \\r\\n    s.date AS date,\\r\\n    s.asin A...</td>\n",
       "      <td>Generate a daily detailed sales report for eac...</td>\n",
       "      <td>AMAZON_VENDOR_ANALYTICS__SAMPLE_DATASET</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SELECT \\r\\n    s.date AS date,\\r\\n    s.asin A...</td>\n",
       "      <td>SELECT s.date AS date, s.asin AS asin, s.progr...</td>\n",
       "      <td>&lt;Improved query&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>542</th>\n",
       "      <td>sf009</td>\n",
       "      <td>SELECT \\n    b.building_class AS 'Building Typ...</td>\n",
       "      <td>A real estate company needs a detailed side-by...</td>\n",
       "      <td>NETHERLANDS_OPEN_MAP_DATA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SELECT \\n    b.building_class AS 'Building Typ...</td>\n",
       "      <td>SELECT b.building_class AS 'Building Type', b....</td>\n",
       "      <td>&lt;Improved query&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>sf013</td>\n",
       "      <td>SELECT \\n    c.class_name AS Class,\\n    s.sub...</td>\n",
       "      <td>Compare the total road lengths in Amsterdam an...</td>\n",
       "      <td>NETHERLANDS_OPEN_MAP_DATA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SELECT \\n    c.class_name AS Class,\\n    s.sub...</td>\n",
       "      <td>SELECT c.class_name AS Class, s.sub_class_name...</td>\n",
       "      <td>&lt;Improved query&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>sf041</td>\n",
       "      <td>SELECT \\r\\n    T1.date AS date,\\r\\n    T1.hour...</td>\n",
       "      <td>Produce a report for ERCOT on October 1, 2022,...</td>\n",
       "      <td>YES_ENERGY__SAMPLE_DATA</td>\n",
       "      <td>ERCOT_Daily_Market_Dynamics_Report.md</td>\n",
       "      <td># Refine the following SQL query using externa...</td>\n",
       "      <td># Refine the following SQL query using externa...</td>\n",
       "      <td>&lt;Improved query&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>sf011</td>\n",
       "      <td>SELECT \\n    census_value,\\n    CASE \\n       ...</td>\n",
       "      <td>Determine the population distribution within e...</td>\n",
       "      <td>CENSUS_GALAXY__ZIP_CODE_TO_BLOCK_GROUP_SAMPLE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SELECT \\n    census_value,\\n    CASE \\n       ...</td>\n",
       "      <td>SELECT census_value, CASE WHEN state_county_tr...</td>\n",
       "      <td>&lt;Improved query&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>281 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    instance_id                                      generated_sql  \\\n",
       "0         bq011  create the appropriate SQL query.\\n\\nHowever, ...   \n",
       "3         bq001  SELECT \\n    T1.visitor_id,\\n    T1.date_of_vi...   \n",
       "5         bq003  SELECT \\n    DATE_FORMAT(visits.visit_date, '%...   \n",
       "7         bq008  SELECT \\n    MAX(`visit_time`) AS `most_visite...   \n",
       "9         bq268  SELECT \\n    MAX(DATEDIFF(day, MAX(last_visit)...   \n",
       "..          ...                                                ...   \n",
       "540       sf029  SELECT \\r\\n    s.date AS date,\\r\\n    s.asin A...   \n",
       "542       sf009  SELECT \\n    b.building_class AS 'Building Typ...   \n",
       "543       sf013  SELECT \\n    c.class_name AS Class,\\n    s.sub...   \n",
       "544       sf041  SELECT \\r\\n    T1.date AS date,\\r\\n    T1.hour...   \n",
       "545       sf011  SELECT \\n    census_value,\\n    CASE \\n       ...   \n",
       "\n",
       "                                              nl_query  \\\n",
       "0    How many distinct pseudo users had positive en...   \n",
       "3    For each visitor who made at least one transac...   \n",
       "5    Between April 1 and July 31 of 2017, using the...   \n",
       "7    In January 2017, among visitors whose campaign...   \n",
       "9    Identify the longest number of days between th...   \n",
       "..                                                 ...   \n",
       "540  Generate a daily detailed sales report for eac...   \n",
       "542  A real estate company needs a detailed side-by...   \n",
       "543  Compare the total road lengths in Amsterdam an...   \n",
       "544  Produce a report for ERCOT on October 1, 2022,...   \n",
       "545  Determine the population distribution within e...   \n",
       "\n",
       "                                                db  \\\n",
       "0                                              ga4   \n",
       "3                                            ga360   \n",
       "5                                            ga360   \n",
       "7                                            ga360   \n",
       "9                                            ga360   \n",
       "..                                             ...   \n",
       "540        AMAZON_VENDOR_ANALYTICS__SAMPLE_DATASET   \n",
       "542                      NETHERLANDS_OPEN_MAP_DATA   \n",
       "543                      NETHERLANDS_OPEN_MAP_DATA   \n",
       "544                        YES_ENERGY__SAMPLE_DATA   \n",
       "545  CENSUS_GALAXY__ZIP_CODE_TO_BLOCK_GROUP_SAMPLE   \n",
       "\n",
       "                         external_knowledge  \\\n",
       "0                                       NaN   \n",
       "3    google_analytics_sample.ga_sessions.md   \n",
       "5    google_analytics_sample.ga_sessions.md   \n",
       "7    google_analytics_sample.ga_sessions.md   \n",
       "9                                       NaN   \n",
       "..                                      ...   \n",
       "540                                     NaN   \n",
       "542                                     NaN   \n",
       "543                                     NaN   \n",
       "544   ERCOT_Daily_Market_Dynamics_Report.md   \n",
       "545                                     NaN   \n",
       "\n",
       "                                           refined_sql  \\\n",
       "0    SELECT \\n    DATE_TRUNC('month', date) AS mont...   \n",
       "3    SELECT \\n    T1.visitor_id,\\n    T1.date_of_vi...   \n",
       "5    SELECT \\n    DATE_FORMAT(visits.visit_date, '%...   \n",
       "7    SELECT \\n    MAX(`visit_time`) AS `most_visite...   \n",
       "9    SELECT \\n    MAX(DATEDIFF(day, MAX(last_visit)...   \n",
       "..                                                 ...   \n",
       "540  SELECT \\r\\n    s.date AS date,\\r\\n    s.asin A...   \n",
       "542  SELECT \\n    b.building_class AS 'Building Typ...   \n",
       "543  SELECT \\n    c.class_name AS Class,\\n    s.sub...   \n",
       "544  # Refine the following SQL query using externa...   \n",
       "545  SELECT \\n    census_value,\\n    CASE \\n       ...   \n",
       "\n",
       "                                   refined_sql_cleaned       final_query  \n",
       "0    SELECT DATE_TRUNC('month', date) AS month, COU...  <Improved query>  \n",
       "3    SELECT T1.visitor_id, T1.date_of_visit, COUNT(...  <Improved query>  \n",
       "5    SELECT DATE_FORMAT(visits.visit_date, '%Y-%m')...  <Improved query>  \n",
       "7    SELECT MAX(`visit_time`) AS `most_visited_page...  <Improved query>  \n",
       "9    SELECT MAX(DATEDIFF(day, MAX(last_visit), MIN(...  <Improved query>  \n",
       "..                                                 ...               ...  \n",
       "540  SELECT s.date AS date, s.asin AS asin, s.progr...  <Improved query>  \n",
       "542  SELECT b.building_class AS 'Building Type', b....  <Improved query>  \n",
       "543  SELECT c.class_name AS Class, s.sub_class_name...  <Improved query>  \n",
       "544  # Refine the following SQL query using externa...  <Improved query>  \n",
       "545  SELECT census_value, CASE WHEN state_county_tr...  <Improved query>  \n",
       "\n",
       "[281 rows x 8 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['final_query']=='<Improved query>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('refined_spider2_queries_cleaned_basic_final.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"refined_spider2_queries_cleaned_basic_final.csv\")\n",
    "df1 = pd.read_csv(\"refined_spider2_queries_cleaned_basic_final1.csv\")\n",
    "df2 = pd.read_csv(\"refined_spider2_queries_cleaned_basic_final2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy original df\n",
    "final_df = df.copy()\n",
    "\n",
    "# Identify unresolved rows in df\n",
    "unresolved_mask_df = final_df[\"final_query\"].isna() | (final_df[\"final_query\"] == \"<Improved query>\")\n",
    "\n",
    "# Fill those unresolved rows with df1 values\n",
    "final_df.loc[unresolved_mask_df, \"final_query\"] = df1[\"final_query\"].values\n",
    "\n",
    "# Re-identify unresolved rows after df1 patch\n",
    "unresolved_mask_df1 = final_df[\"final_query\"].isna() | (final_df[\"final_query\"] == \"<Improved query>\")\n",
    "\n",
    "# Fill those with df2 values\n",
    "final_df.loc[unresolved_mask_df1, \"final_query\"] = df2[\"final_query\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv(\"refined_spider2_queries_cleaned_basic_final_final.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"refined_spider_queries_cleaned_basic_final.csv\")\n",
    "df1 = pd.read_csv(\"refined_spider_queries_cleaned_basic_final1.csv\")\n",
    "df2 = pd.read_csv(\"refined_spider_queries_cleaned_basic_final2.csv\")\n",
    "# Copy original df\n",
    "final_df = df.copy()\n",
    "\n",
    "# Identify unresolved rows in df\n",
    "unresolved_mask_df = final_df[\"final_query\"].isna() | (final_df[\"final_query\"] == \"<Improved query>\")\n",
    "\n",
    "# Fill those unresolved rows with df1 values\n",
    "final_df.loc[unresolved_mask_df, \"final_query\"] = df1[\"final_query\"].values\n",
    "\n",
    "# Re-identify unresolved rows after df1 patch\n",
    "unresolved_mask_df1 = final_df[\"final_query\"].isna() | (final_df[\"final_query\"] == \"<Improved query>\")\n",
    "\n",
    "# Fill those with df2 values\n",
    "final_df.loc[unresolved_mask_df1, \"final_query\"] = df2[\"final_query\"].values\n",
    "final_df.to_csv(\"refined_spider_queries_cleaned_basic_final_final.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instance_id</th>\n",
       "      <th>question</th>\n",
       "      <th>db</th>\n",
       "      <th>initial_sql</th>\n",
       "      <th>refined_sql</th>\n",
       "      <th>final_query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bq011</td>\n",
       "      <td>How many pseudo users were active in the last ...</td>\n",
       "      <td>ga4</td>\n",
       "      <td>Generate an SQL query using the database name ...</td>\n",
       "      <td>SELECT COUNT(*) \\nFROM users \\nWHERE last_acti...</td>\n",
       "      <td>SELECT COUNT(*) \\n    FROM users \\n    WHERE l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bq010</td>\n",
       "      <td>Find the top-selling product among customers w...</td>\n",
       "      <td>ga360</td>\n",
       "      <td>Generate an SQL query using the database name ...</td>\n",
       "      <td>SELECT \\n    s.product_name,\\n    s.sale_price...</td>\n",
       "      <td>SELECT \\n        s.product_name,\\n        s.sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bq009</td>\n",
       "      <td>Which traffic source has the highest total tra...</td>\n",
       "      <td>ga360</td>\n",
       "      <td>Generate an SQL query using the database name ...</td>\n",
       "      <td>SELECT \\n    t1TrafficSourceName AS TrafficSou...</td>\n",
       "      <td>SELECT \\n        t1.TrafficSourceName,\\n      ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bq001</td>\n",
       "      <td>For each visitor who made at least one transac...</td>\n",
       "      <td>ga360</td>\n",
       "      <td>Generate an SQL query using the database name ...</td>\n",
       "      <td>SELECT \\n    DATE_FORMAT(first_visit_date, '%Y...</td>\n",
       "      <td>SELECT \\n        DATE_FORMAT(first_visit_date,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bq002</td>\n",
       "      <td>During the first half of 2017,  focusing on hi...</td>\n",
       "      <td>ga360</td>\n",
       "      <td>Generate an SQL query using the database name ...</td>\n",
       "      <td>SELECT \\r\\n    p.product_name,\\r\\n    MAX(p.re...</td>\n",
       "      <td>SELECT \\n        p.product_name,\\n        MAX(...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  instance_id                                           question     db  \\\n",
       "0       bq011  How many pseudo users were active in the last ...    ga4   \n",
       "1       bq010  Find the top-selling product among customers w...  ga360   \n",
       "2       bq009  Which traffic source has the highest total tra...  ga360   \n",
       "3       bq001  For each visitor who made at least one transac...  ga360   \n",
       "4       bq002  During the first half of 2017,  focusing on hi...  ga360   \n",
       "\n",
       "                                         initial_sql  \\\n",
       "0  Generate an SQL query using the database name ...   \n",
       "1  Generate an SQL query using the database name ...   \n",
       "2  Generate an SQL query using the database name ...   \n",
       "3  Generate an SQL query using the database name ...   \n",
       "4  Generate an SQL query using the database name ...   \n",
       "\n",
       "                                         refined_sql  \\\n",
       "0  SELECT COUNT(*) \\nFROM users \\nWHERE last_acti...   \n",
       "1  SELECT \\n    s.product_name,\\n    s.sale_price...   \n",
       "2  SELECT \\n    t1TrafficSourceName AS TrafficSou...   \n",
       "3  SELECT \\n    DATE_FORMAT(first_visit_date, '%Y...   \n",
       "4  SELECT \\r\\n    p.product_name,\\r\\n    MAX(p.re...   \n",
       "\n",
       "                                         final_query  \n",
       "0  SELECT COUNT(*) \\n    FROM users \\n    WHERE l...  \n",
       "1  SELECT \\n        s.product_name,\\n        s.sa...  \n",
       "2  SELECT \\n        t1.TrafficSourceName,\\n      ...  \n",
       "3  SELECT \\n        DATE_FORMAT(first_visit_date,...  \n",
       "4  SELECT \\n        p.product_name,\\n        MAX(...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('final_refined_partial_30.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "db\n",
       "PATENTS           13\n",
       "ga360             12\n",
       "PATENTS_GOOGLE     4\n",
       "ga4                1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.db.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bonnie\n",
      "Manuela\n",
      "Florence\n",
      "Leona\n",
      "Agnes\n",
      "Nettie\n",
      "Elvira\n",
      "Sadie\n",
      "Annie\n",
      "Mozelle\n"
     ]
    }
   ],
   "source": [
    "from google.oauth2 import service_account\n",
    "from google.cloud import bigquery\n",
    "\n",
    "credential_path = '/isilon/datalake/dma_research/scratch/damalab/Data/Swapnil/Personal/Spider2/spider2-lite/evaluation_suite/bigquery_credential_swapnil.json' # path/to/your/keyfile.json\n",
    "credentials = service_account.Credentials.from_service_account_file(credential_path)\n",
    "client = bigquery.Client(credentials=credentials)\n",
    "\n",
    "# alternatively, you can also set the credential path via environment vairable\n",
    "# import os\n",
    "# os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = \"/path/to/keyfile.json\"\n",
    "# client = bigquery.Client()\n",
    "\n",
    "# Perform a sample query.\n",
    "sql_query = 'SELECT name FROM `bigquery-public-data.usa_names.usa_1910_2013` WHERE state = \"TX\" LIMIT 10'\n",
    "query_job = client.query(sql_query)  # API request\n",
    "rows = query_job.result()  # Waits for query to finish\n",
    "\n",
    "for row in rows:\n",
    "    print(row.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instance_id</th>\n",
       "      <th>question</th>\n",
       "      <th>db</th>\n",
       "      <th>initial_sql</th>\n",
       "      <th>refined_sql</th>\n",
       "      <th>final_query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bq011</td>\n",
       "      <td>How many pseudo users were active in the last ...</td>\n",
       "      <td>ga4</td>\n",
       "      <td>Generate an SQL query using the database name ...</td>\n",
       "      <td>SELECT COUNT(*) \\nFROM users \\nWHERE last_acti...</td>\n",
       "      <td>SELECT COUNT(*) \\n    FROM users \\n    WHERE l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bq010</td>\n",
       "      <td>Find the top-selling product among customers w...</td>\n",
       "      <td>ga360</td>\n",
       "      <td>Generate an SQL query using the database name ...</td>\n",
       "      <td>SELECT \\n    s.product_name,\\n    s.sale_price...</td>\n",
       "      <td>SELECT \\n        s.product_name,\\n        s.sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bq009</td>\n",
       "      <td>Which traffic source has the highest total tra...</td>\n",
       "      <td>ga360</td>\n",
       "      <td>Generate an SQL query using the database name ...</td>\n",
       "      <td>SELECT \\n    t1TrafficSourceName AS TrafficSou...</td>\n",
       "      <td>SELECT \\n        t1.TrafficSourceName,\\n      ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bq001</td>\n",
       "      <td>For each visitor who made at least one transac...</td>\n",
       "      <td>ga360</td>\n",
       "      <td>Generate an SQL query using the database name ...</td>\n",
       "      <td>SELECT \\n    DATE_FORMAT(first_visit_date, '%Y...</td>\n",
       "      <td>SELECT \\n        DATE_FORMAT(first_visit_date,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bq002</td>\n",
       "      <td>During the first half of 2017,  focusing on hi...</td>\n",
       "      <td>ga360</td>\n",
       "      <td>Generate an SQL query using the database name ...</td>\n",
       "      <td>SELECT \\r\\n    p.product_name,\\r\\n    MAX(p.re...</td>\n",
       "      <td>SELECT \\n        p.product_name,\\n        MAX(...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  instance_id                                           question     db  \\\n",
       "0       bq011  How many pseudo users were active in the last ...    ga4   \n",
       "1       bq010  Find the top-selling product among customers w...  ga360   \n",
       "2       bq009  Which traffic source has the highest total tra...  ga360   \n",
       "3       bq001  For each visitor who made at least one transac...  ga360   \n",
       "4       bq002  During the first half of 2017,  focusing on hi...  ga360   \n",
       "\n",
       "                                         initial_sql  \\\n",
       "0  Generate an SQL query using the database name ...   \n",
       "1  Generate an SQL query using the database name ...   \n",
       "2  Generate an SQL query using the database name ...   \n",
       "3  Generate an SQL query using the database name ...   \n",
       "4  Generate an SQL query using the database name ...   \n",
       "\n",
       "                                         refined_sql  \\\n",
       "0  SELECT COUNT(*) \\nFROM users \\nWHERE last_acti...   \n",
       "1  SELECT \\n    s.product_name,\\n    s.sale_price...   \n",
       "2  SELECT \\n    t1TrafficSourceName AS TrafficSou...   \n",
       "3  SELECT \\n    DATE_FORMAT(first_visit_date, '%Y...   \n",
       "4  SELECT \\r\\n    p.product_name,\\r\\n    MAX(p.re...   \n",
       "\n",
       "                                         final_query  \n",
       "0  SELECT COUNT(*) \\n    FROM users \\n    WHERE l...  \n",
       "1  SELECT \\n        s.product_name,\\n        s.sa...  \n",
       "2  SELECT \\n        t1.TrafficSourceName,\\n      ...  \n",
       "3  SELECT \\n        DATE_FORMAT(first_visit_date,...  \n",
       "4  SELECT \\n        p.product_name,\\n        MAX(...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Generate an SQL query using the database name ga4 for the following question: How many pseudo users were active in the last 7 days but inactive in the last 2 days as of January 7, 2021? Additionally, include a condition to filter out users who have been banned within the last 3 months. The table name is 'users' and it contains columns 'username', 'pseudo_user_id', 'last_activity_date', 'banned_date'. Ensure your query includes JOIN clauses with appropriate conditions.\\nSELECT COUNT(*) \\nFROM users \\nWHERE last_activity_date >= DATE_SUB(CURDATE(), INTERVAL 7 DAY) AND last_activity_date <= DATE_SUB(CURDATE(), INTERVAL 2 DAY) \\nAND banned_date IS NULL\\nAND username NOT IN (\\n    SELECT username \\n    FROM users \\n    WHERE last_activity_date >= DATE_SUB(CURDATE(), INTERVAL 3 MONTH)\\n); \\n\\nExplanation:\\n- The first query selects all rows where the `last_activity_date` is greater than or equal to the current date minus seven days and less than the current date plus two days.\\n- The second query filters out any users whose `last_activity_date` is more than three months ago by joining the `users` table with itself on the `username` column using an INNER JOIN clause.\\n- The third query uses a subquery to check if each user's `banned_date` is not null (meaning they haven't been banned within the past three months). This ensures that only users who are still active and haven't been banned in the last 3 months are included in the count.\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['initial_sql'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_queries = {}\n",
    "\n",
    "ground_truth_dir = '/isilon/datalake/dma_research/scratch/damalab/Data/Swapnil/Personal/Text2SQL/Spider2/spider2-lite/evaluation_suite/gold/sql'\n",
    "\n",
    "# Load each ground truth SQL file into the dictionary\n",
    "for file_path in glob.glob(os.path.join(ground_truth_dir, '*.sql')):\n",
    "    query_id = os.path.splitext(os.path.basename(file_path))[0]\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        ground_truth_queries[query_id] = file.read().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize counters for total and matched queries\n",
    "total_queries = 0\n",
    "exact_matches = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instance_id</th>\n",
       "      <th>question</th>\n",
       "      <th>db</th>\n",
       "      <th>initial_sql</th>\n",
       "      <th>refined_sql</th>\n",
       "      <th>final_query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bq011</td>\n",
       "      <td>How many pseudo users were active in the last ...</td>\n",
       "      <td>ga4</td>\n",
       "      <td>Generate an SQL query using the database name ...</td>\n",
       "      <td>SELECT COUNT(*) \\nFROM users \\nWHERE last_acti...</td>\n",
       "      <td>SELECT COUNT(*) \\n    FROM users \\n    WHERE l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bq010</td>\n",
       "      <td>Find the top-selling product among customers w...</td>\n",
       "      <td>ga360</td>\n",
       "      <td>Generate an SQL query using the database name ...</td>\n",
       "      <td>SELECT \\n    s.product_name,\\n    s.sale_price...</td>\n",
       "      <td>SELECT \\n        s.product_name,\\n        s.sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bq009</td>\n",
       "      <td>Which traffic source has the highest total tra...</td>\n",
       "      <td>ga360</td>\n",
       "      <td>Generate an SQL query using the database name ...</td>\n",
       "      <td>SELECT \\n    t1TrafficSourceName AS TrafficSou...</td>\n",
       "      <td>SELECT \\n        t1.TrafficSourceName,\\n      ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bq001</td>\n",
       "      <td>For each visitor who made at least one transac...</td>\n",
       "      <td>ga360</td>\n",
       "      <td>Generate an SQL query using the database name ...</td>\n",
       "      <td>SELECT \\n    DATE_FORMAT(first_visit_date, '%Y...</td>\n",
       "      <td>SELECT \\n        DATE_FORMAT(first_visit_date,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bq002</td>\n",
       "      <td>During the first half of 2017,  focusing on hi...</td>\n",
       "      <td>ga360</td>\n",
       "      <td>Generate an SQL query using the database name ...</td>\n",
       "      <td>SELECT \\r\\n    p.product_name,\\r\\n    MAX(p.re...</td>\n",
       "      <td>SELECT \\n        p.product_name,\\n        MAX(...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  instance_id                                           question     db  \\\n",
       "0       bq011  How many pseudo users were active in the last ...    ga4   \n",
       "1       bq010  Find the top-selling product among customers w...  ga360   \n",
       "2       bq009  Which traffic source has the highest total tra...  ga360   \n",
       "3       bq001  For each visitor who made at least one transac...  ga360   \n",
       "4       bq002  During the first half of 2017,  focusing on hi...  ga360   \n",
       "\n",
       "                                         initial_sql  \\\n",
       "0  Generate an SQL query using the database name ...   \n",
       "1  Generate an SQL query using the database name ...   \n",
       "2  Generate an SQL query using the database name ...   \n",
       "3  Generate an SQL query using the database name ...   \n",
       "4  Generate an SQL query using the database name ...   \n",
       "\n",
       "                                         refined_sql  \\\n",
       "0  SELECT COUNT(*) \\nFROM users \\nWHERE last_acti...   \n",
       "1  SELECT \\n    s.product_name,\\n    s.sale_price...   \n",
       "2  SELECT \\n    t1TrafficSourceName AS TrafficSou...   \n",
       "3  SELECT \\n    DATE_FORMAT(first_visit_date, '%Y...   \n",
       "4  SELECT \\r\\n    p.product_name,\\r\\n    MAX(p.re...   \n",
       "\n",
       "                                         final_query  \n",
       "0  SELECT COUNT(*) \\n    FROM users \\n    WHERE l...  \n",
       "1  SELECT \\n        s.product_name,\\n        s.sa...  \n",
       "2  SELECT \\n        t1.TrafficSourceName,\\n      ...  \n",
       "3  SELECT \\n        DATE_FORMAT(first_visit_date,...  \n",
       "4  SELECT \\n        p.product_name,\\n        MAX(...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLAUSE_KEYWORDS = ['select', 'from', 'where', 'group by', 'order by', 'having', 'limit', 'join']\n",
    "\n",
    "def extract_structure(sql):\n",
    "    sql = sql.lower()\n",
    "    structure = []\n",
    "\n",
    "    for keyword in CLAUSE_KEYWORDS:\n",
    "        # Add to structure if keyword exists in SQL\n",
    "        if re.search(r'\\b' + keyword + r'\\b', sql):\n",
    "            structure.append(keyword)\n",
    "    return structure\n",
    "\n",
    "# Normalize and extract structure\n",
    "def normalize_structure(query):\n",
    "    if not isinstance(query, str): return []\n",
    "    return extract_structure(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = 0\n",
    "total = len(df)\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    query_id = row['instance_id']\n",
    "    pred_struct = normalize_structure(row['final_query'])\n",
    "    true_struct = normalize_structure(ground_truth_queries.get(query_id, ''))\n",
    "\n",
    "    if pred_struct == true_struct:\n",
    "        matches += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Structural Exact Match Score: 20.00%\n"
     ]
    }
   ],
   "source": [
    "score = matches / total if total else 0\n",
    "print(f'Structural Exact Match Score: {score:.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## spider 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLAUSE_KEYWORDS = ['select', 'from', 'where', 'group by', 'order by', 'having', 'limit', 'join']\n",
    "COMPONENTS_1 = {'where', 'group by', 'order by', 'limit', 'join', 'or', 'like', 'having'}\n",
    "COMPONENTS_2 = {'except', 'union', 'intersect', 'in', 'not in', 'nested'}\n",
    "\n",
    "# ----------------------------\n",
    "# Structure Matching\n",
    "# ----------------------------\n",
    "def extract_structure(sql):\n",
    "    sql = sql.lower()\n",
    "    return [kw for kw in CLAUSE_KEYWORDS if kw in sql]\n",
    "\n",
    "def normalize_structure(query):\n",
    "    if not isinstance(query, str):\n",
    "        return []\n",
    "    return extract_structure(query)\n",
    "\n",
    "# ----------------------------\n",
    "# Hardness Classification\n",
    "# ----------------------------\n",
    "def extract_sql_metadata(sql):\n",
    "    sql = sql.lower()\n",
    "    agg_count = len(re.findall(r'\\b(sum|count|max|min|avg)\\(', sql))\n",
    "\n",
    "    select_cols = re.findall(r'select (.*?) from', sql)\n",
    "    select_count = len(select_cols[0].split(',')) if select_cols else 0\n",
    "\n",
    "    where_clause = re.search(r'where (.*?)(group by|order by|having|limit|$)', sql)\n",
    "    where_count = len(re.split(r'\\s+and\\s+|\\s+or\\s+', where_clause.group(1))) if where_clause else 0\n",
    "\n",
    "    group_by_clause = re.search(r'group by (.*?)(order by|having|limit|$)', sql)\n",
    "    group_by_count = len(group_by_clause.group(1).split(',')) if group_by_clause else 0\n",
    "\n",
    "    components_1 = {k for k in COMPONENTS_1 if k in sql}\n",
    "\n",
    "    components_2 = set()\n",
    "    if re.search(r'\\bexcept\\b', sql): components_2.add('except')\n",
    "    if re.search(r'\\bunion\\b', sql): components_2.add('union')\n",
    "    if re.search(r'\\bintersect\\b', sql): components_2.add('intersect')\n",
    "    if re.search(r'\\b(not\\s+)?in\\s*\\(', sql): components_2.add('in')\n",
    "    if re.search(r'\\(\\s*select\\b', sql): components_2.add('nested')\n",
    "\n",
    "    return {\n",
    "        'agg_count': agg_count,\n",
    "        'select_count': select_count,\n",
    "        'where_count': where_count,\n",
    "        'group_by_count': group_by_count,\n",
    "        'components_1': components_1,\n",
    "        'components_2': components_2\n",
    "    }\n",
    "\n",
    "def classify_sql_hardness(info):\n",
    "    c1 = len(info['components_1'])\n",
    "    c2 = len(info['components_2'])\n",
    "    other = sum([\n",
    "        info['agg_count'] > 1,\n",
    "        info['select_count'] > 1,\n",
    "        info['where_count'] > 1,\n",
    "        info['group_by_count'] > 1\n",
    "    ])\n",
    "\n",
    "    if c2 == 0 and c1 <= 1 and other == 0:\n",
    "        return 'easy'\n",
    "    if c2 == 0 and ((c1 == 1 and other <= 2) or (c1 == 2 and other < 2)):\n",
    "        return 'medium'\n",
    "    if c2 == 0 and ((c1 <= 2 and other > 2) or (2 < c1 <= 3 and other <= 2)):\n",
    "        return 'hard'\n",
    "    if c2 == 1 and c1 <= 1 and other == 0:\n",
    "        return 'hard'\n",
    "    return 'extra'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Exact Match Score: 10.24%\n",
      "✅ Avg Jaccard Structural Score: 37.04%\n",
      "\n",
      "📊 Count of Queries by Hardness:\n",
      "hardness\n",
      "easy      291\n",
      "extra     253\n",
      "hard        2\n",
      "medium      1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "📊 Exact Match by Hardness:\n",
      "hardness\n",
      "easy      0.000000\n",
      "extra     0.217391\n",
      "hard      0.500000\n",
      "medium    0.000000\n",
      "Name: exact_match, dtype: float64\n",
      "\n",
      "📊 Jaccard Score by Hardness:\n",
      "hardness\n",
      "easy      0.000000\n",
      "extra     0.792979\n",
      "hard      0.750000\n",
      "medium    0.500000\n",
      "Name: jaccard_score, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Load ground truth SQLs\n",
    "ground_truth_dir = 'spider2_lite_gold/sql'\n",
    "ground_truth_queries = {}\n",
    "\n",
    "for file_path in glob.glob(os.path.join(ground_truth_dir, '*.sql')):\n",
    "    query_id = os.path.splitext(os.path.basename(file_path))[0]\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        ground_truth_queries[query_id] = f.read().strip()\n",
    "\n",
    "# Load predictions\n",
    "df = pd.read_csv('refined_spider2_queries_cleaned_basic_final_final.csv')\n",
    "\n",
    "# Evaluate\n",
    "results = []\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    query_id = row['instance_id']\n",
    "    pred_sql = row['final_query']\n",
    "    gold_sql = ground_truth_queries.get(query_id, '')\n",
    "\n",
    "    # Structure match\n",
    "    pred_struct = normalize_structure(pred_sql)\n",
    "    gold_struct = normalize_structure(gold_sql)\n",
    "\n",
    "    exact_match = int(pred_struct == gold_struct)\n",
    "    jaccard = len(set(pred_struct) & set(gold_struct)) / len(set(pred_struct) | set(gold_struct)) if (pred_struct or gold_struct) else 1.0\n",
    "\n",
    "    # Hardness\n",
    "    hardness = classify_sql_hardness(extract_sql_metadata(gold_sql))\n",
    "\n",
    "    results.append({\n",
    "        'instance_id': query_id,\n",
    "        'exact_match': exact_match,\n",
    "        'jaccard_score': jaccard,\n",
    "        'hardness': hardness\n",
    "    })\n",
    "\n",
    "# ----------------------------\n",
    "# Results\n",
    "# ----------------------------\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "print(f\"✅ Exact Match Score: {results_df['exact_match'].mean():.2%}\")\n",
    "print(f\"✅ Avg Jaccard Structural Score: {results_df['jaccard_score'].mean():.2%}\")\n",
    "\n",
    "print(\"\\n📊 Count of Queries by Hardness:\")\n",
    "print(results_df['hardness'].value_counts().sort_index())\n",
    "\n",
    "print(\"\\n📊 Exact Match by Hardness:\")\n",
    "print(results_df.groupby('hardness')['exact_match'].mean())\n",
    "\n",
    "print(\"\\n📊 Jaccard Score by Hardness:\")\n",
    "print(results_df.groupby('hardness')['jaccard_score'].mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### spider 2.0 ablation qwen "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Exact Match Score: 7.31%\n",
      "✅ Avg Jaccard Structural Score: 33.77%\n",
      "\n",
      "📊 Count of Queries by Hardness:\n",
      "hardness\n",
      "easy      291\n",
      "extra     253\n",
      "hard        2\n",
      "medium      1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "📊 Exact Match by Hardness:\n",
      "hardness\n",
      "easy      0.027491\n",
      "extra     0.122530\n",
      "hard      0.500000\n",
      "medium    0.000000\n",
      "Name: exact_match, dtype: float64\n",
      "\n",
      "📊 Jaccard Score by Hardness:\n",
      "hardness\n",
      "easy      0.027491\n",
      "extra     0.690589\n",
      "hard      0.750000\n",
      "medium    0.500000\n",
      "Name: jaccard_score, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Load ground truth SQLs\n",
    "ground_truth_dir = 'spider2_lite_gold/sql'\n",
    "ground_truth_queries = {}\n",
    "\n",
    "for file_path in glob.glob(os.path.join(ground_truth_dir, '*.sql')):\n",
    "    query_id = os.path.splitext(os.path.basename(file_path))[0]\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        ground_truth_queries[query_id] = f.read().strip()\n",
    "\n",
    "# Load predictions\n",
    "df = pd.read_csv('refined_spider2_queries_cleaned_basic_final_final.csv')\n",
    "\n",
    "# Evaluate\n",
    "results = []\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    query_id = row['instance_id']\n",
    "    pred_sql = row['generated_sql']\n",
    "    gold_sql = ground_truth_queries.get(query_id, '')\n",
    "\n",
    "    # Structure match\n",
    "    pred_struct = normalize_structure(pred_sql)\n",
    "    gold_struct = normalize_structure(gold_sql)\n",
    "\n",
    "    exact_match = int(pred_struct == gold_struct)\n",
    "    jaccard = len(set(pred_struct) & set(gold_struct)) / len(set(pred_struct) | set(gold_struct)) if (pred_struct or gold_struct) else 1.0\n",
    "\n",
    "    # Hardness\n",
    "    hardness = classify_sql_hardness(extract_sql_metadata(gold_sql))\n",
    "\n",
    "    results.append({\n",
    "        'instance_id': query_id,\n",
    "        'exact_match': exact_match,\n",
    "        'jaccard_score': jaccard,\n",
    "        'hardness': hardness\n",
    "    })\n",
    "\n",
    "# ----------------------------\n",
    "# Results\n",
    "# ----------------------------\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "print(f\"✅ Exact Match Score: {results_df['exact_match'].mean():.2%}\")\n",
    "print(f\"✅ Avg Jaccard Structural Score: {results_df['jaccard_score'].mean():.2%}\")\n",
    "\n",
    "print(\"\\n📊 Count of Queries by Hardness:\")\n",
    "print(results_df['hardness'].value_counts().sort_index())\n",
    "\n",
    "print(\"\\n📊 Exact Match by Hardness:\")\n",
    "print(results_df.groupby('hardness')['exact_match'].mean())\n",
    "\n",
    "print(\"\\n📊 Jaccard Score by Hardness:\")\n",
    "print(results_df.groupby('hardness')['jaccard_score'].mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### spider 2.0 ablation starcoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Exact Match Score: 8.41%\n",
      "✅ Avg Jaccard Structural Score: 33.97%\n",
      "\n",
      "📊 Count of Queries by Hardness:\n",
      "hardness\n",
      "easy      291\n",
      "extra     253\n",
      "hard        2\n",
      "medium      1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "📊 Exact Match by Hardness:\n",
      "hardness\n",
      "easy      0.061856\n",
      "extra     0.106719\n",
      "hard      0.500000\n",
      "medium    0.000000\n",
      "Name: exact_match, dtype: float64\n",
      "\n",
      "📊 Jaccard Score by Hardness:\n",
      "hardness\n",
      "easy      0.061856\n",
      "extra     0.655599\n",
      "hard      0.714286\n",
      "medium    0.500000\n",
      "Name: jaccard_score, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Load ground truth SQLs\n",
    "ground_truth_dir = 'spider2_lite_gold/sql'\n",
    "ground_truth_queries = {}\n",
    "\n",
    "for file_path in glob.glob(os.path.join(ground_truth_dir, '*.sql')):\n",
    "    query_id = os.path.splitext(os.path.basename(file_path))[0]\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        ground_truth_queries[query_id] = f.read().strip()\n",
    "\n",
    "# Load predictions\n",
    "df = pd.read_csv('refined_spider2_queries_cleaned_basic_final_final.csv')\n",
    "\n",
    "# Evaluate\n",
    "results = []\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    query_id = row['instance_id']\n",
    "    pred_sql = row['refined_sql_cleaned']\n",
    "    gold_sql = ground_truth_queries.get(query_id, '')\n",
    "\n",
    "    # Structure match\n",
    "    pred_struct = normalize_structure(pred_sql)\n",
    "    gold_struct = normalize_structure(gold_sql)\n",
    "\n",
    "    exact_match = int(pred_struct == gold_struct)\n",
    "    jaccard = len(set(pred_struct) & set(gold_struct)) / len(set(pred_struct) | set(gold_struct)) if (pred_struct or gold_struct) else 1.0\n",
    "\n",
    "    # Hardness\n",
    "    hardness = classify_sql_hardness(extract_sql_metadata(gold_sql))\n",
    "\n",
    "    results.append({\n",
    "        'instance_id': query_id,\n",
    "        'exact_match': exact_match,\n",
    "        'jaccard_score': jaccard,\n",
    "        'hardness': hardness\n",
    "    })\n",
    "\n",
    "# ----------------------------\n",
    "# Results\n",
    "# ----------------------------\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "print(f\"✅ Exact Match Score: {results_df['exact_match'].mean():.2%}\")\n",
    "print(f\"✅ Avg Jaccard Structural Score: {results_df['jaccard_score'].mean():.2%}\")\n",
    "\n",
    "print(\"\\n📊 Count of Queries by Hardness:\")\n",
    "print(results_df['hardness'].value_counts().sort_index())\n",
    "\n",
    "print(\"\\n📊 Exact Match by Hardness:\")\n",
    "print(results_df.groupby('hardness')['exact_match'].mean())\n",
    "\n",
    "print(\"\\n📊 Jaccard Score by Hardness:\")\n",
    "print(results_df.groupby('hardness')['jaccard_score'].mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## spider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Exact Match Score: 34.04%\n",
      "✅ Avg Jaccard Structural Score: 76.98%\n",
      "\n",
      "📊 Count of Queries by Hardness:\n",
      "hardness\n",
      "easy      1220\n",
      "extra     2081\n",
      "hard      1403\n",
      "medium    2426\n",
      "Name: count, dtype: int64\n",
      "\n",
      "📊 Exact Match by Hardness:\n",
      "hardness\n",
      "easy      0.574590\n",
      "extra     0.322441\n",
      "hard      0.225232\n",
      "medium    0.304617\n",
      "Name: exact_match, dtype: float64\n",
      "\n",
      "📊 Jaccard Score by Hardness:\n",
      "hardness\n",
      "easy      0.838996\n",
      "extra     0.767738\n",
      "hard      0.725476\n",
      "medium    0.762382\n",
      "Name: jaccard_score, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Load ground truth SQLs\n",
    "df1 = pd.read_parquet('spider.parquet')\n",
    "\n",
    "# Load predictions\n",
    "df = pd.read_csv('refined_spider_queries_cleaned_basic_final_final.csv')\n",
    "\n",
    "df2 = pd.merge(df, df1, left_on=['nl_query', 'db'], right_on=['question', 'db_id'], how='inner')\n",
    "df.dropna(inplace=True)\n",
    "df2.shape\n",
    "\n",
    "results = []\n",
    "\n",
    "for _, row in df2.iterrows():\n",
    "    query_id = row['instance_id']\n",
    "    pred_sql = row['final_query']\n",
    "    gold_sql = row['query']\n",
    "\n",
    "    # Structure match\n",
    "    pred_struct = normalize_structure(pred_sql)\n",
    "    gold_struct = normalize_structure(gold_sql)\n",
    "\n",
    "    exact_match = int(pred_struct == gold_struct)\n",
    "    jaccard = len(set(pred_struct) & set(gold_struct)) / len(set(pred_struct) | set(gold_struct)) if (pred_struct or gold_struct) else 1.0\n",
    "\n",
    "    # Hardness\n",
    "    hardness = classify_sql_hardness(extract_sql_metadata(gold_sql))\n",
    "\n",
    "    results.append({\n",
    "        'instance_id': query_id,\n",
    "        'exact_match': exact_match,\n",
    "        'jaccard_score': jaccard,\n",
    "        'hardness': hardness\n",
    "    })\n",
    "\n",
    "# ----------------------------\n",
    "# Results\n",
    "# ----------------------------\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "print(f\"✅ Exact Match Score: {results_df['exact_match'].mean():.2%}\")\n",
    "print(f\"✅ Avg Jaccard Structural Score: {results_df['jaccard_score'].mean():.2%}\")\n",
    "\n",
    "print(\"\\n📊 Count of Queries by Hardness:\")\n",
    "print(results_df['hardness'].value_counts().sort_index())\n",
    "\n",
    "print(\"\\n📊 Exact Match by Hardness:\")\n",
    "print(results_df.groupby('hardness')['exact_match'].mean())\n",
    "\n",
    "print(\"\\n📊 Jaccard Score by Hardness:\")\n",
    "print(results_df.groupby('hardness')['jaccard_score'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### spider ablation qwen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Exact Match Score: 27.14%\n",
      "✅ Avg Jaccard Structural Score: 71.21%\n",
      "\n",
      "📊 Count of Queries by Hardness:\n",
      "hardness\n",
      "easy      1220\n",
      "extra     2081\n",
      "hard      1403\n",
      "medium    2426\n",
      "Name: count, dtype: int64\n",
      "\n",
      "📊 Exact Match by Hardness:\n",
      "hardness\n",
      "easy      0.568852\n",
      "extra     0.219125\n",
      "hard      0.144690\n",
      "medium    0.239901\n",
      "Name: exact_match, dtype: float64\n",
      "\n",
      "📊 Jaccard Score by Hardness:\n",
      "hardness\n",
      "easy      0.799443\n",
      "extra     0.692704\n",
      "hard      0.658208\n",
      "medium    0.715931\n",
      "Name: jaccard_score, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Load ground truth SQLs\n",
    "df1 = pd.read_parquet('spider.parquet')\n",
    "\n",
    "# Load predictions\n",
    "df = pd.read_csv('refined_spider_queries_cleaned_basic_final_final.csv')\n",
    "\n",
    "df2 = pd.merge(df, df1, left_on=['nl_query', 'db'], right_on=['question', 'db_id'], how='inner')\n",
    "df.dropna(inplace=True)\n",
    "df2.shape\n",
    "\n",
    "results = []\n",
    "\n",
    "for _, row in df2.iterrows():\n",
    "    query_id = row['instance_id']\n",
    "    pred_sql = row['generated_sql']\n",
    "    gold_sql = row['query']\n",
    "\n",
    "    # Structure match\n",
    "    pred_struct = normalize_structure(pred_sql)\n",
    "    gold_struct = normalize_structure(gold_sql)\n",
    "\n",
    "    exact_match = int(pred_struct == gold_struct)\n",
    "    jaccard = len(set(pred_struct) & set(gold_struct)) / len(set(pred_struct) | set(gold_struct)) if (pred_struct or gold_struct) else 1.0\n",
    "\n",
    "    # Hardness\n",
    "    hardness = classify_sql_hardness(extract_sql_metadata(gold_sql))\n",
    "\n",
    "    results.append({\n",
    "        'instance_id': query_id,\n",
    "        'exact_match': exact_match,\n",
    "        'jaccard_score': jaccard,\n",
    "        'hardness': hardness\n",
    "    })\n",
    "\n",
    "# ----------------------------\n",
    "# Results\n",
    "# ----------------------------\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "print(f\"✅ Exact Match Score: {results_df['exact_match'].mean():.2%}\")\n",
    "print(f\"✅ Avg Jaccard Structural Score: {results_df['jaccard_score'].mean():.2%}\")\n",
    "\n",
    "print(\"\\n📊 Count of Queries by Hardness:\")\n",
    "print(results_df['hardness'].value_counts().sort_index())\n",
    "\n",
    "print(\"\\n📊 Exact Match by Hardness:\")\n",
    "print(results_df.groupby('hardness')['exact_match'].mean())\n",
    "\n",
    "print(\"\\n📊 Jaccard Score by Hardness:\")\n",
    "print(results_df.groupby('hardness')['jaccard_score'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### spider 2.0 ablation starcoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Exact Match Score: 18.67%\n",
      "✅ Avg Jaccard Structural Score: 67.22%\n",
      "\n",
      "📊 Count of Queries by Hardness:\n",
      "hardness\n",
      "easy      1220\n",
      "extra     2081\n",
      "hard      1403\n",
      "medium    2426\n",
      "Name: count, dtype: int64\n",
      "\n",
      "📊 Exact Match by Hardness:\n",
      "hardness\n",
      "easy      0.304918\n",
      "extra     0.190774\n",
      "hard      0.114041\n",
      "medium    0.165705\n",
      "Name: exact_match, dtype: float64\n",
      "\n",
      "📊 Jaccard Score by Hardness:\n",
      "hardness\n",
      "easy      0.698015\n",
      "extra     0.680701\n",
      "hard      0.636588\n",
      "medium    0.672389\n",
      "Name: jaccard_score, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Load ground truth SQLs\n",
    "df1 = pd.read_parquet('spider.parquet')\n",
    "\n",
    "# Load predictions\n",
    "df = pd.read_csv('refined_spider_queries_cleaned_basic_final_final.csv')\n",
    "\n",
    "df2 = pd.merge(df, df1, left_on=['nl_query', 'db'], right_on=['question', 'db_id'], how='inner')\n",
    "df.dropna(inplace=True)\n",
    "df2.shape\n",
    "\n",
    "results = []\n",
    "\n",
    "for _, row in df2.iterrows():\n",
    "    query_id = row['instance_id']\n",
    "    pred_sql = row['refined_sql_cleaned']\n",
    "    gold_sql = row['query']\n",
    "\n",
    "    # Structure match\n",
    "    pred_struct = normalize_structure(pred_sql)\n",
    "    gold_struct = normalize_structure(gold_sql)\n",
    "\n",
    "    exact_match = int(pred_struct == gold_struct)\n",
    "    jaccard = len(set(pred_struct) & set(gold_struct)) / len(set(pred_struct) | set(gold_struct)) if (pred_struct or gold_struct) else 1.0\n",
    "\n",
    "    # Hardness\n",
    "    hardness = classify_sql_hardness(extract_sql_metadata(gold_sql))\n",
    "\n",
    "    results.append({\n",
    "        'instance_id': query_id,\n",
    "        'exact_match': exact_match,\n",
    "        'jaccard_score': jaccard,\n",
    "        'hardness': hardness\n",
    "    })\n",
    "\n",
    "# ----------------------------\n",
    "# Results\n",
    "# ----------------------------\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "print(f\"✅ Exact Match Score: {results_df['exact_match'].mean():.2%}\")\n",
    "print(f\"✅ Avg Jaccard Structural Score: {results_df['jaccard_score'].mean():.2%}\")\n",
    "\n",
    "print(\"\\n📊 Count of Queries by Hardness:\")\n",
    "print(results_df['hardness'].value_counts().sort_index())\n",
    "\n",
    "print(\"\\n📊 Exact Match by Hardness:\")\n",
    "print(results_df.groupby('hardness')['exact_match'].mean())\n",
    "\n",
    "print(\"\\n📊 Jaccard Score by Hardness:\")\n",
    "print(results_df.groupby('hardness')['jaccard_score'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### spider 2.0 vanna_generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Exact Match Score: 33.09%\n",
      "✅ Avg Jaccard Structural Score: 36.28%\n",
      "\n",
      "📊 Count of Queries by Hardness:\n",
      "hardness\n",
      "easy      291\n",
      "extra     253\n",
      "hard        2\n",
      "medium      1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "📊 Exact Match by Hardness:\n",
      "hardness\n",
      "easy      0.563574\n",
      "extra     0.067194\n",
      "hard      0.000000\n",
      "medium    0.000000\n",
      "Name: exact_match, dtype: float64\n",
      "\n",
      "📊 Jaccard Score by Hardness:\n",
      "hardness\n",
      "easy      0.563574\n",
      "extra     0.136095\n",
      "hard      0.000000\n",
      "medium    0.000000\n",
      "Name: jaccard_score, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Load ground truth SQLs\n",
    "ground_truth_dir = 'spider2_lite_gold/sql'\n",
    "ground_truth_queries = {}\n",
    "\n",
    "for file_path in glob.glob(os.path.join(ground_truth_dir, '*.sql')):\n",
    "    query_id = os.path.splitext(os.path.basename(file_path))[0]\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        ground_truth_queries[query_id] = f.read().strip()\n",
    "\n",
    "# Load predictions\n",
    "df = pd.read_csv('vanna_generated_queries.csv')\n",
    "\n",
    "# Evaluate\n",
    "results = []\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    query_id = row['instance_id']\n",
    "    pred_sql = row['vanna_sql']\n",
    "    gold_sql = ground_truth_queries.get(query_id, '')\n",
    "\n",
    "    # Structure match\n",
    "    pred_struct = normalize_structure(pred_sql)\n",
    "    gold_struct = normalize_structure(gold_sql)\n",
    "\n",
    "    exact_match = int(pred_struct == gold_struct)\n",
    "    jaccard = len(set(pred_struct) & set(gold_struct)) / len(set(pred_struct) | set(gold_struct)) if (pred_struct or gold_struct) else 1.0\n",
    "\n",
    "    # Hardness\n",
    "    hardness = classify_sql_hardness(extract_sql_metadata(gold_sql))\n",
    "\n",
    "    results.append({\n",
    "        'instance_id': query_id,\n",
    "        'exact_match': exact_match,\n",
    "        'jaccard_score': jaccard,\n",
    "        'hardness': hardness\n",
    "    })\n",
    "\n",
    "# ----------------------------\n",
    "# Results\n",
    "# ----------------------------\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "print(f\"✅ Exact Match Score: {results_df['exact_match'].mean():.2%}\")\n",
    "print(f\"✅ Avg Jaccard Structural Score: {results_df['jaccard_score'].mean():.2%}\")\n",
    "\n",
    "print(\"\\n📊 Count of Queries by Hardness:\")\n",
    "print(results_df['hardness'].value_counts().sort_index())\n",
    "\n",
    "print(\"\\n📊 Exact Match by Hardness:\")\n",
    "print(results_df.groupby('hardness')['exact_match'].mean())\n",
    "\n",
    "print(\"\\n📊 Jaccard Score by Hardness:\")\n",
    "print(results_df.groupby('hardness')['jaccard_score'].mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## geosql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('refined_geo_queries_cleaned_basic_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instance_id</th>\n",
       "      <th>nl_query</th>\n",
       "      <th>generated_sql</th>\n",
       "      <th>refined_sql</th>\n",
       "      <th>refined_sql_cleaned</th>\n",
       "      <th>final_query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SELECT state.area FROM state WHERE state.state...</td>\n",
       "      <td>what is the size of texas</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SELECT state.area FROM state WHERE state.state...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SELECT city.city_name FROM city WHERE city.sta...</td>\n",
       "      <td>what is the biggest city in nebraska</td>\n",
       "      <td>SELECT city_name\\nFROM cities\\nWHERE state = '...</td>\n",
       "      <td>SELECT city_name\\nFROM cities\\nWHERE state = '...</td>\n",
       "      <td>SELECT city_name FROM cities WHERE state = 'Ne...</td>\n",
       "      <td>SELECT city_name FROM city WHERE state_name = ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SELECT city.population FROM city WHERE city.ci...</td>\n",
       "      <td>how many people live in chicago</td>\n",
       "      <td>SELECT COUNT(*) \\nFROM population \\nWHERE city...</td>\n",
       "      <td>SELECT COUNT(*) \\nFROM population \\nWHERE city...</td>\n",
       "      <td>SELECT COUNT(*) FROM population WHERE city = '...</td>\n",
       "      <td>SELECT population FROM city WHERE city_name = ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SELECT state.population FROM state WHERE state...</td>\n",
       "      <td>how many people live in new mexico</td>\n",
       "      <td>CREATE TABLE addresses (\\n    address_id numbe...</td>\n",
       "      <td>CREATE TABLE addresses (\\n    address_id numbe...</td>\n",
       "      <td>CREATE TABLE addresses ( address_id number, li...</td>\n",
       "      <td>SELECT state_name, population FROM state WHERE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SELECT city.city_name FROM city WHERE city.sta...</td>\n",
       "      <td>what are the major cities in texas</td>\n",
       "      <td>select the name of each city from the \"city\" t...</td>\n",
       "      <td>SELECT city_name\\nFROM city\\nORDER BY populati...</td>\n",
       "      <td>SELECT city_name FROM city ORDER BY population...</td>\n",
       "      <td>SELECT city_name FROM city WHERE state_name='t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         instance_id  \\\n",
       "0  SELECT state.area FROM state WHERE state.state...   \n",
       "1  SELECT city.city_name FROM city WHERE city.sta...   \n",
       "2  SELECT city.population FROM city WHERE city.ci...   \n",
       "3  SELECT state.population FROM state WHERE state...   \n",
       "4  SELECT city.city_name FROM city WHERE city.sta...   \n",
       "\n",
       "                               nl_query  \\\n",
       "0             what is the size of texas   \n",
       "1  what is the biggest city in nebraska   \n",
       "2       how many people live in chicago   \n",
       "3    how many people live in new mexico   \n",
       "4    what are the major cities in texas   \n",
       "\n",
       "                                       generated_sql  \\\n",
       "0                                                NaN   \n",
       "1  SELECT city_name\\nFROM cities\\nWHERE state = '...   \n",
       "2  SELECT COUNT(*) \\nFROM population \\nWHERE city...   \n",
       "3  CREATE TABLE addresses (\\n    address_id numbe...   \n",
       "4  select the name of each city from the \"city\" t...   \n",
       "\n",
       "                                         refined_sql  \\\n",
       "0                                                NaN   \n",
       "1  SELECT city_name\\nFROM cities\\nWHERE state = '...   \n",
       "2  SELECT COUNT(*) \\nFROM population \\nWHERE city...   \n",
       "3  CREATE TABLE addresses (\\n    address_id numbe...   \n",
       "4  SELECT city_name\\nFROM city\\nORDER BY populati...   \n",
       "\n",
       "                                 refined_sql_cleaned  \\\n",
       "0                                                NaN   \n",
       "1  SELECT city_name FROM cities WHERE state = 'Ne...   \n",
       "2  SELECT COUNT(*) FROM population WHERE city = '...   \n",
       "3  CREATE TABLE addresses ( address_id number, li...   \n",
       "4  SELECT city_name FROM city ORDER BY population...   \n",
       "\n",
       "                                         final_query  \n",
       "0  SELECT state.area FROM state WHERE state.state...  \n",
       "1  SELECT city_name FROM city WHERE state_name = ...  \n",
       "2  SELECT population FROM city WHERE city_name = ...  \n",
       "3  SELECT state_name, population FROM state WHERE...  \n",
       "4  SELECT city_name FROM city WHERE state_name='t...  "
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_select_only(query):\n",
    "    \"\"\"\n",
    "    Remove any CREATE or INSERT statements and return only the final SELECT query.\n",
    "    Supports multi-statement SQL inputs.\n",
    "    \"\"\"\n",
    "    # Split on semicolons to separate multiple statements\n",
    "    statements = re.split(r';\\s*', query)\n",
    "    \n",
    "    # Return the first SELECT statement found\n",
    "    for stmt in statements:\n",
    "        if stmt.strip().lower().startswith(\"select\"):\n",
    "            return stmt.strip()\n",
    "    \n",
    "    # If no SELECT found, return empty string\n",
    "    return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['final_query'] = df1['final_query'].apply(extract_select_only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Exact Match Score: 72.64%\n",
      "✅ Avg Jaccard Structural Score: 86.37%\n",
      "\n",
      "📊 Count of Queries by Hardness:\n",
      "hardness\n",
      "easy      195\n",
      "extra     128\n",
      "hard      102\n",
      "medium    105\n",
      "Name: count, dtype: int64\n",
      "\n",
      "📊 Exact Match by Hardness:\n",
      "hardness\n",
      "easy      0.876923\n",
      "extra     0.531250\n",
      "hard      0.529412\n",
      "medium    0.876190\n",
      "Name: exact_match, dtype: float64\n",
      "\n",
      "📊 Jaccard Score by Hardness:\n",
      "hardness\n",
      "easy      0.942308\n",
      "extra     0.785733\n",
      "hard      0.727778\n",
      "medium    0.944762\n",
      "Name: jaccard_score, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for _, row in df1.iterrows():\n",
    "    query_id = row['instance_id']\n",
    "    pred_sql = row['final_query']\n",
    "    gold_sql = row['instance_id']\n",
    "\n",
    "    # Structure match\n",
    "    pred_struct = normalize_structure(pred_sql)\n",
    "    gold_struct = normalize_structure(gold_sql)\n",
    "\n",
    "    exact_match = int(pred_struct == gold_struct)\n",
    "    jaccard = len(set(pred_struct) & set(gold_struct)) / len(set(pred_struct) | set(gold_struct)) if (pred_struct or gold_struct) else 1.0\n",
    "\n",
    "    # Hardness\n",
    "    hardness = classify_sql_hardness(extract_sql_metadata(gold_sql))\n",
    "\n",
    "    results.append({\n",
    "        'instance_id': query_id,\n",
    "        'exact_match': exact_match,\n",
    "        'jaccard_score': jaccard,\n",
    "        'hardness': hardness\n",
    "    })\n",
    "\n",
    "# ----------------------------\n",
    "# Results\n",
    "# ----------------------------\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "print(f\"✅ Exact Match Score: {results_df['exact_match'].mean():.2%}\")\n",
    "print(f\"✅ Avg Jaccard Structural Score: {results_df['jaccard_score'].mean():.2%}\")\n",
    "\n",
    "print(\"\\n📊 Count of Queries by Hardness:\")\n",
    "print(results_df['hardness'].value_counts().sort_index())\n",
    "\n",
    "print(\"\\n📊 Exact Match by Hardness:\")\n",
    "print(results_df.groupby('hardness')['exact_match'].mean())\n",
    "\n",
    "print(\"\\n📊 Jaccard Score by Hardness:\")\n",
    "print(results_df.groupby('hardness')['jaccard_score'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>table_names</th>\n",
       "      <th>tables</th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>what is the size of texas</td>\n",
       "      <td>{\"columns\":[\"area\"],\"index\":[0],\"data\":[[26680...</td>\n",
       "      <td>[state]</td>\n",
       "      <td>[{\"columns\":[\"state_name\",\"population\",\"area\",...</td>\n",
       "      <td>what is the size of texas &lt;table_name&gt; : state...</td>\n",
       "      <td>col : area row 1 : 266807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>what is the biggest city in nebraska</td>\n",
       "      <td>{\"columns\":[\"city_name\"],\"index\":[0],\"data\":[[...</td>\n",
       "      <td>[city]</td>\n",
       "      <td>[{\"columns\":[\"city_name\",\"population\",\"country...</td>\n",
       "      <td>what is the biggest city in nebraska &lt;table_na...</td>\n",
       "      <td>col : city_name row 1 : omaha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>how many people live in chicago</td>\n",
       "      <td>{\"columns\":[\"population\"],\"index\":[0],\"data\":[...</td>\n",
       "      <td>[city]</td>\n",
       "      <td>[{\"columns\":[\"city_name\",\"population\",\"country...</td>\n",
       "      <td>how many people live in chicago &lt;table_name&gt; :...</td>\n",
       "      <td>col : population row 1 : 3005172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>how many people live in new mexico</td>\n",
       "      <td>{\"columns\":[\"population\"],\"index\":[0],\"data\":[...</td>\n",
       "      <td>[state]</td>\n",
       "      <td>[{\"columns\":[\"state_name\",\"population\",\"area\",...</td>\n",
       "      <td>how many people live in new mexico &lt;table_name...</td>\n",
       "      <td>col : population row 1 : 1303000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>what are the major cities in texas</td>\n",
       "      <td>{\"columns\":[\"city_name\"],\"index\":[0,1,2,3,4,5,...</td>\n",
       "      <td>[city]</td>\n",
       "      <td>[{\"columns\":[\"city_name\",\"population\",\"country...</td>\n",
       "      <td>what are the major cities in texas &lt;table_name...</td>\n",
       "      <td>col : city_name row 1 : houston row 2 : dallas...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               question  \\\n",
       "0             what is the size of texas   \n",
       "1  what is the biggest city in nebraska   \n",
       "2       how many people live in chicago   \n",
       "3    how many people live in new mexico   \n",
       "4    what are the major cities in texas   \n",
       "\n",
       "                                              answer table_names  \\\n",
       "0  {\"columns\":[\"area\"],\"index\":[0],\"data\":[[26680...     [state]   \n",
       "1  {\"columns\":[\"city_name\"],\"index\":[0],\"data\":[[...      [city]   \n",
       "2  {\"columns\":[\"population\"],\"index\":[0],\"data\":[...      [city]   \n",
       "3  {\"columns\":[\"population\"],\"index\":[0],\"data\":[...     [state]   \n",
       "4  {\"columns\":[\"city_name\"],\"index\":[0,1,2,3,4,5,...      [city]   \n",
       "\n",
       "                                              tables  \\\n",
       "0  [{\"columns\":[\"state_name\",\"population\",\"area\",...   \n",
       "1  [{\"columns\":[\"city_name\",\"population\",\"country...   \n",
       "2  [{\"columns\":[\"city_name\",\"population\",\"country...   \n",
       "3  [{\"columns\":[\"state_name\",\"population\",\"area\",...   \n",
       "4  [{\"columns\":[\"city_name\",\"population\",\"country...   \n",
       "\n",
       "                                              source  \\\n",
       "0  what is the size of texas <table_name> : state...   \n",
       "1  what is the biggest city in nebraska <table_na...   \n",
       "2  how many people live in chicago <table_name> :...   \n",
       "3  how many people live in new mexico <table_name...   \n",
       "4  what are the major cities in texas <table_name...   \n",
       "\n",
       "                                              target  \n",
       "0                          col : area row 1 : 266807  \n",
       "1                      col : city_name row 1 : omaha  \n",
       "2                   col : population row 1 : 3005172  \n",
       "3                   col : population row 1 : 1303000  \n",
       "4  col : city_name row 1 : houston row 2 : dallas...  "
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyarrow as pa\n",
    "import pandas as pd\n",
    "\n",
    "with pa.memory_map(\"/Users/swapster/Desktop/Text2SQL/geosql/geoquery_nq_train_with_answer.hf/dataset.arrow\", \"rb\") as source:\n",
    "    reader = pa.ipc.RecordBatchStreamReader(source)\n",
    "    table = reader.read_all()\n",
    "\n",
    "df = table.to_pandas()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>table_names</th>\n",
       "      <th>tables</th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>instance_id</th>\n",
       "      <th>nl_query</th>\n",
       "      <th>generated_sql</th>\n",
       "      <th>refined_sql</th>\n",
       "      <th>refined_sql_cleaned</th>\n",
       "      <th>final_query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>what is the size of texas</td>\n",
       "      <td>{\"columns\":[\"area\"],\"index\":[0],\"data\":[[26680...</td>\n",
       "      <td>[state]</td>\n",
       "      <td>[{\"columns\":[\"state_name\",\"population\",\"area\",...</td>\n",
       "      <td>what is the size of texas &lt;table_name&gt; : state...</td>\n",
       "      <td>col : area row 1 : 266807</td>\n",
       "      <td>SELECT state.area FROM state WHERE state.state...</td>\n",
       "      <td>what is the size of texas</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SELECT state.area FROM state WHERE state.state...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>what is the biggest city in nebraska</td>\n",
       "      <td>{\"columns\":[\"city_name\"],\"index\":[0],\"data\":[[...</td>\n",
       "      <td>[city]</td>\n",
       "      <td>[{\"columns\":[\"city_name\",\"population\",\"country...</td>\n",
       "      <td>what is the biggest city in nebraska &lt;table_na...</td>\n",
       "      <td>col : city_name row 1 : omaha</td>\n",
       "      <td>SELECT city.city_name FROM city WHERE city.sta...</td>\n",
       "      <td>what is the biggest city in nebraska</td>\n",
       "      <td>SELECT city_name\\nFROM cities\\nWHERE state = '...</td>\n",
       "      <td>SELECT city_name\\nFROM cities\\nWHERE state = '...</td>\n",
       "      <td>SELECT city_name FROM cities WHERE state = 'Ne...</td>\n",
       "      <td>SELECT city_name FROM city WHERE state_name = ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>how many people live in chicago</td>\n",
       "      <td>{\"columns\":[\"population\"],\"index\":[0],\"data\":[...</td>\n",
       "      <td>[city]</td>\n",
       "      <td>[{\"columns\":[\"city_name\",\"population\",\"country...</td>\n",
       "      <td>how many people live in chicago &lt;table_name&gt; :...</td>\n",
       "      <td>col : population row 1 : 3005172</td>\n",
       "      <td>SELECT city.population FROM city WHERE city.ci...</td>\n",
       "      <td>how many people live in chicago</td>\n",
       "      <td>SELECT COUNT(*) \\nFROM population \\nWHERE city...</td>\n",
       "      <td>SELECT COUNT(*) \\nFROM population \\nWHERE city...</td>\n",
       "      <td>SELECT COUNT(*) FROM population WHERE city = '...</td>\n",
       "      <td>SELECT population FROM city WHERE city_name = ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>how many people live in new mexico</td>\n",
       "      <td>{\"columns\":[\"population\"],\"index\":[0],\"data\":[...</td>\n",
       "      <td>[state]</td>\n",
       "      <td>[{\"columns\":[\"state_name\",\"population\",\"area\",...</td>\n",
       "      <td>how many people live in new mexico &lt;table_name...</td>\n",
       "      <td>col : population row 1 : 1303000</td>\n",
       "      <td>SELECT state.population FROM state WHERE state...</td>\n",
       "      <td>how many people live in new mexico</td>\n",
       "      <td>CREATE TABLE addresses (\\n    address_id numbe...</td>\n",
       "      <td>CREATE TABLE addresses (\\n    address_id numbe...</td>\n",
       "      <td>CREATE TABLE addresses ( address_id number, li...</td>\n",
       "      <td>SELECT state_name, population FROM state WHERE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>what are the major cities in texas</td>\n",
       "      <td>{\"columns\":[\"city_name\"],\"index\":[0,1,2,3,4,5,...</td>\n",
       "      <td>[city]</td>\n",
       "      <td>[{\"columns\":[\"city_name\",\"population\",\"country...</td>\n",
       "      <td>what are the major cities in texas &lt;table_name...</td>\n",
       "      <td>col : city_name row 1 : houston row 2 : dallas...</td>\n",
       "      <td>SELECT city.city_name FROM city WHERE city.sta...</td>\n",
       "      <td>what are the major cities in texas</td>\n",
       "      <td>select the name of each city from the \"city\" t...</td>\n",
       "      <td>SELECT city_name\\nFROM city\\nORDER BY populati...</td>\n",
       "      <td>SELECT city_name FROM city ORDER BY population...</td>\n",
       "      <td>SELECT city_name FROM city WHERE state_name='t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>which states have a major city named austin ?</td>\n",
       "      <td>{\"columns\":[\"state_name\"],\"index\":[0],\"data\":[...</td>\n",
       "      <td>[city]</td>\n",
       "      <td>[{\"columns\":[\"city_name\",\"population\",\"country...</td>\n",
       "      <td>which states have a major city named austin ? ...</td>\n",
       "      <td>col : state_name row 1 : texas</td>\n",
       "      <td>SELECT city.state_name FROM city WHERE city.ci...</td>\n",
       "      <td>which states have a major city named austin ?</td>\n",
       "      <td>SELECT state_name\\nFROM geography_table\\nWHERE...</td>\n",
       "      <td>SELECT state_name\\nFROM geography_table\\nWHERE...</td>\n",
       "      <td>SELECT state_name FROM geography_table WHERE c...</td>\n",
       "      <td>SELECT state_name FROM geography_table WHERE c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>which state is kalamazoo in</td>\n",
       "      <td>{\"columns\":[\"state_name\"],\"index\":[0],\"data\":[...</td>\n",
       "      <td>[city]</td>\n",
       "      <td>[{\"columns\":[\"city_name\",\"population\",\"country...</td>\n",
       "      <td>which state is kalamazoo in &lt;table_name&gt; : cit...</td>\n",
       "      <td>col : state_name row 1 : michigan</td>\n",
       "      <td>SELECT city.state_name FROM city WHERE city.ci...</td>\n",
       "      <td>which state is kalamazoo in</td>\n",
       "      <td>SELECT state FROM geography WHERE city = 'Kala...</td>\n",
       "      <td>SELECT state FROM geography WHERE city = 'Kala...</td>\n",
       "      <td>SELECT state FROM geography WHERE city = 'Kala...</td>\n",
       "      <td>SELECT state FROM geography WHERE city = 'Kala...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>how many states border hawaii</td>\n",
       "      <td>{\"columns\":[\"count(border_info.border)\"],\"inde...</td>\n",
       "      <td>[border_info]</td>\n",
       "      <td>[{\"columns\":[\"state_name\",\"border\"],\"index\":[0...</td>\n",
       "      <td>how many states border hawaii &lt;table_name&gt; : b...</td>\n",
       "      <td>col : count(border_info.border) row 1 : 0</td>\n",
       "      <td>SELECT count(border_info.border) FROM border_i...</td>\n",
       "      <td>how many states border hawaii</td>\n",
       "      <td>SELECT COUNT(*) \\nFROM geography\\nWHERE state_...</td>\n",
       "      <td>SELECT COUNT(*) \\nFROM geography\\nWHERE state_...</td>\n",
       "      <td>SELECT COUNT(*) FROM geography WHERE state_nam...</td>\n",
       "      <td>SELECT COUNT(DISTINCT state_name) FROM geograp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>what is the smallest state in the usa</td>\n",
       "      <td>{\"columns\":[\"state_name\"],\"index\":[0],\"data\":[...</td>\n",
       "      <td>[state]</td>\n",
       "      <td>[{\"columns\":[\"state_name\",\"population\",\"area\",...</td>\n",
       "      <td>what is the smallest state in the usa &lt;table_n...</td>\n",
       "      <td>col : state_name row 1 : district of columbia</td>\n",
       "      <td>SELECT state.state_name FROM state WHERE state...</td>\n",
       "      <td>what is the smallest state in the usa</td>\n",
       "      <td>SELECT \\n    MIN(state) AS smallest_state\\nFRO...</td>\n",
       "      <td>SELECT \\n    MIN(state) AS smallest_state\\nFRO...</td>\n",
       "      <td>SELECT MIN(state) AS smallest_state FROM state...</td>\n",
       "      <td>SELECT state_name FROM state WHERE area=(SELEC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>what is the biggest state in continental us</td>\n",
       "      <td>{\"columns\":[\"state_name\"],\"index\":[0],\"data\":[...</td>\n",
       "      <td>[state]</td>\n",
       "      <td>[{\"columns\":[\"state_name\",\"population\",\"area\",...</td>\n",
       "      <td>what is the biggest state in continental us &lt;t...</td>\n",
       "      <td>col : state_name row 1 : alaska</td>\n",
       "      <td>SELECT state.state_name FROM state WHERE state...</td>\n",
       "      <td>what is the biggest state in continental us</td>\n",
       "      <td>CREATE TABLE states (\\n    id INTEGER,\\n    na...</td>\n",
       "      <td>CREATE TABLE states (\\n    id INTEGER,\\n    na...</td>\n",
       "      <td>CREATE TABLE states ( id INTEGER, name VARCHAR...</td>\n",
       "      <td>SELECT name FROM states WHERE area=(SELECT max...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        question  \\\n",
       "0                      what is the size of texas   \n",
       "1           what is the biggest city in nebraska   \n",
       "2                how many people live in chicago   \n",
       "3             how many people live in new mexico   \n",
       "4             what are the major cities in texas   \n",
       "5  which states have a major city named austin ?   \n",
       "6                    which state is kalamazoo in   \n",
       "7                  how many states border hawaii   \n",
       "8          what is the smallest state in the usa   \n",
       "9    what is the biggest state in continental us   \n",
       "\n",
       "                                              answer    table_names  \\\n",
       "0  {\"columns\":[\"area\"],\"index\":[0],\"data\":[[26680...        [state]   \n",
       "1  {\"columns\":[\"city_name\"],\"index\":[0],\"data\":[[...         [city]   \n",
       "2  {\"columns\":[\"population\"],\"index\":[0],\"data\":[...         [city]   \n",
       "3  {\"columns\":[\"population\"],\"index\":[0],\"data\":[...        [state]   \n",
       "4  {\"columns\":[\"city_name\"],\"index\":[0,1,2,3,4,5,...         [city]   \n",
       "5  {\"columns\":[\"state_name\"],\"index\":[0],\"data\":[...         [city]   \n",
       "6  {\"columns\":[\"state_name\"],\"index\":[0],\"data\":[...         [city]   \n",
       "7  {\"columns\":[\"count(border_info.border)\"],\"inde...  [border_info]   \n",
       "8  {\"columns\":[\"state_name\"],\"index\":[0],\"data\":[...        [state]   \n",
       "9  {\"columns\":[\"state_name\"],\"index\":[0],\"data\":[...        [state]   \n",
       "\n",
       "                                              tables  \\\n",
       "0  [{\"columns\":[\"state_name\",\"population\",\"area\",...   \n",
       "1  [{\"columns\":[\"city_name\",\"population\",\"country...   \n",
       "2  [{\"columns\":[\"city_name\",\"population\",\"country...   \n",
       "3  [{\"columns\":[\"state_name\",\"population\",\"area\",...   \n",
       "4  [{\"columns\":[\"city_name\",\"population\",\"country...   \n",
       "5  [{\"columns\":[\"city_name\",\"population\",\"country...   \n",
       "6  [{\"columns\":[\"city_name\",\"population\",\"country...   \n",
       "7  [{\"columns\":[\"state_name\",\"border\"],\"index\":[0...   \n",
       "8  [{\"columns\":[\"state_name\",\"population\",\"area\",...   \n",
       "9  [{\"columns\":[\"state_name\",\"population\",\"area\",...   \n",
       "\n",
       "                                              source  \\\n",
       "0  what is the size of texas <table_name> : state...   \n",
       "1  what is the biggest city in nebraska <table_na...   \n",
       "2  how many people live in chicago <table_name> :...   \n",
       "3  how many people live in new mexico <table_name...   \n",
       "4  what are the major cities in texas <table_name...   \n",
       "5  which states have a major city named austin ? ...   \n",
       "6  which state is kalamazoo in <table_name> : cit...   \n",
       "7  how many states border hawaii <table_name> : b...   \n",
       "8  what is the smallest state in the usa <table_n...   \n",
       "9  what is the biggest state in continental us <t...   \n",
       "\n",
       "                                              target  \\\n",
       "0                          col : area row 1 : 266807   \n",
       "1                      col : city_name row 1 : omaha   \n",
       "2                   col : population row 1 : 3005172   \n",
       "3                   col : population row 1 : 1303000   \n",
       "4  col : city_name row 1 : houston row 2 : dallas...   \n",
       "5                     col : state_name row 1 : texas   \n",
       "6                  col : state_name row 1 : michigan   \n",
       "7          col : count(border_info.border) row 1 : 0   \n",
       "8      col : state_name row 1 : district of columbia   \n",
       "9                    col : state_name row 1 : alaska   \n",
       "\n",
       "                                         instance_id  \\\n",
       "0  SELECT state.area FROM state WHERE state.state...   \n",
       "1  SELECT city.city_name FROM city WHERE city.sta...   \n",
       "2  SELECT city.population FROM city WHERE city.ci...   \n",
       "3  SELECT state.population FROM state WHERE state...   \n",
       "4  SELECT city.city_name FROM city WHERE city.sta...   \n",
       "5  SELECT city.state_name FROM city WHERE city.ci...   \n",
       "6  SELECT city.state_name FROM city WHERE city.ci...   \n",
       "7  SELECT count(border_info.border) FROM border_i...   \n",
       "8  SELECT state.state_name FROM state WHERE state...   \n",
       "9  SELECT state.state_name FROM state WHERE state...   \n",
       "\n",
       "                                        nl_query  \\\n",
       "0                      what is the size of texas   \n",
       "1           what is the biggest city in nebraska   \n",
       "2                how many people live in chicago   \n",
       "3             how many people live in new mexico   \n",
       "4             what are the major cities in texas   \n",
       "5  which states have a major city named austin ?   \n",
       "6                    which state is kalamazoo in   \n",
       "7                  how many states border hawaii   \n",
       "8          what is the smallest state in the usa   \n",
       "9    what is the biggest state in continental us   \n",
       "\n",
       "                                       generated_sql  \\\n",
       "0                                                NaN   \n",
       "1  SELECT city_name\\nFROM cities\\nWHERE state = '...   \n",
       "2  SELECT COUNT(*) \\nFROM population \\nWHERE city...   \n",
       "3  CREATE TABLE addresses (\\n    address_id numbe...   \n",
       "4  select the name of each city from the \"city\" t...   \n",
       "5  SELECT state_name\\nFROM geography_table\\nWHERE...   \n",
       "6  SELECT state FROM geography WHERE city = 'Kala...   \n",
       "7  SELECT COUNT(*) \\nFROM geography\\nWHERE state_...   \n",
       "8  SELECT \\n    MIN(state) AS smallest_state\\nFRO...   \n",
       "9  CREATE TABLE states (\\n    id INTEGER,\\n    na...   \n",
       "\n",
       "                                         refined_sql  \\\n",
       "0                                                NaN   \n",
       "1  SELECT city_name\\nFROM cities\\nWHERE state = '...   \n",
       "2  SELECT COUNT(*) \\nFROM population \\nWHERE city...   \n",
       "3  CREATE TABLE addresses (\\n    address_id numbe...   \n",
       "4  SELECT city_name\\nFROM city\\nORDER BY populati...   \n",
       "5  SELECT state_name\\nFROM geography_table\\nWHERE...   \n",
       "6  SELECT state FROM geography WHERE city = 'Kala...   \n",
       "7  SELECT COUNT(*) \\nFROM geography\\nWHERE state_...   \n",
       "8  SELECT \\n    MIN(state) AS smallest_state\\nFRO...   \n",
       "9  CREATE TABLE states (\\n    id INTEGER,\\n    na...   \n",
       "\n",
       "                                 refined_sql_cleaned  \\\n",
       "0                                                NaN   \n",
       "1  SELECT city_name FROM cities WHERE state = 'Ne...   \n",
       "2  SELECT COUNT(*) FROM population WHERE city = '...   \n",
       "3  CREATE TABLE addresses ( address_id number, li...   \n",
       "4  SELECT city_name FROM city ORDER BY population...   \n",
       "5  SELECT state_name FROM geography_table WHERE c...   \n",
       "6  SELECT state FROM geography WHERE city = 'Kala...   \n",
       "7  SELECT COUNT(*) FROM geography WHERE state_nam...   \n",
       "8  SELECT MIN(state) AS smallest_state FROM state...   \n",
       "9  CREATE TABLE states ( id INTEGER, name VARCHAR...   \n",
       "\n",
       "                                         final_query  \n",
       "0  SELECT state.area FROM state WHERE state.state...  \n",
       "1  SELECT city_name FROM city WHERE state_name = ...  \n",
       "2  SELECT population FROM city WHERE city_name = ...  \n",
       "3  SELECT state_name, population FROM state WHERE...  \n",
       "4  SELECT city_name FROM city WHERE state_name='t...  \n",
       "5  SELECT state_name FROM geography_table WHERE c...  \n",
       "6  SELECT state FROM geography WHERE city = 'Kala...  \n",
       "7  SELECT COUNT(DISTINCT state_name) FROM geograp...  \n",
       "8  SELECT state_name FROM state WHERE area=(SELEC...  \n",
       "9  SELECT name FROM states WHERE area=(SELECT max...  "
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.merge(df1, left_on=['question'], right_on=['nl_query'], how='inner')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import re\n",
    "from pandasql import sqldf\n",
    "from collections import Counter\n",
    "\n",
    "def force_alias_to_t(query):\n",
    "    \"\"\"\n",
    "    Replace all table references (e.g., FROM state, state.area) with alias 't'.\n",
    "    \"\"\"\n",
    "    table_refs = re.findall(r'\\b(?:FROM|JOIN)\\s+([a-zA-Z_][a-zA-Z0-9_]*)', query, flags=re.IGNORECASE)\n",
    "    prefix_refs = re.findall(r'([a-zA-Z_][a-zA-Z0-9_]*)\\.', query)\n",
    "    all_candidates = set(table_refs + prefix_refs)\n",
    "\n",
    "    for name in all_candidates:\n",
    "        query = re.sub(rf'\\bFROM\\s+{name}\\b', 'FROM t', query, flags=re.IGNORECASE)\n",
    "        query = re.sub(rf'\\bJOIN\\s+{name}\\b', 'JOIN t', query, flags=re.IGNORECASE)\n",
    "        query = re.sub(rf'\\b{name}\\.', 't.', query, flags=re.IGNORECASE)\n",
    "    \n",
    "    return query\n",
    "\n",
    "def get_all_referenced_columns(query):\n",
    "    \"\"\"\n",
    "    Extract column names in the form of 't.column_name' from SQL query.\n",
    "    \"\"\"\n",
    "    return set(re.findall(r't\\.([a-zA-Z_][a-zA-Z0-9_]*)', query))\n",
    "\n",
    "def evaluate_execution_accuracy(df):\n",
    "    correct = 0\n",
    "    total = len(df)\n",
    "    failed_queries = []\n",
    "    missing_column_stats = Counter()\n",
    "\n",
    "    for i, row in df.iterrows():\n",
    "        try:\n",
    "            # --- Parse table JSON ---\n",
    "            table_str = row['tables']\n",
    "            if isinstance(table_str, (list, tuple, pd.Series, np.ndarray)):\n",
    "                table_str = table_str[0]\n",
    "            table_json = json.loads(table_str)\n",
    "            table_df = pd.DataFrame(table_json['data'], columns=table_json['columns'])\n",
    "\n",
    "            # --- Prepare and rewrite query ---\n",
    "            query = force_alias_to_t(row['final_query'])\n",
    "\n",
    "            # --- Check for missing columns ---\n",
    "            query_cols = get_all_referenced_columns(query)\n",
    "            missing_cols = query_cols - set(table_df.columns)\n",
    "            if missing_cols:\n",
    "                failed_queries.append((i, f\"Missing columns in table: {missing_cols}\"))\n",
    "                missing_column_stats.update(missing_cols)\n",
    "                continue\n",
    "\n",
    "            # --- Execute SQL using alias 't' ---\n",
    "            pysqldf = lambda q: sqldf(q, {'t': table_df})\n",
    "            pred_result_df = pysqldf(query)\n",
    "\n",
    "            # --- Parse ground truth answer ---\n",
    "            answer_str = row['answer']\n",
    "            if isinstance(answer_str, (list, tuple, pd.Series, np.ndarray)):\n",
    "                answer_str = answer_str[0]\n",
    "            answer_json = json.loads(answer_str)\n",
    "            true_df = pd.DataFrame(answer_json['data'], columns=answer_json['columns'])\n",
    "\n",
    "            # --- Compare results ---\n",
    "            if pred_result_df.reset_index(drop=True).equals(true_df.reset_index(drop=True)):\n",
    "                correct += 1\n",
    "            else:\n",
    "                failed_queries.append((i, \"Mismatch\"))\n",
    "\n",
    "        except Exception as e:\n",
    "            failed_queries.append((i, f\"Execution error: {e}\"))\n",
    "\n",
    "    # --- Print final stats ---\n",
    "    accuracy = correct / total if total > 0 else 0\n",
    "    print(f\"\\n✅ Execution Accuracy: {accuracy:.2%} ({correct}/{total})\")\n",
    "\n",
    "    if failed_queries:\n",
    "        print(\"\\n❌ Failed Queries Summary:\")\n",
    "        for idx, reason in failed_queries:\n",
    "            print(f\" - Row {idx}: {reason}\")\n",
    "\n",
    "    if missing_column_stats:\n",
    "        print(\"\\n📉 Most Common Missing Columns:\")\n",
    "        for col, count in missing_column_stats.most_common(10):\n",
    "            print(f\" - {col}: {count} times\")\n",
    "\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Execution Accuracy: 17.04% (91/534)\n",
      "\n",
      "❌ Failed Queries Summary:\n",
      " - Row 2: Mismatch\n",
      " - Row 3: Mismatch\n",
      " - Row 5: Mismatch\n",
      " - Row 6: Execution error: (sqlite3.OperationalError) no such column: state\n",
      "[SQL: SELECT state FROM t WHERE city = 'Kalamazoo' AND state = 'CA']\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 7: Mismatch\n",
      " - Row 9: Execution error: (sqlite3.OperationalError) no such column: name\n",
      "[SQL: SELECT name FROM t WHERE area=(SELECT max(area) FROM t)]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 10: Mismatch\n",
      " - Row 11: Execution error: (sqlite3.OperationalError) no such column: state\n",
      "[SQL: SELECT state FROM t WHERE country = 'United States' AND city = 'Austin' AND state = 'TX']\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 12: Execution error: (sqlite3.OperationalError) no such column: name\n",
      "[SQL: SELECT name FROM t WHERE state_id IN (SELECT state_id FROM t WHERE border_state = 'Texas') ORDER BY population DESC LIMIT 1]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 13: Execution error: (sqlite3.OperationalError) no such column: capital_city\n",
      "[SQL: SELECT capital_city FROM t WHERE state_name = 'Pennsylvania']\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 14: Execution error: (sqlite3.OperationalError) no such column: state_name\n",
      "[SQL: SELECT COUNT(*) FROM t WHERE state NOT IN (SELECT state_name FROM t WHERE capital = 'Albany')]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 16: Execution error: (sqlite3.OperationalError) no such column: name\n",
      "[SQL: SELECT name FROM t WHERE bordering_states LIKE '%Ohio%' AND name!= 'Ohio']\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 17: Execution error: (sqlite3.OperationalError) no such column: name\n",
      "[SQL: SELECT name, height FROM t WHERE country = 'Alaska' ORDER BY height DESC LIMIT 1]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 18: Execution error: (sqlite3.OperationalError) no such column: name\n",
      "[SQL: SELECT name FROM t WHERE area = (SELECT MIN(area) FROM t)]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 19: Mismatch\n",
      " - Row 21: Execution error: (sqlite3.OperationalError) no such column: name\n",
      "[SQL: SELECT name FROM t WHERE state_province = 'Hawaii' ORDER BY population ASC LIMIT 1]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 23: Execution error: (sqlite3.OperationalError) no such column: area\n",
      "[SQL: SELECT city_name \n",
      "    FROM t \n",
      "    WHERE population > 150000 \n",
      "    AND state_name = (\n",
      "        SELECT state_name \n",
      "        FROM t \n",
      "        WHERE area = (\n",
      "            SELECT min(area) \n",
      "            FROM t\n",
      "        )\n",
      "    )\n",
      "    ORDER BY city_name]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 24: Missing columns in table: {'area', 'traverse', 'capital', 'river_name'}\n",
      " - Row 25: Execution error: (sqlite3.OperationalError) no such column: Name\n",
      "[SQL: SELECT Name, Population FROM t WHERE State = 'Illinois' ORDER BY Population DESC LIMIT 1]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 26: Execution error: (sqlite3.OperationalError) no such column: name\n",
      "[SQL: SELECT name FROM t WHERE traverse='nebraska' ORDER BY length ASC LIMIT 1]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 27: Execution error: (sqlite3.OperationalError) no such column: country_id\n",
      "[SQL: SELECT COUNT(*) FROM t WHERE country_id = (SELECT id FROM t WHERE name = 'Colorado')]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 28: Execution error: (sqlite3.OperationalError) no such column: city\n",
      "[SQL: SELECT population FROM t WHERE city = 'New York']\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 29: Execution error: (sqlite3.OperationalError) no such column: state\n",
      "[SQL: SELECT state, SUM(population) AS total_population FROM t GROUP BY state ORDER BY total_population DESC LIMIT 1]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 31: Execution error: (sqlite3.OperationalError) no such column: name\n",
      "[SQL: SELECT name FROM t WHERE country = 'USA' ORDER BY length LIMIT 1]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 32: Mismatch\n",
      " - Row 33: Mismatch\n",
      " - Row 34: Execution error: (sqlite3.OperationalError) no such column: name\n",
      "[SQL: SELECT name FROM t WHERE traverse = 'colorado']\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 35: Missing columns in table: {'name', 'state'}\n",
      " - Row 37: Missing columns in table: {'border'}\n",
      " - Row 38: Missing columns in table: {'water_body_id', 'id', 'state'}\n",
      " - Row 39: Mismatch\n",
      " - Row 40: Execution error: (sqlite3.OperationalError) no such column: area\n",
      "[SQL: SELECT city_name FROM t WHERE population = (\n",
      "        SELECT min(population) FROM t WHERE state_name = (\n",
      "            SELECT state_name FROM t WHERE area = (\n",
      "                SELECT min(area) FROM t\n",
      "            )\n",
      "        )\n",
      "    )]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 41: Execution error: (sqlite3.OperationalError) no such column: state\n",
      "[SQL: SELECT COUNT(*) FROM t WHERE state = (SELECT state_name FROM t WHERE population = (SELECT MAX(population) FROM t))]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 42: Execution error: (sqlite3.OperationalError) no such table: highlow\n",
      "[SQL: SELECT MAX(`point`) FROM `highlow` WHERE `state_name` = 'Wyoming']\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 44: Execution error: (sqlite3.OperationalError) no such table: geography\n",
      "[SQL: SELECT MIN(`latitude`) AS `lowest_point` FROM `geography` WHERE `latitude` > 39.75]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 45: Execution error: (sqlite3.OperationalError) no such column: MISSISSIPPI\n",
      "[SQL: SELECT LENGTH(MISSISSIPPI) AS 'Length of Mississippi River' FROM (SELECT ROW_NUMBER() OVER (ORDER BY MISSISSIPPI) AS RowNumber, MISSISSIPPI FROM t) WHERE RowNumber = 1]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 46: Execution error: (sqlite3.OperationalError) no such column: name\n",
      "[SQL: SELECT name, length_km, origin, flow_direction FROM t WHERE state = 'Texas' AND length_km > 10000]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 47: Execution error: (sqlite3.OperationalError) no such column: name\n",
      "[SQL: SELECT name FROM t WHERE traverse = 'Arizona']\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 48: Mismatch\n",
      " - Row 49: Mismatch\n",
      " - Row 50: Missing columns in table: {'capital'}\n",
      " - Row 52: Execution error: (sqlite3.OperationalError) no such column: elevation\n",
      "[SQL: SELECT MAX(elevation) FROM t WHERE name = 'colorado']\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 53: Execution error: (sqlite3.OperationalError) no such column: border\n",
      "[SQL: SELECT population FROM t WHERE state_name = (SELECT border FROM t WHERE state_name = 'Texas' ORDER BY area DESC LIMIT 1)]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 55: Execution error: (sqlite3.OperationalError) no such column: value\n",
      "[SQL: SELECT value AS population FROM t WHERE state_name='california']\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 56: Execution error: (sqlite3.OperationalError) no such column: state\n",
      "[SQL: SELECT state FROM t WHERE city = 'Austin' AND state = 'TX']\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 57: Execution error: (sqlite3.OperationalError) no such column: city\n",
      "[SQL: SELECT ROUND(AVG(population), 2) AS avg_population FROM t WHERE city = 'Boston' AND state = 'Massachusetts']\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 59: Missing columns in table: {'country'}\n",
      " - Row 60: Execution error: 'NoneType' object has no attribute 'reset_index'\n",
      " - Row 62: Missing columns in table: {'population', 'state_name'}\n",
      " - Row 63: Missing columns in table: {'name', 'state_id', 'id'}\n",
      " - Row 64: Execution error: 'NoneType' object has no attribute 'reset_index'\n",
      " - Row 65: Execution error: (sqlite3.OperationalError) no such column: state\n",
      "[SQL: SELECT state FROM t WHERE country = 'New York' AND state = 'NY']\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 66: Execution error: (sqlite3.OperationalError) no such column: name\n",
      "[SQL: SELECT name, height FROM t WHERE country = 'United States' ORDER BY height DESC LIMIT 1]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 67: Missing columns in table: {'population', 'state_name'}\n",
      " - Row 69: Execution error: (sqlite3.OperationalError) no such column: name\n",
      "[SQL: SELECT name FROM t WHERE location = ST_GeomFromText('POINT(-122.3320708 47.6062095)', 4326) ORDER BY population DESC LIMIT 1]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 70: Mismatch\n",
      " - Row 71: Execution error: (sqlite3.OperationalError) no such column: state\n",
      "[SQL: SELECT state FROM t WHERE city = 'pittsburgh' AND state = 'PA']\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 73: Mismatch\n",
      " - Row 74: Execution error: (sqlite3.OperationalError) no such column: river_length_km\n",
      "[SQL: SELECT river_name, country_name, river_length_km FROM t WHERE river_length_km = (SELECT min(river_length_km) FROM t) AND country_name = 'World']\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 75: Execution error: 'NoneType' object has no attribute 'reset_index'\n",
      " - Row 76: Execution error: (sqlite3.OperationalError) no such column: state\n",
      "[SQL: SELECT state, COUNT(*) as river_count\n",
      "    FROM t\n",
      "    GROUP BY state\n",
      "    ORDER BY river_count DESC\n",
      "    LIMIT 1]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 77: Execution error: (sqlite3.OperationalError) no such table: geography_data\n",
      "[SQL: SELECT `density` FROM `geography_data` WHERE `state` = 'SD']\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 83: Execution error: (sqlite3.OperationalError) no such column: state\n",
      "[SQL: SELECT state FROM t WHERE density = (SELECT MIN(density) FROM t)]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 84: Execution error: (sqlite3.OperationalError) no such column: city\n",
      "[SQL: SELECT COUNT(*) FROM t WHERE city = 'Springfield']\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 85: Mismatch\n",
      " - Row 86: Execution error: (sqlite3.OperationalError) no such column: elevation\n",
      "[SQL: SELECT MAX(elevation) FROM t WHERE state_name = 'Montana']\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 88: Execution error: (sqlite3.OperationalError) no such column: state\n",
      "[SQL: SELECT state FROM t WHERE city = 'Flintton' AND state = 'MA']\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 89: Missing columns in table: {'border'}\n",
      " - Row 90: Execution error: (sqlite3.OperationalError) no such column: bordering_state\n",
      "[SQL: SELECT state_name FROM t WHERE bordering_state = 'Florida' AND state_name!= 'Florida']\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 91: Missing columns in table: {'country'}\n",
      " - Row 92: Missing columns in table: {'border'}\n",
      " - Row 93: Execution error: (sqlite3.OperationalError) no such column: border\n",
      "[SQL: SELECT state_name FROM t WHERE state_name IN (SELECT border FROM t WHERE state_name = 'Texas') ORDER BY area ASC LIMIT 1]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 94: Mismatch\n",
      " - Row 95: Missing columns in table: {'population', 'state_name'}\n",
      " - Row 96: Execution error: (sqlite3.OperationalError) no such column: state_id\n",
      "[SQL: SELECT state_id, SUM(LENGTH_km) as total_length FROM t GROUP BY state_id ORDER BY total_length DESC LIMIT 1]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 97: Execution error: (sqlite3.OperationalError) no such column: state\n",
      "[SQL: SELECT COUNT(*) FROM t WHERE state = 'Florida' AND population > 150000]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 98: Execution error: (sqlite3.OperationalError) no such column: length_in_miles\n",
      "[SQL: SELECT `river_name`, `length_in_miles` FROM t WHERE `state_name` = 'New York' ORDER BY `length_in_miles` DESC LIMIT 1]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 99: Missing columns in table: {'name', 'length_meters'}\n",
      " - Row 100: Mismatch\n",
      " - Row 101: Mismatch\n",
      " - Row 102: Mismatch\n",
      " - Row 104: Missing columns in table: {'name'}\n",
      " - Row 105: Execution error: (sqlite3.OperationalError) no such column: state\n",
      "[SQL: SELECT river_name FROM t WHERE state='Texas']\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 106: Execution error: (sqlite3.OperationalError) no such column: state_id\n",
      "[SQL: SELECT COUNT(*) FROM t WHERE state_id IN (SELECT state_id FROM t WHERE river_name = 'Mississippi')]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 107: Missing columns in table: {'area', 'state_name'}\n",
      " - Row 108: Missing columns in table: {'name', 'state_id', 'id', 'height_meters'}\n",
      " - Row 110: Execution error: (sqlite3.OperationalError) no such column: population_density\n",
      "[SQL: SELECT AVG(population_density) AS avg_population_per_square_km FROM t WHERE state_name = 'Pennsylvania']\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 111: Execution error: (sqlite3.OperationalError) no such column: name\n",
      "[SQL: SELECT name FROM t WHERE state = 'NM']\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 112: Missing columns in table: {'river_id', 'id', 'discharge', 'name', 'location'}\n",
      " - Row 113: Execution error: (sqlite3.OperationalError) no such column: state\n",
      "[SQL: SELECT river_name FROM t WHERE state='arkansas']\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 114: Missing columns in table: {'river_id', 'id', 'discharge', 'name', 'location'}\n",
      " - Row 115: Execution error: (sqlite3.OperationalError) no such column: state\n",
      "[SQL: SELECT river_name FROM t WHERE state='arkansas']\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 116: Execution error: (sqlite3.OperationalError) no such column: state\n",
      "[SQL: SELECT COUNT(DISTINCT state) FROM t WHERE river_name='colorado']\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 117: Mismatch\n",
      " - Row 118: Execution error: 'NoneType' object has no attribute 'reset_index'\n",
      " - Row 119: Mismatch\n",
      " - Row 120: Execution error: (sqlite3.OperationalError) no such column: state_name\n",
      "[SQL: SELECT DISTINCT state_name, COUNT(river_id) AS num_rivers, LENGTH(river_id) AS length_km FROM t WHERE river_name = 'Missouri River' GROUP BY state_name ORDER BY num_rivers DESC, length_km ASC]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 121: Execution error: (sqlite3.OperationalError) no such column: city\n",
      "[SQL: SELECT state_name FROM t WHERE city ='san jose']\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 122: Mismatch\n",
      " - Row 123: Execution error: (sqlite3.OperationalError) no such column: country_id\n",
      "[SQL: SELECT country_id, province_id, MAX(length_meters) as max_length\n",
      "    FROM t\n",
      "    GROUP BY country_id, province_id\n",
      "    ORDER BY max_length DESC\n",
      "    LIMIT 1]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 124: Mismatch\n",
      " - Row 125: Execution error: (sqlite3.OperationalError) no such column: state\n",
      "[SQL: SELECT state FROM t WHERE country = 'Georgia']\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 126: Missing columns in table: {'population', 'state_name'}\n",
      " - Row 127: Execution error: (sqlite3.OperationalError) no such column: name\n",
      "[SQL: SELECT name, length_km, avg_flow_rate_m3s FROM t WHERE state = 'Illinois' AND length_km > 750]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 128: Missing columns in table: {'state', 'border_state'}\n",
      " - Row 129: Execution error: (sqlite3.OperationalError) no such column: point_name\n",
      "[SQL: SELECT MAX(point_name) FROM t WHERE state = 'Ohio']\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 130: Missing columns in table: {'border_name'}\n",
      " - Row 131: Missing columns in table: {'city_name'}\n",
      " - Row 132: Missing columns in table: {'population', 'state_name'}\n",
      " - Row 134: Execution error: (sqlite3.OperationalError) no such column: name\n",
      "[SQL: SELECT name FROM t WHERE bordering_states LIKE '%Mississippi%' OR bordering_states LIKE '%Missouri%']\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 137: Execution error: (sqlite3.OperationalError) no such column: bordering_states\n",
      "[SQL: SELECT bordering_states FROM t WHERE name = 'New Hampshire']\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 138: Mismatch\n",
      " - Row 139: Missing columns in table: {'border'}\n",
      " - Row 140: Execution error: (sqlite3.OperationalError) no such column: name\n",
      "[SQL: SELECT name FROM t WHERE length_miles = (SELECT MIN(length_miles) FROM t)]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 141: Mismatch\n",
      " - Row 142: Execution error: (sqlite3.OperationalError) no such column: length_meters\n",
      "[SQL: SELECT river_name \n",
      "    FROM t \n",
      "    WHERE traverse = 'colorado' \n",
      "    ORDER BY length_meters DESC \n",
      "    LIMIT 1]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 143: Execution error: (sqlite3.OperationalError) no such column: state_province\n",
      "[SQL: SELECT state_province FROM t WHERE name = 'New Orleans']\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 144: Execution error: (sqlite3.OperationalError) no such column: state\n",
      "[SQL: SELECT state, MAX(density) as max_density\n",
      "    FROM t\n",
      "    GROUP BY state\n",
      "    ORDER BY max_density DESC\n",
      "    LIMIT 1]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 146: Execution error: 'NoneType' object has no attribute 'reset_index'\n",
      " - Row 147: Execution error: (sqlite3.OperationalError) no such table: mountains\n",
      "[SQL: SELECT `height` FROM `mountains` WHERE `country` = 'Texas' AND `name` = 'Mount Rushmore' ORDER BY `height` DESC LIMIT 1]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 148: Execution error: (sqlite3.OperationalError) no such column: country\n",
      "[SQL: SELECT city_name FROM t WHERE country = 'United States' AND population > 150000 ORDER BY city_name]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 149: Execution error: (sqlite3.OperationalError) no such column: state\n",
      "[SQL: SELECT city_name, population FROM t WHERE state = 'Wisconsin' AND population > 10000000]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 150: Execution error: (sqlite3.OperationalError) no such column: state\n",
      "[SQL: SELECT population FROM t WHERE state = 'Oregon' AND population > 1000000000]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 151: Mismatch\n",
      " - Row 152: Execution error: (sqlite3.OperationalError) no such column: state\n",
      "[SQL: SELECT capital FROM t WHERE state = 'TX']\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 153: Execution error: (sqlite3.OperationalError) no such column: state\n",
      "[SQL: SELECT state, COUNT(*) as population FROM t GROUP BY state ORDER BY population DESC LIMIT 1]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 154: Missing columns in table: {'name'}\n",
      " - Row 155: Mismatch\n",
      " - Row 156: Execution error: (sqlite3.OperationalError) no such column: name\n",
      "[SQL: SELECT name FROM t WHERE traverse='texas' ORDER BY length DESC]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 158: Execution error: (sqlite3.OperationalError) no such table: city\n",
      "[SQL: SELECT COUNT(*) FROM `city` WHERE `city_name` = 'austin']\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 159: Execution error: (sqlite3.OperationalError) no such column: high_point\n",
      "[SQL: SELECT MAX(high_point) FROM t WHERE state_name IN(SELECT state_name FROM t WHERE capital='Des Moines')]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 160: Execution error: 'NoneType' object has no attribute 'reset_index'\n",
      " - Row 161: Execution error: (sqlite3.OperationalError) no such column: border_state_name\n",
      "[SQL: SELECT COUNT(*) FROM t WHERE state_name = 'Iowa' OR border_state_name = 'Iowa']\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 162: Execution error: (sqlite3.OperationalError) no such column: name\n",
      "[SQL: SELECT name, length_in_miles FROM t WHERE state = 'California' ORDER BY length_in_miles DESC LIMIT 1]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 163: Execution error: (sqlite3.OperationalError) no such table: border_info\n",
      "[SQL: SELECT COUNT(*) FROM `border_info` WHERE `country_code` IN (SELECT `country_code` FROM `states` WHERE `state_code` = 'AK' AND `state_name` = 'Alaska')]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 164: Missing columns in table: {'border', 'state_name'}\n",
      " - Row 166: Execution error: (sqlite3.OperationalError) no such column: border\n",
      "[SQL: SELECT state_name FROM t WHERE state_name IN (SELECT border FROM t WHERE state_name = 'Texas') ORDER BY population DESC LIMIT 1]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 168: Mismatch\n",
      " - Row 169: Execution error: (sqlite3.OperationalError) no such column: state\n",
      "[SQL: SELECT state FROM t WHERE river = (SELECT river FROM t WHERE length_in_miles = (SELECT MAX(length_in_miles) FROM t))]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 171: Execution error: (sqlite3.OperationalError) no such column: capital_city\n",
      "[SQL: SELECT city_name FROM t WHERE city_name = (SELECT capital_city FROM t WHERE capital_city = city_name ORDER BY population DESC LIMIT 1)]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 172: Execution error: (sqlite3.OperationalError) no such column: state\n",
      "[SQL: SELECT COUNT(DISTINCT state) FROM t WHERE (state = 'colorado' AND country IN (SELECT country FROM t WHERE state = 'new mexico')) OR (state = 'new mexico' AND country IN (SELECT country FROM t WHERE state = 'colorado'))]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 174: Execution error: (sqlite3.OperationalError) no such column: state_name\n",
      "[SQL: SELECT state_name FROM t WHERE state_id IN (SELECT state_id FROM t WHERE river_name = 'Missouri')]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 175: Execution error: (sqlite3.OperationalError) no such table: states\n",
      "[SQL: SELECT `area` FROM `states` WHERE `name` = 'South Carolina']\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 176: Execution error: 'NoneType' object has no attribute 'reset_index'\n",
      " - Row 177: Execution error: (sqlite3.OperationalError) no such column: name\n",
      "[SQL: SELECT name FROM t WHERE state_id = (\n",
      "        SELECT id FROM t WHERE area = (\n",
      "            SELECT max(area) FROM t\n",
      "        )\n",
      "    ) ORDER BY population ASC LIMIT 1]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 178: Missing columns in table: {'border'}\n",
      " - Row 179: Execution error: (sqlite3.OperationalError) no such column: state\n",
      "[SQL: SELECT * FROM t WHERE state = 'California' AND country = 'United States']\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 180: Execution error: (sqlite3.OperationalError) no such column: t.city_name\n",
      "[SQL: SELECT t.city_name FROM t AS c WHERE t.state_name='texas' AND t.population=(SELECT max(t.population) FROM t AS c WHERE t.state_name='texas')]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 181: Missing columns in table: {'border'}\n",
      " - Row 183: Missing columns in table: {'iota', 'state_name'}\n",
      " - Row 186: Execution error: (sqlite3.OperationalError) no such column: state\n",
      "[SQL: SELECT state FROM t WHERE location_name = 'Des Moines' AND location_state = 'IA']\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 187: Mismatch\n",
      " - Row 188: Execution error: (sqlite3.OperationalError) no such column: point\n",
      "[SQL: SELECT point FROM t WHERE state = 'Florida' ORDER BY point DESC LIMIT 1]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 189: Mismatch\n",
      " - Row 190: Execution error: (sqlite3.OperationalError) no such column: state_name\n",
      "[SQL: SELECT DISTINCT state_name FROM t WHERE river_name = 'Colorado' ORDER BY state_name]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 191: Mismatch\n",
      " - Row 192: Missing columns in table: {'state_id', 'id'}\n",
      " - Row 193: Missing columns in table: {'name', 'state_id', 'id'}\n",
      " - Row 194: Mismatch\n",
      " - Row 195: Execution error: (sqlite3.OperationalError) no such column: country_id\n",
      "[SQL: SELECT COUNT(DISTINCT country_id) FROM t WHERE length > 750]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 196: Execution error: (sqlite3.OperationalError) no such column: state\n",
      "[SQL: SELECT population FROM t WHERE state = 'Illinois']\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 197: Execution error: (sqlite3.OperationalError) no such column: name\n",
      "[SQL: SELECT name FROM t WHERE bordering_countries LIKE '%Rhode Island%' ORDER BY name]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 198: Missing columns in table: {'capital'}\n",
      " - Row 200: Execution error: (sqlite3.OperationalError) no such column: border\n",
      "[SQL: SELECT state_name FROM t \n",
      "    WHERE state_name <> 'Alaska' AND state_name <> 'Hawaii' \n",
      "    GROUP BY state_name \n",
      "    ORDER BY COUNT(border) ASC \n",
      "    LIMIT 1]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 201: Missing columns in table: {'border'}\n",
      " - Row 203: Execution error: (sqlite3.OperationalError) no such column: height_feet\n",
      "[SQL: SELECT height_feet FROM t WHERE location_name = 'Mount McKinley' AND location_type = 'Mountain']\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 204: Execution error: (sqlite3.OperationalError) no such column: State\n",
      "[SQL: SELECT State FROM t WHERE Capital = 'Sacramento']\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 205: Execution error: (sqlite3.OperationalError) no such column: state\n",
      "[SQL: SELECT COUNT(*) FROM t WHERE state = 'Texas']\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 206: Execution error: (sqlite3.OperationalError) no such column: name\n",
      "[SQL: SELECT name, population FROM t WHERE state = 'Alaska' ORDER BY population DESC LIMIT 1]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 207: Execution error: (sqlite3.OperationalError) no such column: name\n",
      "[SQL: SELECT name FROM t ORDER BY area DESC LIMIT 1]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 208: Execution error: (sqlite3.OperationalError) no such column: population\n",
      "[SQL: SELECT state_name FROM t WHERE state_name IN (SELECT state_name FROM t WHERE state_name = 'Mississippi') AND population > 1000000 AND state_name NOT IN (SELECT state_name FROM t WHERE state_name = 'Mississippi')]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 209: Mismatch\n",
      " - Row 210: Execution error: (sqlite3.OperationalError) no such column: state\n",
      "[SQL: SELECT state FROM t WHERE river = (SELECT river FROM t WHERE length = (SELECT min(length) FROM t))]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 211: Execution error: (sqlite3.OperationalError) no such column: state\n",
      "[SQL: SELECT state FROM t WHERE country = 'United States' AND population = (SELECT MIN(population) FROM t)]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 212: Mismatch\n",
      " - Row 213: Execution error: (sqlite3.OperationalError) no such column: state\n",
      "[SQL: SELECT state, MAX(population) as max_population FROM t GROUP BY state ORDER BY max_population DESC LIMIT 1]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 214: Mismatch\n",
      " - Row 215: Execution error: (sqlite3.OperationalError) no such column: point\n",
      "[SQL: SELECT MIN(point) FROM t WHERE state = 'Texas']\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 216: Execution error: (sqlite3.OperationalError) no such column: state\n",
      "[SQL: SELECT state, MAX(highest_point) AS highest_point FROM t WHERE population = (SELECT MIN(population) FROM t) GROUP BY state]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 217: Execution error: (sqlite3.OperationalError) no such column: capital\n",
      "[SQL: SELECT city_name, population FROM t WHERE city_name IN (SELECT capital FROM t WHERE country = 'USA') ORDER BY population DESC LIMIT 1]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 218: Mismatch\n",
      " - Row 220: Execution error: (sqlite3.OperationalError) no such column: city\n",
      "[SQL: SELECT population FROM t WHERE city = 'Denver' AND state = 'CO']\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 221: Mismatch\n",
      " - Row 222: Mismatch\n",
      " - Row 223: Execution error: 'NoneType' object has no attribute 'reset_index'\n",
      " - Row 226: Execution error: (sqlite3.OperationalError) no such column: state_name\n",
      "[SQL: SELECT river_name FROM t WHERE state IN (SELECT state_name FROM t WHERE lowest_elevation = (SELECT MIN(lowest_elevation) FROM t))]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 227: Execution error: (sqlite3.OperationalError) no such column: state\n",
      "[SQL: SELECT state FROM t WHERE density = (SELECT MAX(density) FROM t)]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 228: Execution error: (sqlite3.OperationalError) no such column: state\n",
      "[SQL: SELECT city_name FROM t WHERE state = 'Oregon' AND population = (SELECT MAX(population) FROM t WHERE state = 'Oregon')]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 229: Mismatch\n",
      " - Row 230: Execution error: (sqlite3.OperationalError) no such column: state\n",
      "[SQL: SELECT COUNT(*) FROM t WHERE state = 'NY']\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 232: Execution error: (sqlite3.OperationalError) no such column: elevation\n",
      "[SQL: SELECT mountain_name FROM t WHERE state_name = 'Alaska' AND elevation > 0]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 233: Execution error: (sqlite3.OperationalError) no such table: population\n",
      "[SQL: SELECT `population` FROM `population` WHERE `city` = 'Springfield' AND `state` = 'Missouri']\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 234: Missing columns in table: {'name'}\n",
      " - Row 235: Mismatch\n",
      " - Row 236: Missing columns in table: {'state_id', 'id', 'state_name'}\n",
      " - Row 237: Execution error: (sqlite3.OperationalError) no such column: state\n",
      "[SQL: SELECT (SELECT SUM(population) FROM t WHERE state = 'TX') / (SELECT area FROM t WHERE state_name = 'Texas') AS population_density]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 238: Missing columns in table: {'name', 'state_id', 'id'}\n",
      " - Row 239: Execution error: (sqlite3.OperationalError) no such column: border\n",
      "[SQL: SELECT state_name FROM t WHERE state_name IN (SELECT border FROM t WHERE state_name = 'Texas') ORDER BY area DESC LIMIT 1]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 240: Execution error: (sqlite3.OperationalError) no such column: name\n",
      "[SQL: SELECT name FROM t WHERE population = (SELECT MAX(population) FROM t WHERE state = 'Arizona') AND state = 'Arizona']\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 241: Execution error: (sqlite3.OperationalError) no such column: state\n",
      "[SQL: SELECT state FROM t WHERE city = 'Boston' AND state = 'MA']\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 242: Missing columns in table: {'area', 'state_name'}\n",
      " - Row 243: Execution error: (sqlite3.OperationalError) no such column: name\n",
      "[SQL: SELECT name FROM t WHERE state = 'Louisiana' AND state_code = 'LA']\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 245: Missing columns in table: {'name'}\n",
      " - Row 246: Execution error: (sqlite3.OperationalError) no such column: name\n",
      "[SQL: SELECT name FROM t WHERE population = (SELECT MAX(population) FROM t)]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 247: Execution error: (sqlite3.OperationalError) no such column: elevation\n",
      "[SQL: SELECT elevation FROM t WHERE state = 'New Mexico']\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 248: Execution error: (sqlite3.OperationalError) no such column: state_name\n",
      "[SQL: SELECT state_name, area FROM t WHERE state_name IN (SELECT traverse FROM t WHERE river_name = 'Mississippi') ORDER BY area DESC LIMIT 1]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 249: Execution error: (sqlite3.OperationalError) no such column: border\n",
      "[SQL: SELECT COUNT(DISTINCT river_name) AS num_rivers FROM t WHERE traverse IN (SELECT border FROM t WHERE state_name = 'Colorado')]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 251: Execution error: (sqlite3.OperationalError) no such table: Geography\n",
      "[SQL: SELECT `River_Name`, `Length_Meters` FROM `Geography` WHERE `Country`!= 'Texas' ORDER BY `Length_Meters` DESC LIMIT 1]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 252: Mismatch\n",
      " - Row 253: Missing columns in table: {'country_id', 'name', 'id'}\n",
      " - Row 254: Execution error: (sqlite3.OperationalError) no such column: name\n",
      "[SQL: SELECT name FROM t WHERE state = 'Texas' AND elevation > 0]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 255: Execution error: (sqlite3.OperationalError) no such column: border\n",
      "[SQL: SELECT state_name FROM t WHERE state_name IN(SELECT border FROM t WHERE state_name='texas') AND area=(SELECT max(area) FROM t WHERE state_name IN(SELECT border FROM t WHERE state_name='texas'))]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 257: Execution error: (sqlite3.OperationalError) no such column: length_km\n",
      "[SQL: SELECT length_km FROM t WHERE river_name = 'Missouri']\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 258: Missing columns in table: {'CountryCode', 'StateID', 'Population'}\n",
      " - Row 259: Execution error: (sqlite3.OperationalError) no such column: state\n",
      "[SQL: SELECT state, population_in_millions FROM t ORDER BY population_in_millions DESC LIMIT 1]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 261: Mismatch\n",
      " - Row 263: Execution error: (sqlite3.OperationalError) no such column: state\n",
      "[SQL: SELECT state, COUNT(*) as num_rivers FROM t GROUP BY state ORDER BY num_rivers DESC LIMIT 1]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 264: Execution error: (sqlite3.OperationalError) no such column: state\n",
      "[SQL: SELECT river_name FROM t WHERE state = 'nevada']\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 265: Missing columns in table: {'area'}\n",
      " - Row 266: Mismatch\n",
      " - Row 267: Missing columns in table: {'border'}\n",
      " - Row 268: Execution error: (sqlite3.OperationalError) no such column: state\n",
      "[SQL: SELECT state_name FROM t WHERE state_name NOT IN (SELECT state FROM t WHERE country = 'USA')]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 269: Execution error: (sqlite3.OperationalError) no such column: name\n",
      "[SQL: SELECT length FROM t WHERE name = 'Rio Grande']\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 271: Mismatch\n",
      " - Row 272: Mismatch\n",
      " - Row 273: Execution error: (sqlite3.OperationalError) no such column: State\n",
      "[SQL: SELECT COUNT(*) AS SizeOfCalifornia FROM t WHERE State = 'California']\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 274: Execution error: (sqlite3.OperationalError) no such column: state\n",
      "[SQL: SELECT capital FROM t WHERE state = 'Vermont' ORDER BY capital]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 276: Execution error: (sqlite3.OperationalError) no such column: state2\n",
      "[SQL: SELECT state_name FROM t WHERE state_name NOT IN (SELECT DISTINCT state1 FROM t UNION SELECT DISTINCT state2 FROM t)]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 278: Missing columns in table: {'name', 'id'}\n",
      " - Row 279: Missing columns in table: {'name', 'state_id', 'id'}\n",
      " - Row 280: Mismatch\n",
      " - Row 282: Mismatch\n",
      " - Row 283: Mismatch\n",
      " - Row 284: Missing columns in table: {'state_id'}\n",
      " - Row 285: Missing columns in table: {'river_id', 'id', 'continent', 'country_id', 'name'}\n",
      " - Row 286: Missing columns in table: {'country_id', 'name', 'state_id', 'id'}\n",
      " - Row 287: Mismatch\n",
      " - Row 288: Execution error: (sqlite3.OperationalError) no such column: state\n",
      "[SQL: SELECT state, COUNT(*) as city_count FROM t GROUP BY state ORDER BY city_count DESC LIMIT 1]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 291: Execution error: (sqlite3.OperationalError) no such column: State\n",
      "[SQL: SELECT COUNT(*) FROM t WHERE State = 'Montana']\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 292: Missing columns in table: {'traverse', 'river_name'}\n",
      " - Row 293: Execution error: 'NoneType' object has no attribute 'reset_index'\n",
      " - Row 294: Mismatch\n",
      " - Row 295: Mismatch\n",
      " - Row 296: Execution error: (sqlite3.OperationalError) no such function: SUBSTRING_INDEX\n",
      "[SQL: SELECT ROUND(SUBSTRING_INDEX(CAST(population AS VARCHAR(10)), ',', -1)) AS population_size FROM t WHERE state_name = 'Texas']\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 297: Execution error: (sqlite3.OperationalError) no such column: state_name\n",
      "[SQL: SELECT COUNT(*) FROM t WHERE state_name IN (SELECT state_name FROM t WHERE river_name='colorado')]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 299: Execution error: 'NoneType' object has no attribute 'reset_index'\n",
      " - Row 300: Execution error: (sqlite3.OperationalError) no such column: state\n",
      "[SQL: SELECT COUNT(*) FROM t WHERE state = 'Alaska' AND country = 'United States']\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 302: Mismatch\n",
      " - Row 303: Mismatch\n",
      " - Row 305: Execution error: (sqlite3.OperationalError) no such column: country\n",
      "[SQL: SELECT country, MAX(river_length) AS longest_river_length FROM t WHERE country = 'USA' AND river_length IS NOT NULL GROUP BY country]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 306: Execution error: (sqlite3.OperationalError) no such column: name\n",
      "[SQL: SELECT name FROM t WHERE country = 'Utah' AND state = 'UT']\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 307: Mismatch\n",
      " - Row 309: Execution error: (sqlite3.OperationalError) no such column: state\n",
      "[SQL: SELECT COUNT(*) FROM t WHERE state = 'PA' AND population > 150000]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 310: Execution error: (sqlite3.OperationalError) no such column: state_id\n",
      "[SQL: SELECT COUNT(DISTINCT state_id) FROM t WHERE length = (SELECT MIN(length) FROM t)]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 312: Execution error: (sqlite3.OperationalError) no such column: name\n",
      "[SQL: SELECT name FROM t WHERE state = 'Indiana' AND country = 'United States']\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 313: Execution error: (sqlite3.OperationalError) no such column: capital\n",
      "[SQL: SELECT city_name FROM t WHERE city_name IN (SELECT capital FROM t WHERE country = 'United States') ORDER BY population DESC LIMIT 1]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 314: Execution error: (sqlite3.OperationalError) no such column: city\n",
      "[SQL: SELECT population FROM t WHERE city = 'Boston']\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 315: Execution error: (sqlite3.OperationalError) no such column: state\n",
      "[SQL: SELECT state FROM t WHERE capital = 'Columbus']\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 317: Execution error: (sqlite3.OperationalError) no such column: state_province_county\n",
      "[SQL: SELECT state_province_county, area FROM t WHERE state_province_county='new mexico']\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 318: Mismatch\n",
      " - Row 319: Execution error: (sqlite3.OperationalError) no such column: name\n",
      "[SQL: SELECT name FROM t WHERE state = 'Missouri' AND country = 'United States']\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 320: Missing columns in table: {'ID', 'STATE_ID'}\n",
      " - Row 321: Execution error: (sqlite3.OperationalError) no such column: state\n",
      "[SQL: SELECT state, population FROM t WHERE area = (SELECT MAX(area) FROM t) ORDER BY population DESC LIMIT 1]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 322: Execution error: (sqlite3.OperationalError) no such column: state\n",
      "[SQL: SELECT state FROM t WHERE city = 'dallas' AND state = 'TX']\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 325: Execution error: (sqlite3.OperationalError) no such column: country\n",
      "[SQL: SELECT capital FROM t WHERE country = 'Utah' ORDER BY capital]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 326: Execution error: (sqlite3.OperationalError) no such column: name\n",
      "[SQL: SELECT name FROM t WHERE state = 'Montana' AND country = 'United States']\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 327: Execution error: (sqlite3.OperationalError) no such column: bordering_states\n",
      "[SQL: SELECT COUNT(*) FROM t WHERE 'Texas' = ANY(bordering_states)]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 329: Missing columns in table: {'border', 'population', 'state_name'}\n",
      " - Row 330: Mismatch\n",
      " - Row 331: Mismatch\n",
      " - Row 332: Mismatch\n",
      " - Row 333: Execution error: 'NoneType' object has no attribute 'reset_index'\n",
      " - Row 334: Execution error: (sqlite3.OperationalError) no such column: state\n",
      "[SQL: SELECT state, city_name, population FROM t WHERE population = (SELECT max(population) FROM t)]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 335: Missing columns in table: {'city'}\n",
      " - Row 336: Missing columns in table: {'name', 'id'}\n",
      " - Row 337: Execution error: (sqlite3.OperationalError) no such column: state\n",
      "[SQL: SELECT capital FROM t WHERE state = 'Texas']\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 338: Execution error: 'NoneType' object has no attribute 'reset_index'\n",
      " - Row 339: Missing columns in table: {'id'}\n",
      " - Row 340: Execution error: (sqlite3.OperationalError) no such column: state_id\n",
      "[SQL: SELECT COUNT(*) FROM t WHERE state_id = (SELECT state_id FROM t WHERE name = 'Mississippi')]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 341: Missing columns in table: {'population', 'state_name'}\n",
      " - Row 342: Missing columns in table: {'area'}\n",
      " - Row 343: Mismatch\n",
      " - Row 344: Execution error: 'NoneType' object has no attribute 'reset_index'\n",
      " - Row 345: Execution error: (sqlite3.OperationalError) no such column: name\n",
      "[SQL: SELECT name, area FROM t WHERE country = 'Alaska']\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 346: Execution error: (sqlite3.OperationalError) no such table: states\n",
      "[SQL: SELECT COUNT(*) FROM `states` WHERE `state` IN (SELECT `river_name` FROM `river` WHERE `traverse` = 'Missouri')]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 347: Execution error: (sqlite3.OperationalError) no such column: name\n",
      "[SQL: SELECT name, population, area FROM t WHERE area = (SELECT MIN(area) FROM t)]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 349: Mismatch\n",
      " - Row 350: Execution error: (sqlite3.OperationalError) no such column: bordering_states\n",
      "[SQL: SELECT bordering_states FROM t WHERE name = 'Arkansas']\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 351: Mismatch\n",
      " - Row 352: Execution error: (sqlite3.OperationalError) no such column: country\n",
      "[SQL: SELECT state_name FROM t WHERE lowest_elevation = (SELECT MIN(lowest_elevation) FROM t WHERE country = 'United States')]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 353: Missing columns in table: {'city_name'}\n",
      " - Row 354: Execution error: (sqlite3.OperationalError) no such column: state\n",
      "[SQL: SELECT COUNT(*) FROM t WHERE state = 'Oregon' AND population > 150000]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 355: Mismatch\n",
      " - Row 356: Missing columns in table: {'state_id'}\n",
      " - Row 357: Mismatch\n",
      " - Row 358: Execution error: (sqlite3.OperationalError) no such column: state\n",
      "[SQL: SELECT COUNT(*) FROM t WHERE state = 'TX' AND population > 150000]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 359: Mismatch\n",
      " - Row 360: Execution error: (sqlite3.OperationalError) no such column: name\n",
      "[SQL: SELECT name FROM t WHERE city = 'boulder']\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 361: Execution error: 'NoneType' object has no attribute 'reset_index'\n",
      " - Row 362: Execution error: (sqlite3.OperationalError) no such column: height\n",
      "[SQL: SELECT height FROM t WHERE country = 'United States' AND name = 'Guadalupe Peak']\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 363: Missing columns in table: {'name', 'state_id', 'id'}\n",
      " - Row 364: Mismatch\n",
      " - Row 365: Execution error: (sqlite3.OperationalError) no such column: latitude\n",
      "[SQL: SELECT MIN(latitude), MAX(longitude) FROM t WHERE state = 'Texas']\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 366: Execution error: (sqlite3.OperationalError) no such column: state\n",
      "[SQL: SELECT state, (population / area) AS population_density FROM t WHERE population = (SELECT MIN(population) FROM t ) ORDER BY population_density DESC]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 367: Execution error: (sqlite3.OperationalError) no such column: bordering_states\n",
      "[SQL: SELECT bordering_states FROM t WHERE state_name = 'Texas']\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 368: Execution error: (sqlite3.OperationalError) no such column: name\n",
      "[SQL: SELECT name FROM t WHERE borders = 'Mississippi']\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 369: Execution error: (sqlite3.OperationalError) no such column: elevation\n",
      "[SQL: SELECT MAX(elevation) FROM t WHERE state = 'South Carolina']\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 370: Execution error: (sqlite3.OperationalError) no such column: state_name\n",
      "[SQL: SELECT COUNT(DISTINCT state_name) FROM t WHERE state_code IN (\n",
      "        SELECT state_code FROM t WHERE border = 'Mississippi'\n",
      "    )]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 371: Execution error: (sqlite3.OperationalError) no such column: name\n",
      "[SQL: SELECT COUNT(*) FROM t WHERE name LIKE '%colorado%' AND country_id = 1]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 372: Mismatch\n",
      " - Row 373: Mismatch\n",
      " - Row 374: Mismatch\n",
      " - Row 375: Execution error: (sqlite3.OperationalError) no such column: state_area\n",
      "[SQL: SELECT state_area FROM t WHERE state_name='Texas']\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 376: Missing columns in table: {'area', 'capital'}\n",
      " - Row 377: Mismatch\n",
      " - Row 378: Mismatch\n",
      " - Row 379: Execution error: (sqlite3.OperationalError) no such column: name\n",
      "[SQL: SELECT name FROM t WHERE traverse='ohio']\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 380: Missing columns in table: {'lowest_point'}\n",
      " - Row 381: Mismatch\n",
      " - Row 382: Execution error: (sqlite3.OperationalError) no such column: state\n",
      "[SQL: SELECT capital FROM t WHERE state = 'Indiana']\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 384: Mismatch\n",
      " - Row 385: Execution error: (sqlite3.OperationalError) no such column: state\n",
      "[SQL: SELECT state FROM t WHERE population = (SELECT MIN(population) FROM t)]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 387: Mismatch\n",
      " - Row 388: Execution error: (sqlite3.OperationalError) no such column: name\n",
      "[SQL: SELECT name FROM t WHERE state = 'Kansas' ORDER BY population DESC LIMIT 1]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 389: Execution error: 'NoneType' object has no attribute 'reset_index'\n",
      " - Row 390: Missing columns in table: {'border', 'state_name'}\n",
      " - Row 391: Missing columns in table: {'border', 'state'}\n",
      " - Row 392: Execution error: (sqlite3.OperationalError) no such column: state_area\n",
      "[SQL: SELECT state_area FROM t WHERE state_capital='Albany']\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 394: Execution error: (sqlite3.OperationalError) no such column: name\n",
      "[SQL: SELECT name, lowest_elevation FROM t WHERE lowest_elevation = (SELECT min(lowest_elevation) FROM t)]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 395: Execution error: (sqlite3.OperationalError) no such column: state_province\n",
      "[SQL: SELECT state_province FROM t WHERE city_name='rochester']\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 396: Execution error: (sqlite3.OperationalError) no such column: name\n",
      "[SQL: SELECT name FROM t WHERE country = 'United States' ORDER BY LENGTH(name) DESC LIMIT 1]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 398: Mismatch\n",
      " - Row 401: Execution error: 'NoneType' object has no attribute 'reset_index'\n",
      " - Row 402: Execution error: (sqlite3.OperationalError) no such column: state_name\n",
      "[SQL: SELECT state_name FROM t WHERE state_name IN (SELECT bordering_states FROM t WHERE border = 'Mississippi')]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 403: Mismatch\n",
      " - Row 404: Missing columns in table: {'border'}\n",
      " - Row 405: Missing columns in table: {'traverse', 'river_name'}\n",
      " - Row 406: Execution error: (sqlite3.OperationalError) no such column: state_province_county\n",
      "[SQL: SELECT state_province_county, population FROM t WHERE state_province_county='montana']\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 407: Missing columns in table: {'border', 'capital', 'state_name'}\n",
      " - Row 408: Execution error: (sqlite3.OperationalError) no such column: elevation\n",
      "[SQL: SELECT MIN(elevation) AS lowest_elevation FROM t WHERE state = 'Pennsylvania']\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 409: Execution error: (sqlite3.OperationalError) no such column: state\n",
      "[SQL: SELECT state FROM t WHERE city = 'Denver' AND state = 'CO']\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 410: Missing columns in table: {'state_province_county', 'address_id'}\n",
      " - Row 411: Execution error: (sqlite3.OperationalError) no such column: name\n",
      "[SQL: SELECT COUNT(name) FROM t WHERE state = 'Louisiana']\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 412: Missing columns in table: {'name'}\n",
      " - Row 413: Missing columns in table: {'name'}\n",
      " - Row 414: Mismatch\n",
      " - Row 415: Mismatch\n",
      " - Row 416: Execution error: (sqlite3.OperationalError) no such column: Name\n",
      "[SQL: SELECT COUNT(*) FROM t WHERE Name = 'Kentucky']\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 417: Missing columns in table: {'capital'}\n",
      " - Row 418: Mismatch\n",
      " - Row 419: Mismatch\n",
      " - Row 421: Missing columns in table: {'name', 'id'}\n",
      " - Row 422: Mismatch\n",
      " - Row 423: Missing columns in table: {'name'}\n",
      " - Row 425: Mismatch\n",
      " - Row 426: Execution error: (sqlite3.OperationalError) no such column: city\n",
      "[SQL: SELECT population FROM t WHERE city = 'Portland' AND state = 'MA']\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 427: Missing columns in table: {'highest_point'}\n",
      " - Row 429: Execution error: (sqlite3.OperationalError) no such column: state\n",
      "[SQL: SELECT state FROM t WHERE country = 'Massachusetts' AND state = 'Massachusetts']\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 430: Missing columns in table: {'border_id'}\n",
      " - Row 433: Execution error: (sqlite3.OperationalError) no such column: height\n",
      "[SQL: SELECT MAX(height) FROM t WHERE state = 'LA']\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 434: Mismatch\n",
      " - Row 435: Execution error: (sqlite3.OperationalError) no such column: location\n",
      "[SQL: SELECT river_name AS RiverName FROM t WHERE location = 'Texas' AND river_type = 'River']\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 436: Missing columns in table: {'name'}\n",
      " - Row 437: Execution error: (sqlite3.OperationalError) no such column: city_name\n",
      "[SQL: SELECT state_name AS border_state FROM t WHERE city_name IN (SELECT city_name FROM t WHERE state_name='Kentucky') ORDER BY state_name ASC]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 438: Execution error: (sqlite3.OperationalError) no such column: name\n",
      "[SQL: SELECT name FROM t WHERE state='Texas' ORDER BY length DESC LIMIT 1]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 439: Execution error: (sqlite3.OperationalError) no such column: state\n",
      "[SQL: SELECT state, ROW_NUMBER() OVER (ORDER BY population DESC) AS row_num FROM t WHERE population = (SELECT MAX(population) FROM t)]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 440: Mismatch\n",
      " - Row 441: Mismatch\n",
      " - Row 442: Execution error: (sqlite3.OperationalError) no such column: city\n",
      "[SQL: SELECT population FROM t WHERE city = 'atlanta' AND country = 'usa']\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 444: Execution error: (sqlite3.OperationalError) no such column: StateName\n",
      "[SQL: SELECT StateName FROM t WHERE RiverName = 'Mississippi']\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 445: Execution error: 'NoneType' object has no attribute 'reset_index'\n",
      " - Row 447: Execution error: (sqlite3.OperationalError) no such column: state\n",
      "[SQL: SELECT area FROM t WHERE state = 'California']\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 449: Execution error: (sqlite3.OperationalError) no such table: geography\n",
      "[SQL: SELECT `city_name` AS `capital`, `state` AS `province` FROM `geography` WHERE `country_code` = 'US' AND `region_code` = 'MI' ORDER BY `province` LIMIT 1]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 451: Execution error: (sqlite3.OperationalError) no such column: name\n",
      "[SQL: SELECT COUNT(*) FROM t WHERE name = 'Austin' AND country = 'USA' AND state = 'TX']\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 455: Missing columns in table: {'population', 'state_name'}\n",
      " - Row 456: Execution error: (sqlite3.OperationalError) no such column: country_code\n",
      "[SQL: SELECT state_name FROM t WHERE country_code = 'US' AND state_name!= 'wisconsin']\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 457: Execution error: (sqlite3.OperationalError) no such column: name\n",
      "[SQL: SELECT name FROM t WHERE bordering_countries LIKE '%Arizona%' AND name NOT LIKE 'Arizona%']\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 458: Missing columns in table: {'capital'}\n",
      " - Row 459: Missing columns in table: {'border'}\n",
      " - Row 460: Execution error: (sqlite3.OperationalError) no such column: location\n",
      "[SQL: SELECT river_name FROM t WHERE location='virginia']\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 461: Missing columns in table: {'population', 'state_name'}\n",
      " - Row 462: Mismatch\n",
      " - Row 463: Execution error: (sqlite3.OperationalError) no such column: name\n",
      "[SQL: SELECT name FROM t WHERE bordering_countries LIKE '%Kentucky%']\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 464: Execution error: 'NoneType' object has no attribute 'reset_index'\n",
      " - Row 465: Mismatch\n",
      " - Row 466: Mismatch\n",
      " - Row 467: Execution error: 'NoneType' object has no attribute 'reset_index'\n",
      " - Row 468: Execution error: (sqlite3.OperationalError) no such column: state\n",
      "[SQL: SELECT state FROM t ORDER BY point DESC LIMIT 1]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 469: Mismatch\n",
      " - Row 470: Execution error: 'NoneType' object has no attribute 'reset_index'\n",
      " - Row 471: Execution error: (sqlite3.OperationalError) no such column: capital\n",
      "[SQL: SELECT city_name FROM t WHERE population=(SELECT max(population) FROM t WHERE city_name IN (SELECT capital FROM t))]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 472: Execution error: (sqlite3.OperationalError) no such column: country\n",
      "[SQL: SELECT MIN(length) FROM t WHERE country = 'USA']\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 473: Missing columns in table: {'capital'}\n",
      " - Row 475: Execution error: (sqlite3.OperationalError) no such column: border\n",
      "[SQL: SELECT river_name FROM t WHERE traverse IN (SELECT border FROM t WHERE state_name='Alabama')]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 476: Execution error: (sqlite3.OperationalError) no such column: City\n",
      "[SQL: SELECT City AS BiggestCity FROM t ORDER BY Population DESC LIMIT 1]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 477: Execution error: (sqlite3.OperationalError) no such column: state\n",
      "[SQL: SELECT state FROM t WHERE population / area = (SELECT MIN(population / area) FROM t)]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 478: Execution error: (sqlite3.OperationalError) no such column: elevation\n",
      "[SQL: SELECT elevation FROM t WHERE name='death valley']\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 479: Mismatch\n",
      " - Row 480: Execution error: (sqlite3.OperationalError) no such column: state\n",
      "[SQL: SELECT city_name FROM t WHERE state = 'Missouri' AND population > 150000]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 481: Execution error: (sqlite3.OperationalError) no such column: state\n",
      "[SQL: SELECT state, density, area FROM t WHERE density = (SELECT MIN(density) FROM t WHERE density > 0)]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 482: Execution error: (sqlite3.OperationalError) no such column: state\n",
      "[SQL: SELECT capital FROM t WHERE state = 'New Hampshire']\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 485: Missing columns in table: {'name'}\n",
      " - Row 486: Missing columns in table: {'name', 'state_id', 'id'}\n",
      " - Row 487: Mismatch\n",
      " - Row 488: Execution error: (sqlite3.OperationalError) no such column: t.border\n",
      "[SQL: SELECT DISTINCT t.border FROM t b1\n",
      "    JOIN t b2 ON t.state_name = t.border\n",
      "    JOIN t b3 ON t.state_name = t.border\n",
      "    JOIN t b4 ON t.state_name = t.border\n",
      "    WHERE t.state_name = 'Texas']\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 489: Missing columns in table: {'name', 'state_id', 'id'}\n",
      " - Row 490: Execution error: (sqlite3.OperationalError) no such column: range\n",
      "[SQL: SELECT river_name, range AS Longest_River_Mileage FROM t ORDER BY range DESC LIMIT 1]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 492: Execution error: (sqlite3.OperationalError) no such column: capital_city\n",
      "[SQL: SELECT capital_city FROM t WHERE state_name = 'Texas']\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 493: Execution error: (sqlite3.OperationalError) no such column: state\n",
      "[SQL: SELECT state, population FROM t WHERE state = 'SD']\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 495: Execution error: (sqlite3.OperationalError) no such column: border\n",
      "[SQL: SELECT state_name FROM t WHERE state_name NOT IN (SELECT border FROM t WHERE state_name = 'Texas')]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 496: Execution error: (sqlite3.OperationalError) no such column: border\n",
      "[SQL: SELECT COUNT(*) \n",
      "    FROM t \n",
      "    WHERE state IN (\n",
      "        SELECT border \n",
      "        FROM t \n",
      "        WHERE state_name = 'nebraska'\n",
      "    ) \n",
      "    AND population > 150000]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 497: Execution error: (sqlite3.OperationalError) no such column: capital_city\n",
      "[SQL: SELECT state_name, capital_city FROM t WHERE capital = 'Sacramento' AND state_code = 'CA']\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 498: Missing columns in table: {'border'}\n",
      " - Row 499: Execution error: (sqlite3.OperationalError) no such column: state\n",
      "[SQL: SELECT city_name FROM t WHERE population=(SELECT max(population) FROM t WHERE state='California')]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 500: Mismatch\n",
      " - Row 501: Execution error: (sqlite3.OperationalError) no such column: name\n",
      "[SQL: SELECT name FROM t WHERE state = 'Oregon' AND country = 'United States']\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 502: Mismatch\n",
      " - Row 503: Execution error: (sqlite3.OperationalError) no such table: geography\n",
      "[SQL: SELECT `population` / `area` AS `population_density` FROM `geography` WHERE `state_name` = 'Wyoming' AND `state_code` = 'WY']\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 505: Mismatch\n",
      " - Row 506: Mismatch\n",
      " - Row 507: Execution error: (sqlite3.OperationalError) no such column: name\n",
      "[SQL: SELECT name FROM t WHERE country_code = 'US' AND name LIKE '%river%' ORDER BY length(name) DESC LIMIT 1]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 508: Execution error: (sqlite3.OperationalError) no such column: state\n",
      "[SQL: SELECT `river_name` FROM t WHERE state = 'Illinois']\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 509: Mismatch\n",
      " - Row 510: Execution error: (sqlite3.OperationalError) no such table: highlow\n",
      "[SQL: SELECT MAX(`highest_point_ft`) as highest_point_ft FROM `highlow` WHERE `state_name` = 'Kansas']\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 511: Mismatch\n",
      " - Row 512: Execution error: (sqlite3.OperationalError) no such column: city\n",
      "[SQL: SELECT city FROM t WHERE state_province_county = 'Texas']\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 513: Missing columns in table: {'name'}\n",
      " - Row 514: Missing columns in table: {'border'}\n",
      " - Row 515: Execution error: (sqlite3.OperationalError) no such column: state_province_county\n",
      "[SQL: SELECT `state_province_county`, MIN(`latitude`) FROM t WHERE `state_province_county` = 'Iowa' GROUP BY `state_province_county`]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 516: Execution error: (sqlite3.OperationalError) no such column: state\n",
      "[SQL: SELECT state FROM t WHERE state_code IN (SELECT state_code FROM t WHERE river_name = 'Ohio')]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 517: Execution error: 'NoneType' object has no attribute 'reset_index'\n",
      " - Row 518: Execution error: (sqlite3.OperationalError) no such column: state_name\n",
      "[SQL: SELECT river_name FROM t WHERE traverse IN (SELECT state_name FROM t WHERE lowest_elevation = (SELECT MIN(lowest_elevation) FROM t))]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 519: Execution error: 'NoneType' object has no attribute 'reset_index'\n",
      " - Row 520: Execution error: (sqlite3.OperationalError) no such column: city\n",
      "[SQL: SELECT population FROM t WHERE city = 'atlanta']\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 523: Execution error: (sqlite3.OperationalError) no such column: city\n",
      "[SQL: SELECT population FROM t WHERE city = 'Seattle' AND state = 'WA']\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 524: Mismatch\n",
      " - Row 525: Mismatch\n",
      " - Row 526: Mismatch\n",
      " - Row 527: Execution error: (sqlite3.OperationalError) no such column: state\n",
      "[SQL: SELECT SUM(population) FROM t WHERE state = 'California' AND country = 'United States']\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 529: Execution error: (sqlite3.OperationalError) no such column: latitude\n",
      "[SQL: SELECT MAX(latitude), MAX(longitude) FROM t WHERE state = 'Texas']\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " - Row 530: Execution error: 'NoneType' object has no attribute 'reset_index'\n",
      " - Row 532: Missing columns in table: {'geometry'}\n",
      " - Row 533: Execution error: (sqlite3.OperationalError) no such table: high_points\n",
      "[SQL: SELECT `high_points`.`state`, `high_points`.`name`, `high_points`.`height` FROM `high_points` WHERE `high_points`.`state` = 'Delaware' AND `high_points`.`height` = (SELECT MAX(`high_points`.`height`) FROM `high_points` WHERE `high_points`.`state` = 'Delaware')]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "\n",
      "📉 Most Common Missing Columns:\n",
      " - name: 28 times\n",
      " - id: 20 times\n",
      " - border: 17 times\n",
      " - state_name: 16 times\n",
      " - state_id: 13 times\n",
      " - population: 9 times\n",
      " - capital: 8 times\n",
      " - area: 6 times\n",
      " - state: 4 times\n",
      " - traverse: 3 times\n"
     ]
    }
   ],
   "source": [
    "accuracy = evaluate_execution_accuracy(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### spider 2.0 ablation qwen "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Exact Match Score: 53.40%\n",
      "✅ Avg Jaccard Structural Score: 73.57%\n",
      "\n",
      "📊 Count of Queries by Hardness:\n",
      "hardness\n",
      "easy      195\n",
      "extra     128\n",
      "hard      102\n",
      "medium    105\n",
      "Name: count, dtype: int64\n",
      "\n",
      "📊 Exact Match by Hardness:\n",
      "hardness\n",
      "easy      0.697436\n",
      "extra     0.359375\n",
      "hard      0.313725\n",
      "medium    0.657143\n",
      "Name: exact_match, dtype: float64\n",
      "\n",
      "📊 Jaccard Score by Hardness:\n",
      "hardness\n",
      "easy      0.860385\n",
      "extra     0.615123\n",
      "hard      0.568581\n",
      "medium    0.813651\n",
      "Name: jaccard_score, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for _, row in df1.iterrows():\n",
    "    query_id = row['instance_id']\n",
    "    pred_sql = row['generated_sql']\n",
    "    gold_sql = row['instance_id']\n",
    "\n",
    "    # Structure match\n",
    "    pred_struct = normalize_structure(pred_sql)\n",
    "    gold_struct = normalize_structure(gold_sql)\n",
    "\n",
    "    exact_match = int(pred_struct == gold_struct)\n",
    "    jaccard = len(set(pred_struct) & set(gold_struct)) / len(set(pred_struct) | set(gold_struct)) if (pred_struct or gold_struct) else 1.0\n",
    "\n",
    "    # Hardness\n",
    "    hardness = classify_sql_hardness(extract_sql_metadata(gold_sql))\n",
    "\n",
    "    results.append({\n",
    "        'instance_id': query_id,\n",
    "        'exact_match': exact_match,\n",
    "        'jaccard_score': jaccard,\n",
    "        'hardness': hardness\n",
    "    })\n",
    "\n",
    "# ----------------------------\n",
    "# Results\n",
    "# ----------------------------\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "print(f\"✅ Exact Match Score: {results_df['exact_match'].mean():.2%}\")\n",
    "print(f\"✅ Avg Jaccard Structural Score: {results_df['jaccard_score'].mean():.2%}\")\n",
    "\n",
    "print(\"\\n📊 Count of Queries by Hardness:\")\n",
    "print(results_df['hardness'].value_counts().sort_index())\n",
    "\n",
    "print(\"\\n📊 Exact Match by Hardness:\")\n",
    "print(results_df.groupby('hardness')['exact_match'].mean())\n",
    "\n",
    "print(\"\\n📊 Jaccard Score by Hardness:\")\n",
    "print(results_df.groupby('hardness')['jaccard_score'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### spider 2.0 ablation starcoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Exact Match Score: 52.26%\n",
      "✅ Avg Jaccard Structural Score: 76.16%\n",
      "\n",
      "📊 Count of Queries by Hardness:\n",
      "hardness\n",
      "easy      195\n",
      "extra     128\n",
      "hard      102\n",
      "medium    105\n",
      "Name: count, dtype: int64\n",
      "\n",
      "📊 Exact Match by Hardness:\n",
      "hardness\n",
      "easy      0.666667\n",
      "extra     0.343750\n",
      "hard      0.343137\n",
      "medium    0.647619\n",
      "Name: exact_match, dtype: float64\n",
      "\n",
      "📊 Jaccard Score by Hardness:\n",
      "hardness\n",
      "easy      0.831581\n",
      "extra     0.688821\n",
      "hard      0.660247\n",
      "medium    0.819002\n",
      "Name: jaccard_score, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for _, row in df1.iterrows():\n",
    "    query_id = row['instance_id']\n",
    "    pred_sql = row['refined_sql_cleaned']\n",
    "    gold_sql = row['instance_id']\n",
    "\n",
    "    # Structure match\n",
    "    pred_struct = normalize_structure(pred_sql)\n",
    "    gold_struct = normalize_structure(gold_sql)\n",
    "\n",
    "    exact_match = int(pred_struct == gold_struct)\n",
    "    jaccard = len(set(pred_struct) & set(gold_struct)) / len(set(pred_struct) | set(gold_struct)) if (pred_struct or gold_struct) else 1.0\n",
    "\n",
    "    # Hardness\n",
    "    hardness = classify_sql_hardness(extract_sql_metadata(gold_sql))\n",
    "\n",
    "    results.append({\n",
    "        'instance_id': query_id,\n",
    "        'exact_match': exact_match,\n",
    "        'jaccard_score': jaccard,\n",
    "        'hardness': hardness\n",
    "    })\n",
    "\n",
    "# ----------------------------\n",
    "# Results\n",
    "# ----------------------------\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "print(f\"✅ Exact Match Score: {results_df['exact_match'].mean():.2%}\")\n",
    "print(f\"✅ Avg Jaccard Structural Score: {results_df['jaccard_score'].mean():.2%}\")\n",
    "\n",
    "print(\"\\n📊 Count of Queries by Hardness:\")\n",
    "print(results_df['hardness'].value_counts().sort_index())\n",
    "\n",
    "print(\"\\n📊 Exact Match by Hardness:\")\n",
    "print(results_df.groupby('hardness')['exact_match'].mean())\n",
    "\n",
    "print(\"\\n📊 Jaccard Score by Hardness:\")\n",
    "print(results_df.groupby('hardness')['jaccard_score'].mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
